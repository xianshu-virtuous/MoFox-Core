#!/usr/bin/env python3
"""æ•°æ®åº“è¿ç§»è„šæœ¬

æ”¯æŒåœ¨ä¸åŒæ•°æ®åº“ä¹‹é—´è¿ç§»æ•°æ®ï¼š
- SQLite <-> MySQL
- SQLite <-> PostgreSQL
- MySQL <-> PostgreSQL

ä½¿ç”¨æ–¹æ³•:
    python scripts/migrate_database.py --help
    python scripts/migrate_database.py --source sqlite --target postgresql
    python scripts/migrate_database.py --source mysql --target postgresql --batch-size 5000

æ³¨æ„äº‹é¡¹:
1. è¿ç§»å‰è¯·å¤‡ä»½æºæ•°æ®åº“
2. ç›®æ ‡æ•°æ®åº“åº”è¯¥æ˜¯ç©ºçš„æˆ–ä¸å­˜åœ¨çš„ï¼ˆè„šæœ¬ä¼šè‡ªåŠ¨åˆ›å»ºè¡¨ï¼‰
3. è¿ç§»è¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…

å®ç°ç»†èŠ‚:
- ä½¿ç”¨ SQLAlchemy è¿›è¡Œæ•°æ®åº“è¿æ¥å’Œå…ƒæ•°æ®ç®¡ç†
- é‡‡ç”¨æµå¼è¿ç§»ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤šæ•°æ®
- æ”¯æŒ SQLiteã€MySQLã€PostgreSQL ä¹‹é—´çš„äº’ç›¸è¿ç§»
"""

from __future__ import annotations

import argparse
import logging
import os
import sys
from getpass import getpass

# =============================================================================
# è®¾ç½®æ—¥å¿—
# =============================================================================

logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s] %(message)s",
)

logger = logging.getLogger(__name__)

# =============================================================================
# å¯¼å…¥ç¬¬ä¸‰æ–¹åº“ï¼ˆå»¶è¿Ÿå¯¼å…¥ä»¥ä¾¿å‹å¥½æŠ¥é”™ï¼‰
# =============================================================================

try:
    import tomllib
except ImportError:
    tomllib = None

from typing import Any, Iterable, Callable

from sqlalchemy import (
    create_engine,
    MetaData,
    Table,
    inspect,
    text,
    types as sqltypes,
)
from sqlalchemy.engine import Engine, Connection
from sqlalchemy.exc import SQLAlchemyError

# ====== ä¸ºäº†åœ¨ Windows ä¸Šæ›´å‹å¥½çš„è¾“å‡ºä¸­æ–‡ï¼Œæå‰è®¾ç½®ç¯å¢ƒ ======
# æœ‰äº› Windows ç»ˆç«¯é»˜è®¤ç¼–ç ä¸æ˜¯ UTF-8ï¼Œè¿™é‡Œåšä¸ªå…¼å®¹
if os.name == "nt":
    try:
        import ctypes

        ctypes.windll.kernel32.SetConsoleOutputCP(65001)
    except Exception:
        pass


# =============================================================================
# é…ç½®ç›¸å…³å·¥å…·
# =============================================================================


def get_project_root() -> str:
    """è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå½“å‰è„šæœ¬çš„ä¸Šçº§ç›®å½•ï¼‰"""
    return os.path.dirname(os.path.dirname(os.path.abspath(__file__)))


PROJECT_ROOT = get_project_root()


def load_bot_config() -> dict:
    """åŠ è½½ config/bot_config.toml é…ç½®æ–‡ä»¶

    è¿”å›:
        dict: é…ç½®å­—å…¸ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥ï¼Œåˆ™è¿”å›ç©ºå­—å…¸
    """
    config_path = os.path.join(PROJECT_ROOT, "config", "bot_config.toml")
    if not os.path.exists(config_path):
        logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: %s", config_path)
        return {}

    if tomllib is None:
        logger.warning("å½“å‰ Python ç‰ˆæœ¬ä¸æ”¯æŒ tomllibï¼Œè¯·ä½¿ç”¨ Python 3.11+ æˆ–æ‰‹åŠ¨å®‰è£… tomli")
        return {}

    try:
        with open(config_path, "rb") as f:
            config = tomllib.load(f)
        return config
    except Exception as e:
        logger.error("è§£æé…ç½®æ–‡ä»¶å¤±è´¥: %s", e)
        return {}


def get_database_config_from_toml(db_type: str) -> dict | None:
    """ä» bot_config.toml ä¸­è¯»å–æ•°æ®åº“é…ç½®

    Args:
        db_type: æ•°æ®åº“ç±»å‹ï¼Œæ”¯æŒ "sqlite"ã€"mysql"ã€"postgresql"

    Returns:
        dict: æ•°æ®åº“é…ç½®å­—å…¸ï¼Œå¦‚æœå¯¹åº”é…ç½®ä¸å­˜åœ¨åˆ™è¿”å› None
    """
    config_data = load_bot_config()
    if not config_data:
        return None

    # å…¼å®¹æ—§ç»“æ„å’Œæ–°ç»“æ„
    # æ—§ç»“æ„: é¡¶å±‚ç›´æ¥æœ‰ db_type ç›¸å…³å­—æ®µ
    # æ–°ç»“æ„: åœ¨ [database] ä¸‹æœ‰ db_type ç›¸å…³å­—æ®µ
    db_config = config_data.get("database", {})

    if db_type == "sqlite":
        sqlite_path = (
            db_config.get("sqlite_path")
            or config_data.get("sqlite_path")
            or "data/MaiBot.db"
        )
        if not os.path.isabs(sqlite_path):
            sqlite_path = os.path.join(PROJECT_ROOT, sqlite_path)
        return {"path": sqlite_path}

    elif db_type == "mysql":
        return {
            "host": db_config.get("mysql_host")
            or config_data.get("mysql_host")
            or "localhost",
            "port": db_config.get("mysql_port")
            or config_data.get("mysql_port")
            or 3306,
            "database": db_config.get("mysql_database")
            or config_data.get("mysql_database")
            or "maibot",
            "user": db_config.get("mysql_user")
            or config_data.get("mysql_user")
            or "root",
            "password": db_config.get("mysql_password")
            or config_data.get("mysql_password")
            or "",
            "charset": db_config.get("mysql_charset")
            or config_data.get("mysql_charset")
            or "utf8mb4",
        }

    elif db_type == "postgresql":
        return {
            "host": db_config.get("postgresql_host")
            or config_data.get("postgresql_host")
            or "localhost",
            "port": db_config.get("postgresql_port")
            or config_data.get("postgresql_port")
            or 5432,
            "database": db_config.get("postgresql_database")
            or config_data.get("postgresql_database")
            or "maibot",
            "user": db_config.get("postgresql_user")
            or config_data.get("postgresql_user")
            or "postgres",
            "password": db_config.get("postgresql_password")
            or config_data.get("postgresql_password")
            or "",
            "schema": db_config.get("postgresql_schema")
            or config_data.get("postgresql_schema")
            or "public",
        }

    return None


# =============================================================================
# æ•°æ®åº“è¿æ¥ç›¸å…³
# =============================================================================


def create_sqlite_engine(sqlite_path: str) -> Engine:
    """ï¿½ï¿½ï¿½ï¿½ SQLite ï¿½ï¿½ï¿½ï¿½"""
    if not os.path.isabs(sqlite_path):
        sqlite_path = os.path.join(PROJECT_ROOT, sqlite_path)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(sqlite_path), exist_ok=True)

    url = f"sqlite:///{sqlite_path}"
    logger.info("ä½¿ç”¨ SQLite æ•°æ®åº“: %s", sqlite_path)
    engine = create_engine(
        url,
        future=True,
        connect_args={
            "timeout": 30,  # wait a bit if the db is locked
            "check_same_thread": False,
        },
    )
    # Increase busy timeout to reduce "database is locked" errors on SQLite
    with engine.connect() as conn:
        conn.execute(text("PRAGMA busy_timeout=30000"))
    return engine


def create_postgresql_engine(
    host: str,
    port: int,
    database: str,
    user: str,
    password: str,
    schema: str = "public",
) -> Engine:
    """åˆ›å»º PostgreSQL å¼•æ“"""
    # åœ¨å¯¼å…¥ psycopg2 ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè§£å†³ Windows ç¼–ç é—®é¢˜
    # psycopg2 åœ¨ Windows ä¸Šè¿æ¥æ—¶ï¼Œå¦‚æœå®¢æˆ·ç«¯ç¼–ç ä¸æœåŠ¡å™¨ä¸ä¸€è‡´å¯èƒ½ä¼šæœ‰é—®é¢˜
    os.environ.setdefault("PGCLIENTENCODING", "utf-8")

    # å»¶è¿Ÿå¯¼å…¥ psycopg2ï¼Œä»¥ä¾¿å‹å¥½æç¤º
    try:
        import psycopg2  # noqa: F401
    except ImportError:
        logger.error("éœ€è¦å®‰è£… psycopg2-binary æ‰èƒ½è¿æ¥ PostgreSQL: pip install psycopg2-binary")
        raise

    url = f"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}"
    logger.info("ä½¿ç”¨ PostgreSQL æ•°æ®åº“: %s@%s:%s/%s (schema=%s)", user, host, port, database, schema)
    engine = create_engine(url, future=True)
    # ä¸ºäº†æ–¹ä¾¿ï¼Œè®¾ç½® search_path
    with engine.connect() as conn:
        conn.execute(text(f"SET search_path TO {schema}"))
    return engine


def create_engine_by_type(db_type: str, config: dict) -> Engine:
    """æ ¹æ®æ•°æ®åº“ç±»å‹åˆ›å»ºå¯¹åº”çš„ SQLAlchemy Engine

    Args:
        db_type: æ•°æ®åº“ç±»å‹ï¼Œæ”¯æŒ sqlite/mysql/postgresql
        config: é…ç½®å­—å…¸

    Returns:
        Engine: SQLAlchemy å¼•æ“å®ä¾‹
    """
    db_type = db_type.lower()
    if db_type == "sqlite":
        return create_sqlite_engine(config["path"])
    elif db_type == "mysql":
        return create_mysql_engine(
            host=config["host"],
            port=config["port"],
            database=config["database"],
            user=config["user"],
            password=config["password"],
            charset=config.get("charset", "utf8mb4"),
        )
    elif db_type == "postgresql":
        return create_postgresql_engine(
            host=config["host"],
            port=config["port"],
            database=config["database"],
            user=config["user"],
            password=config["password"],
            schema=config.get("schema", "public"),
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {db_type}")


# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================


def chunked_iterable(iterable: Iterable, size: int) -> Iterable[list]:
    """å°†å¯è¿­ä»£å¯¹è±¡åˆ†å—

    Args:
        iterable: å¯è¿­ä»£å¯¹è±¡
        size: æ¯å—å¤§å°

    Yields:
        list: åˆ†å—åˆ—è¡¨
    """
    chunk: list[Any] = []
    for item in iterable:
        chunk.append(item)
        if len(chunk) >= size:
            yield chunk
            chunk = []
    if chunk:
        yield chunk


def get_table_row_count(conn: Connection, table: Table) -> int:
    """è·å–è¡¨çš„è¡Œæ•°"""
    try:
        result = conn.execute(text(f"SELECT COUNT(*) FROM {table.name}"))
        return int(result.scalar() or 0)
    except SQLAlchemyError as e:
        logger.warning("è·å–è¡¨è¡Œæ•°å¤±è´¥ %s: %s", table.name, e)
        return 0


def copy_table_structure(source_table: Table, target_metadata: MetaData, target_engine: Engine) -> Table:
    """å¤åˆ¶è¡¨ç»“æ„åˆ°ç›®æ ‡æ•°æ®åº“ï¼Œä½¿å…¶ç»“æ„ä¿æŒä¸€è‡´"""
    target_is_sqlite = target_engine.dialect.name == "sqlite"
    target_is_pg = target_engine.dialect.name == "postgresql"

    columns = []
    for c in source_table.columns:
        new_col = c.copy()

        # SQLite ä¸æ”¯æŒ nextval ç­‰ server_default
        if target_is_sqlite:
            new_col.server_default = None

        # PostgreSQL éœ€è¦å°†éƒ¨åˆ† SQLite ç‰¹æœ‰ç±»å‹è½¬æ¢
        if target_is_pg:
            col_type = new_col.type
            # SQLite DATETIME -> é€šç”¨ DateTime
            if isinstance(col_type, sqltypes.DateTime) or col_type.__class__.__name__ in {"DATETIME", "DateTime"}:
                new_col.type = sqltypes.DateTime()
            # TEXT(50) ç­‰é•¿åº¦å—é™çš„ TEXT åœ¨ PG æ— æ•ˆï¼Œæ”¹ç”¨ String(length)
            elif isinstance(col_type, sqltypes.Text) and getattr(col_type, "length", None):
                new_col.type = sqltypes.String(length=col_type.length)

        columns.append(new_col)

    # ä¸ºé¿å…è¿­ä»£çº¦æŸé›†åˆæ—¶å‡ºç° â€œSet changed size during iterationâ€ï¼Œè¿™é‡Œä¸å¤åˆ¶è¡¨çº§çº¦æŸ
    target_table = Table(
        source_table.name,
        target_metadata,
        *columns,
    )
    target_metadata.create_all(target_engine, tables=[target_table])
    return target_table


def migrate_table_data(
    source_conn: Connection,
    target_conn: Connection,
    source_table: Table,
    target_table: Table,
    batch_size: int = 1000,
) -> tuple[int, int]:
    """è¿ç§»å•ä¸ªè¡¨çš„æ•°æ®

    Args:
        source_conn: æºæ•°æ®åº“è¿æ¥
        target_conn: ç›®æ ‡æ•°æ®åº“è¿æ¥
        source_table: æºè¡¨å¯¹è±¡
        target_table: ç›®æ ‡è¡¨å¯¹è±¡
        batch_size: æ¯æ‰¹æ¬¡å¤„ç†å¤§å°

    Returns:
        tuple[int, int]: (è¿ç§»è¡Œæ•°, é”™è¯¯æ•°é‡)
    """
    total_rows = get_table_row_count(source_conn, source_table)
    logger.info(
        "å¼€å§‹è¿ç§»è¡¨: %s (å…± %s è¡Œ)",
        source_table.name,
        total_rows if total_rows else "æœªçŸ¥",
    )

    migrated_rows = 0
    error_count = 0

    # ä½¿ç”¨æµå¼æŸ¥è¯¢ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½å¤ªå¤šæ•°æ®
    # å¯¹äº SQLAlchemy 1.4/2.0 å¯ä»¥ä½¿ç”¨ yield_per
    try:
        select_stmt = source_table.select()
        result = source_conn.execute(select_stmt)
    except SQLAlchemyError as e:
        logger.error("æŸ¥è¯¢è¡¨ %s å¤±è´¥: %s", source_table.name, e)
        return 0, 1

    def insert_batch(rows: list[dict]):
        nonlocal migrated_rows, error_count
        if not rows:
            return
        try:
            target_conn.execute(target_table.insert(), rows)
            migrated_rows += len(rows)
            logger.info("  å·²è¿ç§» %d/%s è¡Œ", migrated_rows, total_rows or "?")
        except SQLAlchemyError as e:
            logger.error("å†™å…¥è¡¨ %s å¤±è´¥: %s", target_table.name, e)
            error_count += len(rows)

    batch: list[dict] = []
    null_char_replacements = 0

    for row in result:
        # Use column objects to access row mapping to avoid quoted_name keys
        row_dict = {}
        for col in source_table.columns:
            val = row._mapping[col]
            if isinstance(val, str) and "\x00" in val:
                val = val.replace("\x00", "")
                null_char_replacements += 1
            row_dict[col.key] = val

        batch.append(row_dict)
        if len(batch) >= batch_size:
            insert_batch(batch)
            batch = []

    if batch:
        insert_batch(batch)

    logger.info(
        "å®Œæˆè¿ç§»è¡¨: %s (æˆåŠŸ: %d è¡Œ, å¤±è´¥: %d è¡Œ)",
        source_table.name,
        migrated_rows,
        error_count,
    )
    if null_char_replacements:
        logger.warning(
            "è¡¨ %s ä¸­ %d ä¸ªå­—ç¬¦ä¸²å€¼åŒ…å« NUL å·²è¢«ç§»é™¤åå†™å…¥ç›®æ ‡åº“",
            source_table.name,
            null_char_replacements,
        )

    return migrated_rows, error_count


def confirm_action(prompt: str, default: bool = False) -> bool:
    """ç¡®è®¤æ“ä½œ

    Args:
        prompt: æç¤ºä¿¡æ¯
        default: é»˜è®¤å€¼

    Returns:
        bool: ç”¨æˆ·æ˜¯å¦ç¡®è®¤
    """
    while True:
        if default:
            choice = input(f"{prompt} [Y/n]: ").strip().lower()
            if choice == "":
                return True
        else:
            choice = input(f"{prompt} [y/N]: ").strip().lower()
            if choice == "":
                return False

        if choice in ("y", "yes"):
            return True
        elif choice in ("n", "no"):
            return False
        else:
            print("è¯·è¾“å…¥ y æˆ– n")


# =============================================================================
# è¿ç§»å™¨å®ç°
# =============================================================================


class DatabaseMigrator:
    """é€šç”¨æ•°æ®åº“è¿ç§»å™¨"""

    def __init__(
        self,
        source_type: str,
        target_type: str,
        batch_size: int = 1000,
        source_config: dict | None = None,
        target_config: dict | None = None,
    ):
        """åˆå§‹åŒ–è¿ç§»å™¨

        Args:
            source_type: æºæ•°æ®åº“ç±»å‹
            target_type: ç›®æ ‡æ•°æ®åº“ç±»å‹
            batch_size: æ‰¹é‡å¤„ç†å¤§å°
            source_config: æºæ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
            target_config: ç›®æ ‡æ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼Œéœ€è¦æ‰‹åŠ¨æŒ‡å®šï¼‰
        """
        self.source_type = source_type.lower()
        self.target_type = target_type.lower()
        self.batch_size = batch_size
        self.source_config = source_config
        self.target_config = target_config

        self._validate_database_types()

        self.source_engine: Any = None
        self.target_engine: Any = None
        self.metadata = MetaData()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "tables_migrated": 0,
            "rows_migrated": 0,
            "errors": [],
            "start_time": None,
            "end_time": None,
        }

    def _validate_database_types(self):
        """éªŒè¯æ•°æ®åº“ç±»å‹"""
        supported_types = {"sqlite", "mysql", "postgresql"}
        if self.source_type not in supported_types:
            raise ValueError(f"ä¸æ”¯æŒçš„æºæ•°æ®åº“ç±»å‹: {self.source_type}")
        if self.target_type not in supported_types:
            raise ValueError(f"ä¸æ”¯æŒçš„ç›®æ ‡æ•°æ®åº“ç±»å‹: {self.target_type}")

    def _load_source_config(self) -> dict:
        """åŠ è½½æºæ•°æ®åº“é…ç½®

        å¦‚æœåˆå§‹åŒ–æ—¶æä¾›äº† source_configï¼Œåˆ™ç›´æ¥ä½¿ç”¨ï¼›
        å¦åˆ™ä» bot_config.toml ä¸­è¯»å–ã€‚
        """
        if self.source_config:
            logger.info("ä½¿ç”¨ä¼ å…¥çš„æºæ•°æ®åº“é…ç½®")
            return self.source_config

        logger.info("æœªæä¾›æºæ•°æ®åº“é…ç½®ï¼Œå°è¯•ä» bot_config.toml è¯»å–")
        config = get_database_config_from_toml(self.source_type)
        if not config:
            raise ValueError("æ— æ³•ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æºæ•°æ®åº“é…ç½®ï¼Œè¯·æ£€æŸ¥ config/bot_config.toml")

        logger.info("æˆåŠŸä»é…ç½®æ–‡ä»¶è¯»å–æºæ•°æ®åº“é…ç½®")
        return config

    def _load_target_config(self) -> dict:
        """åŠ è½½ç›®æ ‡æ•°æ®åº“é…ç½®

        ç›®æ ‡æ•°æ®åº“é…ç½®å¿…é¡»é€šè¿‡åˆå§‹åŒ–å‚æ•°æä¾›ï¼Œæˆ–è€…é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æ„å»ºã€‚
        """
        if not self.target_config:
            raise ValueError("æœªæä¾›ç›®æ ‡æ•°æ®åº“é…ç½®ï¼Œè¯·é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæˆ–åœ¨äº¤äº’æ¨¡å¼ä¸­è¾“å…¥")
        logger.info("ä½¿ç”¨ä¼ å…¥çš„ç›®æ ‡æ•°æ®åº“é…ç½®")
        return self.target_config

    def _connect_databases(self):
        """è¿æ¥æºæ•°æ®åº“å’Œç›®æ ‡æ•°æ®åº“"""
        # æºæ•°æ®åº“é…ç½®
        source_config = self._load_source_config()
        # ç›®æ ‡æ•°æ®åº“é…ç½®
        target_config = self._load_target_config()

        # é˜²æ­¢æº/ç›®æ ‡ SQLite æŒ‡å‘åŒä¸€è·¯å¾„å¯¼è‡´è‡ªæˆ‘è¦†ç›–åŠé”
        if (
            self.source_type == "sqlite"
            and self.target_type == "sqlite"
            and os.path.abspath(source_config.get("path", "")) == os.path.abspath(target_config.get("path", ""))
        ):
            raise ValueError("æºæ•°æ®åº“ä¸ç›®æ ‡æ•°æ®åº“ä¸èƒ½æ˜¯åŒä¸€ä¸ª SQLite æ–‡ä»¶ï¼Œè¯·ä¸ºç›®æ ‡æŒ‡å®šä¸åŒçš„è·¯å¾„")

        # åˆ›å»ºå¼•æ“
        self.source_engine = create_engine_by_type(self.source_type, source_config)
        self.target_engine = create_engine_by_type(self.target_type, target_config)

        # åå°„æºæ•°æ®åº“å…ƒæ•°æ®
        logger.info("æ­£åœ¨åå°„æºæ•°æ®åº“å…ƒæ•°æ®...")
        self.metadata.reflect(bind=self.source_engine)
        logger.info("å‘ç° %d å¼ è¡¨: %s", len(self.metadata.tables), ", ".join(self.metadata.tables.keys()))

    def _get_tables_in_dependency_order(self) -> list[Table]:
        """è·å–æŒ‰ä¾èµ–é¡ºåºæ’åºçš„è¡¨åˆ—è¡¨

        ä¸ºäº†é¿å…å¤–é”®çº¦æŸé—®é¢˜ï¼Œåˆ›å»ºè¡¨æ—¶éœ€è¦æŒ‰ç…§ä¾èµ–é¡ºåºï¼Œ
        ä¾‹å¦‚å…ˆåˆ›å»ºè¢«å¼•ç”¨çš„è¡¨ï¼Œå†åˆ›å»ºå¼•ç”¨å®ƒä»¬çš„è¡¨ã€‚
        """
        inspector = inspect(self.source_engine)

        # æ„å»ºä¾èµ–å›¾ï¼štable -> set(dependent_tables)
        dependencies: dict[str, set[str]] = {}
        for table_name in self.metadata.tables:
            dependencies[table_name] = set()

        for table_name, table in self.metadata.tables.items():
            fks = inspector.get_foreign_keys(table_name)
            for fk in fks:
                # è¢«å¼•ç”¨çš„è¡¨
                referred_table = fk["referred_table"]
                if referred_table in dependencies:
                    dependencies[table_name].add(referred_table)

        # æ‹“æ‰‘æ’åº
        sorted_tables: list[Table] = []
        visited: set[str] = set()
        temp_mark: set[str] = set()

        def visit(table_name: str):
            if table_name in visited:
                return
            if table_name in temp_mark:
                logger.warning("æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–ï¼Œè¡¨: %s", table_name)
                return
            temp_mark.add(table_name)
            for dep in dependencies[table_name]:
                visit(dep)
            temp_mark.remove(table_name)
            visited.add(table_name)
            sorted_tables.append(self.metadata.tables[table_name])

        for table_name in dependencies:
            if table_name not in visited:
                visit(table_name)

        return sorted_tables

    def _drop_target_tables(self):
        """åˆ é™¤ç›®æ ‡æ•°æ®åº“ä¸­å·²æœ‰çš„è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰

        ä½¿ç”¨ Engine.begin() è¿›è¡Œè¿æ¥ä»¥æ”¯æŒ autobegin å’Œ begin å…¼å®¹ SQLAlchemy 2.0 çš„å†™æ³•
        """
        if self.target_engine is None:
            logger.warning("ç›®æ ‡æ•°æ®åº“å¼•æ“å°šæœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ é™¤è¡¨")
            return

        with self.target_engine.begin() as conn:
            inspector = inspect(conn)
            existing_tables = inspector.get_table_names()

            if not existing_tables:
                logger.info("ç›®æ ‡æ•°æ®åº“ä¸­æ²¡æœ‰å·²å­˜åœ¨çš„è¡¨ï¼Œæ— éœ€åˆ é™¤")
                return

            logger.info("ç›®æ ‡æ•°æ®åº“ä¸­çš„å½“å‰è¡¨: %s", ", ".join(existing_tables))
            if confirm_action("æ˜¯å¦åˆ é™¤ç›®æ ‡æ•°æ®åº“ä¸­ç°æœ‰çš„è¡¨åˆ—è¡¨ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€", default=False):
                for table_name in existing_tables:
                    try:
                        logger.info("åˆ é™¤ç›®æ ‡æ•°æ®åº“è¡¨: %s", table_name)
                        conn.execute(text(f"DROP TABLE IF EXISTS {table_name} CASCADE"))
                    except SQLAlchemyError as e:
                        logger.error("åˆ é™¤ %s å¤±è´¥: %s", table_name, e)
                        self.stats["errors"].append(
                            f"åˆ é™¤ {table_name} å¤±è´¥: {e}"
                        )
            else:
                logger.info("è·³è¿‡åˆ é™¤ç›®æ ‡æ•°æ®åº“ä¸­çš„è¡¨ï¼Œç»§ç»­è¿ç§»è¿‡ç¨‹")

    def migrate(self):
        """æ‰§è¡Œè¿ç§»æ“ä½œ"""
        import time

        self.stats["start_time"] = time.time()

        # è¿æ¥æ•°æ®åº“
        self._connect_databases()

        # è·å–è¡¨çš„ä¾èµ–é¡ºåº
        tables = self._get_tables_in_dependency_order()
        logger.info("æŒ‰ä¾èµ–é¡ºåºè¿ç§»è¡¨: %s", ", ".join(t.name for t in tables))

        # åˆ é™¤ç›®æ ‡åº“ä¸­å·²æœ‰è¡¨ï¼ˆå¯é€‰ï¼‰
        self._drop_target_tables()

        # å¼€å§‹è¿ç§»
        with self.source_engine.connect() as source_conn:
            for source_table in tables:
                try:
                    # åœ¨ç›®æ ‡åº“ä¸­åˆ›å»ºè¡¨ç»“æ„
                    target_table = copy_table_structure(source_table, MetaData(), self.target_engine)

                    # æ¯å¼ è¡¨å•ç‹¬äº‹åŠ¡ï¼Œé¿å…é€€å‡ºä¸Šä¸‹æ–‡è¢«è‡ªåŠ¨å›æ»š
                    with self.target_engine.begin() as target_conn:
                        migrated_rows, error_count = migrate_table_data(
                            source_conn,
                            target_conn,
                            source_table,
                            target_table,
                            batch_size=self.batch_size,
                        )

                    self.stats["tables_migrated"] += 1
                    self.stats["rows_migrated"] += migrated_rows
                    if error_count > 0:
                        self.stats["errors"].append(
                            f"è¡¨ {source_table.name} è¿ç§»å¤±è´¥ {error_count} è¡Œ"
                        )

                except Exception as e:
                    logger.error("è¿ç§»è¡¨ %s æ—¶å‘ç”Ÿé”™è¯¯: %s", source_table.name, e)
                    self.stats["errors"].append(f"è¡¨ {source_table.name} è¿ç§»å¤±è´¥: {e}")

        self.stats["end_time"] = time.time()

    def print_summary(self):
        """æ‰“å°è¿ç§»æ€»ç»“"""
        import time

        duration = None
        if self.stats["start_time"] is not None and self.stats["end_time"] is not None:
            duration = self.stats["end_time"] - self.stats["start_time"]

        print("\n" + "=" * 60)
        print("è¿ç§»å®Œæˆï¼")
        print(f"  è¿ç§»è¡¨æ•°é‡: {self.stats['tables_migrated']}")
        print(f"  è¿ç§»è¡Œæ•°é‡: {self.stats['rows_migrated']}")
        if duration is not None:
            print(f"  æ€»è€—æ—¶: {duration:.2f} ç§’")
        if self.stats["errors"]:
            print("  âš ï¸ å‘ç”Ÿé”™è¯¯:")
            for err in self.stats["errors"]:
                print(f"    - {err}")
        else:
            print("  æ²¡æœ‰å‘ç”Ÿé”™è¯¯ ğŸ‰")
        print("=" * 60 + "\n")

    def run(self):
        """è¿è¡Œè¿ç§»å¹¶æ‰“å°æ€»ç»“"""
        self.migrate()
        self.print_summary()
        return self.stats


# =============================================================================
# å‘½ä»¤è¡Œå‚æ•°è§£æ
# =============================================================================


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="æ•°æ®åº“è¿ç§»å·¥å…· - åœ¨ SQLiteã€MySQLã€PostgreSQL ä¹‹é—´è¿ç§»æ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""ç¤ºä¾‹:
  # ä» SQLite è¿ç§»åˆ° PostgreSQL
  python scripts/migrate_database.py \
    --source sqlite \
    --target postgresql \
    --target-host localhost \
    --target-port 5432 \
    --target-database maibot \
    --target-user postgres \
    --target-password your_password

  # ä» SQLite è¿ç§»åˆ° MySQL
  python scripts/migrate_database.py \
    --source sqlite \
    --target mysql \
    --target-host localhost \
    --target-port 3306 \
    --target-database maibot \
    --target-user root \
    --target-password your_password

  # ä½¿ç”¨äº¤äº’å¼å‘å¯¼æ¨¡å¼ï¼ˆæ¨èï¼‰
  python scripts/migrate_database.py
  python scripts/migrate_database.py --interactive
        """,
    )

    # åŸºæœ¬å‚æ•°
    parser.add_argument(
        "--source",
        type=str,
        choices=["sqlite", "mysql", "postgresql"],
        help="æºæ•°æ®åº“ç±»å‹ï¼ˆä¸æŒ‡å®šæ—¶ï¼Œåœ¨äº¤äº’æ¨¡å¼ä¸­é€‰æ‹©ï¼‰",
    )
    parser.add_argument(
        "--target",
        type=str,
        choices=["sqlite", "mysql", "postgresql"],
        help="ç›®æ ‡æ•°æ®åº“ç±»å‹ï¼ˆä¸æŒ‡å®šæ—¶ï¼Œåœ¨äº¤äº’æ¨¡å¼ä¸­é€‰æ‹©ï¼‰",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=1000,
        help="æ‰¹é‡å¤„ç†å¤§å°ï¼ˆé»˜è®¤: 1000ï¼‰",
    )

    parser.add_argument(
        "--interactive",
        action="store_true",
        help="å¯ç”¨äº¤äº’å¼å‘å¯¼æ¨¡å¼ï¼ˆæ¨èï¼šç›´æ¥è¿è¡Œè„šæœ¬æˆ–åŠ ä¸Šæ­¤å‚æ•°ï¼‰",
    )

    # æºæ•°æ®åº“å‚æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä» bot_config.toml è¯»å–ï¼‰
    source_group = parser.add_argument_group("æºæ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä» bot_config.toml è¯»å–ï¼‰")
    source_group.add_argument("--source-path", type=str, help="SQLite æ•°æ®åº“è·¯å¾„")
    source_group.add_argument("--source-host", type=str, help="MySQL/PostgreSQL ä¸»æœº")
    source_group.add_argument("--source-port", type=int, help="MySQL/PostgreSQL ç«¯å£")
    source_group.add_argument("--source-database", type=str, help="æ•°æ®åº“å")
    source_group.add_argument("--source-user", type=str, help="ç”¨æˆ·å")
    source_group.add_argument("--source-password", type=str, help="å¯†ç ")

    # ç›®æ ‡æ•°æ®åº“å‚æ•°
    target_group = parser.add_argument_group("ç›®æ ‡æ•°æ®åº“é…ç½®")
    target_group.add_argument("--target-path", type=str, help="SQLite æ•°æ®åº“è·¯å¾„")
    target_group.add_argument("--target-host", type=str, help="MySQL/PostgreSQL ä¸»æœº")
    target_group.add_argument("--target-port", type=int, help="MySQL/PostgreSQL ç«¯å£")
    target_group.add_argument("--target-database", type=str, help="æ•°æ®åº“å")
    target_group.add_argument("--target-user", type=str, help="ç”¨æˆ·å")
    target_group.add_argument("--target-password", type=str, help="å¯†ç ")
    target_group.add_argument("--target-schema", type=str, default="public", help="PostgreSQL schema")
    target_group.add_argument("--target-charset", type=str, default="utf8mb4", help="MySQL å­—ç¬¦é›†")

    return parser.parse_args()


def build_config_from_args(args, prefix: str, db_type: str) -> dict | None:
    """ä»å‘½ä»¤è¡Œå‚æ•°æ„å»ºé…ç½®

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        prefix: å‚æ•°å‰ç¼€ ("source" æˆ– "target")
        db_type: æ•°æ®åº“ç±»å‹

    Returns:
        é…ç½®å­—å…¸æˆ– None
    """
    if db_type == "sqlite":
        path = getattr(args, f"{prefix}_path", None)
        if path:
            return {"path": path}
        return None

    elif db_type in ("mysql", "postgresql"):
        host = getattr(args, f"{prefix}_host", None)
        if not host:
            return None

        config = {
            "host": host,
            "port": getattr(args, f"{prefix}_port") or (3306 if db_type == "mysql" else 5432),
            "database": getattr(args, f"{prefix}_database") or "maibot",
            "user": getattr(args, f"{prefix}_user") or ("root" if db_type == "mysql" else "postgres"),
            "password": getattr(args, f"{prefix}_password") or "",
        }

        if db_type == "mysql":
            config["charset"] = getattr(args, f"{prefix}_charset", "utf8mb4")
        elif db_type == "postgresql":
            config["schema"] = getattr(args, f"{prefix}_schema", "public")

        return config

    return None


def _ask_choice(prompt: str, options: list[str], default_index: int | None = None) -> str:
    """åœ¨æ§åˆ¶å°ä¸­è®©ç”¨æˆ·ä»å¤šä¸ªé€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ª"""
    while True:
        print()
        print(prompt)
        for i, opt in enumerate(options, start=1):
            default_mark = ""
            if default_index is not None and i - 1 == default_index:
                default_mark = "  (é»˜è®¤)"
            print(f"  {i}) {opt}{default_mark}")
        ans = input("è¯·è¾“å…¥é€‰é¡¹ç¼–å·: ").strip()
        if not ans and default_index is not None:
            return options[default_index]
        if ans.isdigit():
            idx = int(ans)
            if 1 <= idx <= len(options):
                return options[idx - 1]
        print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")


def _ask_int(prompt: str, default: int | None = None) -> int:
    """åœ¨æ§åˆ¶å°ä¸­è¾“å…¥æ­£æ•´æ•°"""
    while True:
        suffix = f" (é»˜è®¤ {default})" if default is not None else ""
        raw = input(f"{prompt}{suffix}: ").strip()
        if not raw and default is not None:
            return default
        try:
            value = int(raw)
            if value <= 0:
                raise ValueError()
            return value
        except ValueError:
            print("âŒ è¯·è¾“å…¥ä¸€ä¸ªå¤§äº 0 çš„æ•´æ•°ã€‚")


def _ask_str(
    prompt: str,
    default: str | None = None,
    allow_empty: bool = False,
    is_password: bool = False,
) -> str:
    """åœ¨æ§åˆ¶å°ä¸­è¾“å…¥å­—ç¬¦ä¸²ï¼Œå¯é€‰é»˜è®¤å€¼/å¯†ç è¾“å…¥"""
    while True:
        suffix = f" (é»˜è®¤: {default})" if default is not None else ""
        full_prompt = f"{prompt}{suffix}: "
        raw = getpass(full_prompt) if is_password else input(full_prompt)
        raw = raw.strip()
        if not raw:
            if default is not None:
                return default
            if allow_empty:
                return ""
            print("âŒ è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
            continue
        return raw


def interactive_setup() -> dict:
    """äº¤äº’å¼å‘å¯¼ï¼Œè¿”å›ç”¨äºåˆå§‹åŒ– DatabaseMigrator çš„å‚æ•°å­—å…¸"""
    print("=" * 60)
    print("ğŸŒŸ æ•°æ®åº“è¿ç§»å‘å¯¼")
    print("åªéœ€å›ç­”å‡ ä¸ªé—®é¢˜ï¼Œæˆ‘ä¼šå¸®ä½ æ„é€ è¿ç§»é…ç½®ã€‚")
    print("=" * 60)

    db_types = ["sqlite", "mysql", "postgresql"]

    # é€‰æ‹©æºæ•°æ®åº“
    source_type = _ask_choice("è¯·é€‰æ‹©ã€æºæ•°æ®åº“ç±»å‹ã€‘:", db_types, default_index=0)

    # é€‰æ‹©ç›®æ ‡æ•°æ®åº“ï¼ˆä¸èƒ½ä¸æºç›¸åŒï¼‰
    while True:
        default_idx = 2 if len(db_types) >= 3 else 0
        target_type = _ask_choice("è¯·é€‰æ‹©ã€ç›®æ ‡æ•°æ®åº“ç±»å‹ã€‘:", db_types, default_index=default_idx)
        if target_type != source_type:
            break
        print("âŒ ç›®æ ‡æ•°æ®åº“ä¸èƒ½å’Œæºæ•°æ®åº“ç›¸åŒï¼Œè¯·é‡æ–°é€‰æ‹©ã€‚")

    # æ‰¹é‡å¤§å°
    batch_size = _ask_int("è¯·è¾“å…¥æ‰¹é‡å¤§å° batch-size", default=1000)

    # æºæ•°æ®åº“é…ç½®ï¼šé»˜è®¤ä½¿ç”¨ bot_config.toml
    print()
    print("æºæ•°æ®åº“é…ç½®ï¼š")
    print("  é»˜è®¤ä¼šä» config/bot_config.toml ä¸­è¯»å–å¯¹åº”é…ç½®ã€‚")
    use_default_source = input("æ˜¯å¦ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ã€æºæ•°æ®åº“ã€‘é…ç½®? [Y/n]: ").strip().lower()
    if use_default_source in ("", "y", "yes"):
        source_config = None  # è®© DatabaseMigrator è‡ªå·±å»è¯»é…ç½®
    else:
        # ç®€å•äº¤äº’å¼é…ç½®æºæ•°æ®åº“
        print("è¯·æ‰‹åŠ¨è¾“å…¥æºæ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼š")
        if source_type == "sqlite":
            source_path = _ask_str("æº SQLite æ–‡ä»¶è·¯å¾„", default="data/MaiBot.db")
            source_config = {"path": source_path}
        else:
            port_default = 3306 if source_type == "mysql" else 5432
            user_default = "root" if source_type == "mysql" else "postgres"
            host = _ask_str("æºæ•°æ®åº“ host", default="localhost")
            port = _ask_int("æºæ•°æ®åº“ port", default=port_default)
            database = _ask_str("æºæ•°æ®åº“å", default="maibot")
            user = _ask_str("æºæ•°æ®åº“ç”¨æˆ·å", default=user_default)
            password = _ask_str("æºæ•°æ®åº“å¯†ç ï¼ˆè¾“å…¥æ—¶ä¸å›æ˜¾ï¼‰", default="", is_password=True)
            source_config = {
                "host": host,
                "port": port,
                "database": database,
                "user": user,
                "password": password,
            }
            if source_type == "mysql":
                source_config["charset"] = _ask_str("æºæ•°æ®åº“å­—ç¬¦é›†", default="utf8mb4")
            elif source_type == "postgresql":
                source_config["schema"] = _ask_str("æºæ•°æ®åº“ schema", default="public")

    # ç›®æ ‡æ•°æ®åº“é…ç½®ï¼ˆå¿…é¡»æ˜¾å¼ç¡®è®¤ï¼‰
    print()
    print("ç›®æ ‡æ•°æ®åº“é…ç½®ï¼š")
    if target_type == "sqlite":
        target_path = _ask_str(
            "ç›®æ ‡ SQLite æ–‡ä»¶è·¯å¾„ï¼ˆè‹¥ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»ºï¼‰",
            default="data/MaiBot.db",
        )
        target_config = {"path": target_path}
    else:
        port_default = 3306 if target_type == "mysql" else 5432
        user_default = "root" if target_type == "mysql" else "postgres"
        host = _ask_str("ç›®æ ‡æ•°æ®åº“ host", default="localhost")
        port = _ask_int("ç›®æ ‡æ•°æ®åº“ port", default=port_default)
        database = _ask_str("ç›®æ ‡æ•°æ®åº“å", default="maibot")
        user = _ask_str("ç›®æ ‡æ•°æ®åº“ç”¨æˆ·å", default=user_default)
        password = _ask_str("ç›®æ ‡æ•°æ®åº“å¯†ç ï¼ˆè¾“å…¥æ—¶ä¸å›æ˜¾ï¼‰", default="", is_password=True)

        target_config = {
            "host": host,
            "port": port,
            "database": database,
            "user": user,
            "password": password,
        }
        if target_type == "mysql":
            target_config["charset"] = _ask_str("ç›®æ ‡æ•°æ®åº“å­—ç¬¦é›†", default="utf8mb4")
        elif target_type == "postgresql":
            target_config["schema"] = _ask_str("ç›®æ ‡æ•°æ®åº“ schema", default="public")

    print()
    print("=" * 60)
    print("è¿ç§»é…ç½®ç¡®è®¤ï¼š")
    print(f"  æºæ•°æ®åº“ç±»å‹: {source_type}")
    print(f"  ç›®æ ‡æ•°æ®åº“ç±»å‹: {target_type}")
    print(f"  æ‰¹é‡å¤§å°: {batch_size}")
    print("âš ï¸ è¯·ç¡®è®¤ç›®æ ‡æ•°æ®åº“ä¸ºç©ºæˆ–å¯ä»¥è¢«è¦†ç›–ï¼Œå¹¶ä¸”å·²å¤‡ä»½æºæ•°æ®åº“ã€‚")
    confirm = input("æ˜¯å¦å¼€å§‹è¿ç§»ï¼Ÿ[Y/n]: ").strip().lower()
    if confirm not in ("", "y", "yes"):
        print("å·²å–æ¶ˆè¿ç§»ã€‚")
        sys.exit(0)

    return {
        "source_type": source_type,
        "target_type": target_type,
        "batch_size": batch_size,
        "source_config": source_config,
        "target_config": target_config,
    }


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # å¦‚æœæ²¡æœ‰ä»»ä½•å‚æ•°ï¼Œæˆ–è€…æ˜¾å¼æŒ‡å®š --interactiveï¼Œåˆ™è¿›å…¥äº¤äº’æ¨¡å¼
    if args.interactive or len(sys.argv) == 1:
        params = interactive_setup()
        try:
            migrator = DatabaseMigrator(**params)
            stats = migrator.run()
            if stats["errors"]:
                sys.exit(1)
            return
        except KeyboardInterrupt:
            print("\nè¿ç§»è¢«ç”¨æˆ·ä¸­æ–­")
            sys.exit(130)
        except Exception as e:
            print(f"è¿ç§»å¤±è´¥: {e}")
            sys.exit(1)

    # éäº¤äº’æ¨¡å¼ï¼šä¿æŒåŸæœ‰è¡Œä¸ºï¼Œä½†å¦‚æœæ²¡ç»™ source/targetï¼Œå°±æç¤ºé”™è¯¯
    if not args.source or not args.target:
        print("é”™è¯¯: éäº¤äº’æ¨¡å¼ä¸‹å¿…é¡»æŒ‡å®š --source å’Œ --targetã€‚")
        print("ä½ ä¹Ÿå¯ä»¥ç›´æ¥è¿è¡Œè„šæœ¬æˆ–æ·»åŠ  --interactive ä½¿ç”¨äº¤äº’å¼å‘å¯¼ã€‚")
        sys.exit(2)

    # æ„å»ºé…ç½®
    source_config = build_config_from_args(args, "source", args.source)
    target_config = build_config_from_args(args, "target", args.target)

    # éªŒè¯ç›®æ ‡é…ç½®
    if target_config is None:
        if args.target == "sqlite":
            if not args.target_path:
                print("é”™è¯¯: ç›®æ ‡æ•°æ®åº“ä¸º SQLite æ—¶ï¼Œå¿…é¡»æŒ‡å®š --target-pathï¼ˆæˆ–ä½¿ç”¨äº¤äº’æ¨¡å¼ï¼‰")
                sys.exit(1)
            target_config = {"path": args.target_path}
        else:
            if not args.target_host:
                print(f"é”™è¯¯: ç›®æ ‡æ•°æ®åº“ä¸º {args.target} æ—¶ï¼Œå¿…é¡»æŒ‡å®š --target-hostï¼ˆæˆ–ä½¿ç”¨äº¤äº’æ¨¡å¼ï¼‰")
                sys.exit(1)

    try:
        migrator = DatabaseMigrator(
            source_type=args.source,
            target_type=args.target,
            batch_size=args.batch_size,
            source_config=source_config,
            target_config=target_config,
        )

        stats = migrator.run()

        # å¦‚æœæœ‰é”™è¯¯ï¼Œè¿”å›éé›¶é€€å‡ºç 
        if stats["errors"]:
            sys.exit(1)

    except KeyboardInterrupt:
        print("\nè¿ç§»è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"è¿ç§»å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
