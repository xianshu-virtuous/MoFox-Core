#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘åˆ†æå™¨æ¨¡å— - ä¼˜åŒ–ç‰ˆæœ¬
æ”¯æŒå¤šç§åˆ†ææ¨¡å¼ï¼šæ‰¹å¤„ç†ã€é€å¸§ã€è‡ªåŠ¨é€‰æ‹©
"""

import os
import cv2
import tempfile
import asyncio
import base64
import hashlib
import time
import numpy as np
from PIL import Image
from pathlib import Path
from typing import List, Tuple, Optional, Dict
import io
from concurrent.futures import ThreadPoolExecutor
from functools import partial
import numpy as np

from src.llm_models.utils_model import LLMRequest
from src.config.config import global_config, model_config
from src.common.logger import get_logger
from src.common.database.sqlalchemy_models import get_db_session, Videos

logger = get_logger("utils_video")

# å…¨å±€æ­£åœ¨å¤„ç†çš„è§†é¢‘å“ˆå¸Œé›†åˆï¼Œç”¨äºé˜²æ­¢é‡å¤å¤„ç†
processing_videos = set()
processing_lock = asyncio.Lock()
# ä¸ºæ¯ä¸ªè§†é¢‘hashåˆ›å»ºç‹¬ç«‹çš„é”å’Œäº‹ä»¶
video_locks = {}
video_events = {}
video_lock_manager = asyncio.Lock()


def _extract_frames_worker(video_path: str,
                           max_frames: int, 
                           frame_quality: int,
                           max_image_size: int,
                           frame_extraction_mode: str,
                           frame_interval_seconds: Optional[float]) -> List[Tuple[str, float]]:
    """çº¿ç¨‹æ± ä¸­æå–è§†é¢‘å¸§çš„å·¥ä½œå‡½æ•°"""
    frames = []
    try:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        if frame_extraction_mode == "time_interval":
            # æ–°æ¨¡å¼ï¼šæŒ‰æ—¶é—´é—´éš”æŠ½å¸§
            time_interval = frame_interval_seconds
            next_frame_time = 0.0
            extracted_count = 0  # åˆå§‹åŒ–æå–å¸§è®¡æ•°å™¨
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0
                
                if current_time >= next_frame_time:
                    # è½¬æ¢ä¸ºPILå›¾åƒå¹¶å‹ç¼©
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    pil_image = Image.fromarray(frame_rgb)
                    
                    # è°ƒæ•´å›¾åƒå¤§å°
                    if max(pil_image.size) > max_image_size:
                        ratio = max_image_size / max(pil_image.size)
                        new_size = tuple(int(dim * ratio) for dim in pil_image.size)
                        pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
                    
                    # è½¬æ¢ä¸ºbase64
                    buffer = io.BytesIO()
                    pil_image.save(buffer, format='JPEG', quality=frame_quality)
                    frame_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                    
                    frames.append((frame_base64, current_time))
                    extracted_count += 1
                    
                    # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ä½¿ç”¨loggerï¼Œå› ä¸ºåœ¨çº¿ç¨‹æ± ä¸­
                    # logger.debug(f"æå–ç¬¬{extracted_count}å¸§ (æ—¶é—´: {current_time:.2f}s)")
                    
                    next_frame_time += time_interval
        else:
            # ä½¿ç”¨numpyä¼˜åŒ–å¸§é—´éš”è®¡ç®—
            if duration > 0:
                frame_interval = max(1, int(duration / max_frames * fps))
            else:
                frame_interval = 30  # é»˜è®¤é—´éš”
                
            # ä½¿ç”¨numpyè®¡ç®—ç›®æ ‡å¸§ä½ç½®
            target_frames = np.arange(0, min(max_frames, total_frames // frame_interval + 1)) * frame_interval
            target_frames = target_frames[target_frames < total_frames].astype(int)
            
            for target_frame in target_frames:
                # è·³è½¬åˆ°ç›®æ ‡å¸§
                cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
                ret, frame = cap.read()
                if not ret:
                    continue
                    
                # ä½¿ç”¨numpyä¼˜åŒ–å›¾åƒå¤„ç†
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä½¿ç”¨numpyè¿›è¡Œå°ºå¯¸è®¡ç®—
                height, width = frame_rgb.shape[:2]
                max_dim = max(height, width)
                
                if max_dim > max_image_size:
                    # ä½¿ç”¨numpyè®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                    ratio = max_image_size / max_dim
                    new_width = int(width * ratio)
                    new_height = int(height * ratio)
                    
                    # ä½¿ç”¨opencvè¿›è¡Œé«˜æ•ˆç¼©æ”¾
                    frame_resized = cv2.resize(frame_rgb, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)
                    pil_image = Image.fromarray(frame_resized)
                else:
                    pil_image = Image.fromarray(frame_rgb)
                
                # è½¬æ¢ä¸ºbase64
                buffer = io.BytesIO()
                pil_image.save(buffer, format='JPEG', quality=frame_quality)
                frame_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                
                # è®¡ç®—æ—¶é—´æˆ³
                timestamp = target_frame / fps if fps > 0 else 0
                frames.append((frame_base64, timestamp))
        
        cap.release()
        return frames
        
    except Exception as e:
        # è¿”å›é”™è¯¯ä¿¡æ¯
        return [("ERROR", str(e))]


class VideoAnalyzer:
    """ä¼˜åŒ–çš„è§†é¢‘åˆ†æå™¨ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–è§†é¢‘åˆ†æå™¨"""
        # ä½¿ç”¨ä¸“ç”¨çš„è§†é¢‘åˆ†æé…ç½®
        try:
            self.video_llm = LLMRequest(
                model_set=model_config.model_task_config.video_analysis,
                request_type="video_analysis"
            )
            logger.info("âœ… ä½¿ç”¨video_analysisæ¨¡å‹é…ç½®")
        except (AttributeError, KeyError) as e:
            # å¦‚æœvideo_analysisä¸å­˜åœ¨ï¼Œä½¿ç”¨vlmé…ç½®
            self.video_llm = LLMRequest(
                model_set=model_config.model_task_config.vlm,
                request_type="vlm"
            )
            logger.warning(f"video_analysisé…ç½®ä¸å¯ç”¨({e})ï¼Œå›é€€ä½¿ç”¨vlmé…ç½®")
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–å‚æ•°ï¼Œå¦‚æœé…ç½®ä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
        config = global_config.video_analysis

        # ä½¿ç”¨ getattr ç»Ÿä¸€è·å–é…ç½®å‚æ•°ï¼Œå¦‚æœé…ç½®ä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
        self.max_frames = getattr(config, 'max_frames', 6)
        self.frame_quality = getattr(config, 'frame_quality', 85)
        self.max_image_size = getattr(config, 'max_image_size', 600)
        self.enable_frame_timing = getattr(config, 'enable_frame_timing', True)
        self.batch_analysis_prompt = getattr(config, 'batch_analysis_prompt', """è¯·åˆ†æè¿™ä¸ªè§†é¢‘çš„å†…å®¹ã€‚è¿™äº›å›¾ç‰‡æ˜¯ä»è§†é¢‘ä¸­æŒ‰æ—¶é—´é¡ºåºæå–çš„å…³é”®å¸§ã€‚

è¯·æä¾›è¯¦ç»†çš„åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. è§†é¢‘çš„æ•´ä½“å†…å®¹å’Œä¸»é¢˜
2. ä¸»è¦äººç‰©ã€å¯¹è±¡å’Œåœºæ™¯æè¿°
3. åŠ¨ä½œã€æƒ…èŠ‚å’Œæ—¶é—´çº¿å‘å±•
4. è§†è§‰é£æ ¼å’Œè‰ºæœ¯ç‰¹ç‚¹
5. æ•´ä½“æ°›å›´å’Œæƒ…æ„Ÿè¡¨è¾¾
6. ä»»ä½•ç‰¹æ®Šçš„è§†è§‰æ•ˆæœæˆ–æ–‡å­—å†…å®¹

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œåˆ†æè¦è¯¦ç»†å‡†ç¡®ã€‚""")
        
        # æ–°å¢çš„çº¿ç¨‹æ± é…ç½®
        self.use_multiprocessing = getattr(config, 'use_multiprocessing', True)
        self.max_workers = getattr(config, 'max_workers', 2)
        self.frame_extraction_mode = getattr(config, 'frame_extraction_mode', 'fixed_number')
        self.frame_interval_seconds = getattr(config, 'frame_interval_seconds', 2.0)
        
        # å°†é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å¼æ˜ å°„åˆ°å†…éƒ¨ä½¿ç”¨çš„æ¨¡å¼åç§°
        config_mode = getattr(config, 'analysis_mode', 'auto')
        if config_mode == "batch_frames":
            self.analysis_mode = "batch"
        elif config_mode == "frame_by_frame":
            self.analysis_mode = "sequential"
        elif config_mode == "auto":
            self.analysis_mode = "auto"
        else:
            logger.warning(f"æ— æ•ˆçš„åˆ†ææ¨¡å¼: {config_mode}ï¼Œä½¿ç”¨é»˜è®¤çš„autoæ¨¡å¼")
            self.analysis_mode = "auto"
            
        self.frame_analysis_delay = 0.3  # APIè°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰
        self.frame_interval = 1.0  # æŠ½å¸§æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
        self.batch_size = 3  # æ‰¹å¤„ç†æ—¶æ¯æ‰¹å¤„ç†çš„å¸§æ•°
        self.timeout = 60.0  # åˆ†æè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
        if config:
            logger.info("âœ… ä»é…ç½®æ–‡ä»¶è¯»å–è§†é¢‘åˆ†æå‚æ•°")
        else:
            logger.warning("é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘video_analysisé…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        
        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ã€‚è¯·ä»”ç»†è§‚å¯Ÿç”¨æˆ·æä¾›çš„è§†é¢‘å…³é”®å¸§ï¼Œè¯¦ç»†æè¿°è§†é¢‘å†…å®¹ã€‚"
        
        logger.info(f"âœ… è§†é¢‘åˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼Œåˆ†ææ¨¡å¼: {self.analysis_mode}, çº¿ç¨‹æ± : {self.use_multiprocessing}")

    def _calculate_video_hash(self, video_data: bytes) -> str:
        """è®¡ç®—è§†é¢‘æ–‡ä»¶çš„hashå€¼"""
        hash_obj = hashlib.sha256()
        hash_obj.update(video_data)
        return hash_obj.hexdigest()
    
    def _check_video_exists(self, video_hash: str) -> Optional[Videos]:
        """æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²ç»åˆ†æè¿‡"""
        try:
            with get_db_session() as session:
                # æ˜ç¡®åˆ·æ–°ä¼šè¯ä»¥ç¡®ä¿çœ‹åˆ°å…¶ä»–äº‹åŠ¡çš„æœ€æ–°æäº¤
                session.expire_all()
                return session.query(Videos).filter(Videos.video_hash == video_hash).first()
        except Exception as e:
            logger.warning(f"æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: {e}")
            return None
    
    def _store_video_result(self, video_hash: str, description: str, metadata: Optional[Dict] = None) -> Optional[Videos]:
        """å­˜å‚¨è§†é¢‘åˆ†æç»“æœåˆ°æ•°æ®åº“"""
        try:
            with get_db_session() as session:
                # åªæ ¹æ®video_hashæŸ¥æ‰¾
                existing_video = session.query(Videos).filter(
                    Videos.video_hash == video_hash
                ).first()
                
                if existing_video:
                    # å¦‚æœå·²å­˜åœ¨ï¼Œæ›´æ–°æè¿°å’Œè®¡æ•°
                    existing_video.description = description
                    existing_video.count += 1
                    existing_video.timestamp = time.time()
                    if metadata:
                        existing_video.duration = metadata.get('duration')
                        existing_video.frame_count = metadata.get('frame_count')
                        existing_video.fps = metadata.get('fps')
                        existing_video.resolution = metadata.get('resolution')
                        existing_video.file_size = metadata.get('file_size')
                    session.commit()
                    session.refresh(existing_video)
                    logger.info(f"âœ… æ›´æ–°å·²å­˜åœ¨çš„è§†é¢‘è®°å½•ï¼Œhash: {video_hash[:16]}..., count: {existing_video.count}")
                    return existing_video
                else:
                    video_record = Videos(
                        video_hash=video_hash,
                        description=description,
                        timestamp=time.time(),
                        count=1
                    )
                    if metadata:
                        video_record.duration = metadata.get('duration')
                        video_record.frame_count = metadata.get('frame_count')
                        video_record.fps = metadata.get('fps')
                        video_record.resolution = metadata.get('resolution')
                        video_record.file_size = metadata.get('file_size')
                    
                    session.add(video_record)
                    session.commit()
                    session.refresh(video_record)
                    logger.info(f"âœ… æ–°è§†é¢‘åˆ†æç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œhash: {video_hash[:16]}...")
                    return video_record
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨è§†é¢‘åˆ†æç»“æœæ—¶å‡ºé”™: {e}")
            return None

    def set_analysis_mode(self, mode: str):
        """è®¾ç½®åˆ†ææ¨¡å¼"""
        if mode in ["batch", "sequential", "auto"]:
            self.analysis_mode = mode
            # logger.info(f"åˆ†ææ¨¡å¼å·²è®¾ç½®ä¸º: {mode}")
        else:
            logger.warning(f"æ— æ•ˆçš„åˆ†ææ¨¡å¼: {mode}")

    async def extract_frames(self, video_path: str) -> List[Tuple[str, float]]:
        """æå–è§†é¢‘å¸§ - æ”¯æŒå¤šè¿›ç¨‹å’Œå•çº¿ç¨‹æ¨¡å¼"""
        # å…ˆè·å–è§†é¢‘ä¿¡æ¯
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        cap.release()
        
        logger.info(f"è§†é¢‘ä¿¡æ¯: {total_frames}å¸§, {fps:.2f}FPS, {duration:.2f}ç§’")
        
        # ä¼°ç®—æå–å¸§æ•°
        if duration > 0:
            frame_interval = max(1, int(duration / self.max_frames * fps))
            estimated_frames = min(self.max_frames, total_frames // frame_interval + 1)
        else:
            estimated_frames = self.max_frames
            
        logger.info(f"è®¡ç®—å¾—å‡ºå¸§é—´éš”: {frame_interval} (å°†æå–çº¦{estimated_frames}å¸§)")
        
        # æ ¹æ®é…ç½®é€‰æ‹©å¤„ç†æ–¹å¼
        if self.use_multiprocessing:
            return await self._extract_frames_multiprocess(video_path)
        else:
            return await self._extract_frames_fallback(video_path)

    async def _extract_frames_multiprocess(self, video_path: str) -> List[Tuple[str, float]]:
        """çº¿ç¨‹æ± ç‰ˆæœ¬çš„å¸§æå–"""
        loop = asyncio.get_event_loop()
        
        try:
            logger.info("ğŸ”„ å¯åŠ¨çº¿ç¨‹æ± å¸§æå–...")
            # ä½¿ç”¨çº¿ç¨‹æ± ï¼Œé¿å…è¿›ç¨‹é—´çš„å¯¼å…¥é—®é¢˜
            with ThreadPoolExecutor(max_workers=1) as executor:
                frames = await loop.run_in_executor(
                    executor,
                    _extract_frames_worker,
                    video_path,
                    self.max_frames,
                    self.frame_quality,
                    self.max_image_size,
                    self.frame_extraction_mode,
                    self.frame_interval_seconds
                )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if frames and frames[0][0] == "ERROR":
                logger.error(f"çº¿ç¨‹æ± å¸§æå–å¤±è´¥: {frames[0][1]}")
                # é™çº§åˆ°å•çº¿ç¨‹æ¨¡å¼
                logger.info("ğŸ”„ é™çº§åˆ°å•çº¿ç¨‹æ¨¡å¼...")
                return await self._extract_frames_fallback(video_path)
            
            logger.info(f"âœ… æˆåŠŸæå–{len(frames)}å¸§ (çº¿ç¨‹æ± æ¨¡å¼)")
            return frames
            
        except Exception as e:
            logger.error(f"çº¿ç¨‹æ± å¸§æå–å¤±è´¥: {e}")
            # é™çº§åˆ°åŸå§‹æ–¹æ³•
            logger.info("ğŸ”„ é™çº§åˆ°å•çº¿ç¨‹æ¨¡å¼...")
            return await self._extract_frames_fallback(video_path)

    async def _extract_frames_fallback(self, video_path: str) -> List[Tuple[str, float]]:
        """å¸§æå–çš„é™çº§æ–¹æ³• - åŸå§‹å¼‚æ­¥ç‰ˆæœ¬"""
        frames = []
        extracted_count = 0
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        logger.info(f"è§†é¢‘ä¿¡æ¯: {total_frames}å¸§, {fps:.2f}FPS, {duration:.2f}ç§’")
        
        # ä½¿ç”¨numpyä¼˜åŒ–å¸§é—´éš”è®¡ç®—
        if duration > 0:
            frame_interval = max(1, int(duration / self.max_frames * fps))
        else:
            frame_interval = 30  # é»˜è®¤é—´éš”
            
        logger.info(f"è®¡ç®—å¾—å‡ºå¸§é—´éš”: {frame_interval} (å°†æå–çº¦{min(self.max_frames, total_frames // frame_interval + 1)}å¸§)")

        # ä½¿ç”¨numpyè®¡ç®—ç›®æ ‡å¸§ä½ç½®
        target_frames = np.arange(0, min(self.max_frames, total_frames // frame_interval + 1)) * frame_interval
        target_frames = target_frames[target_frames < total_frames].astype(int)
        
        extracted_count = 0
        
        for target_frame in target_frames:
            # è·³è½¬åˆ°ç›®æ ‡å¸§
            cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
            ret, frame = cap.read()
            if not ret:
                continue
                
            # ä½¿ç”¨numpyä¼˜åŒ–å›¾åƒå¤„ç†
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä½¿ç”¨numpyè¿›è¡Œå°ºå¯¸è®¡ç®—
            height, width = frame_rgb.shape[:2]
            max_dim = max(height, width)
            
            if max_dim > self.max_image_size:
                # ä½¿ç”¨numpyè®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                ratio = self.max_image_size / max_dim
                new_width = int(width * ratio)
                new_height = int(height * ratio)
                
                # ä½¿ç”¨opencvè¿›è¡Œé«˜æ•ˆç¼©æ”¾
                frame_resized = cv2.resize(frame_rgb, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)
                pil_image = Image.fromarray(frame_resized)
            else:
                pil_image = Image.fromarray(frame_rgb)
            
            # è½¬æ¢ä¸ºbase64
            buffer = io.BytesIO()
            pil_image.save(buffer, format='JPEG', quality=self.frame_quality)
            frame_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            # è®¡ç®—æ—¶é—´æˆ³
            timestamp = target_frame / fps if fps > 0 else 0
            frames.append((frame_base64, timestamp))
            extracted_count += 1
            
            logger.debug(f"æå–ç¬¬{extracted_count}å¸§ (æ—¶é—´: {timestamp:.2f}s, å¸§å·: {target_frame})")
            
            # æ¯æå–ä¸€å¸§è®©æ­¥ä¸€æ¬¡
            await asyncio.sleep(0.001)
            
        cap.release()
        logger.info(f"âœ… æˆåŠŸæå–{len(frames)}å¸§")
        return frames

    async def analyze_frames_batch(self, frames: List[Tuple[str, float]], user_question: str = None) -> str:
        """æ‰¹é‡åˆ†ææ‰€æœ‰å¸§"""
        logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ{len(frames)}å¸§")
        
        if not frames:
            return "âŒ æ²¡æœ‰å¯åˆ†æçš„å¸§"
        
        # æ„å»ºæç¤ºè¯
        prompt = self.batch_analysis_prompt
        
        if user_question:
            prompt += f"\n\nç”¨æˆ·é—®é¢˜: {user_question}"
        
        # æ·»åŠ å¸§ä¿¡æ¯åˆ°æç¤ºè¯
        frame_info = []
        for i, (_frame_base64, timestamp) in enumerate(frames):
            if self.enable_frame_timing:
                frame_info.append(f"ç¬¬{i+1}å¸§ (æ—¶é—´: {timestamp:.2f}s)")
            else:
                frame_info.append(f"ç¬¬{i+1}å¸§")
        
        prompt += f"\n\nè§†é¢‘åŒ…å«{len(frames)}å¸§å›¾åƒï¼š{', '.join(frame_info)}"
        prompt += "\n\nè¯·åŸºäºæ‰€æœ‰æä¾›çš„å¸§å›¾åƒè¿›è¡Œç»¼åˆåˆ†æï¼Œå…³æ³¨å¹¶æè¿°è§†é¢‘çš„å®Œæ•´å†…å®¹å’Œæ•…äº‹å‘å±•ã€‚"
        
        try:
            # å°è¯•ä½¿ç”¨å¤šå›¾ç‰‡åˆ†æ
            response = await self._analyze_multiple_frames(frames, prompt)
            logger.info("âœ… è§†é¢‘è¯†åˆ«å®Œæˆ")
            return response
            
        except Exception as e:
            logger.error(f"âŒ è§†é¢‘è¯†åˆ«å¤±è´¥: {e}")
            # é™çº§åˆ°å•å¸§åˆ†æ
            logger.warning("é™çº§åˆ°å•å¸§åˆ†ææ¨¡å¼")
            try:
                frame_base64, timestamp = frames[0]
                fallback_prompt = prompt + f"\n\næ³¨æ„ï¼šç”±äºæŠ€æœ¯é™åˆ¶ï¼Œå½“å‰ä»…æ˜¾ç¤ºç¬¬1å¸§ (æ—¶é—´: {timestamp:.2f}s)ï¼Œè§†é¢‘å…±æœ‰{len(frames)}å¸§ã€‚è¯·åŸºäºè¿™ä¸€å¸§è¿›è¡Œåˆ†æã€‚"
                
                response, _ = await self.video_llm.generate_response_for_image(
                    prompt=fallback_prompt,
                    image_base64=frame_base64,
                    image_format="jpeg"
                )
                logger.info("âœ… é™çº§çš„å•å¸§åˆ†æå®Œæˆ")
                return response
            except Exception as fallback_e:
                logger.error(f"âŒ é™çº§åˆ†æä¹Ÿå¤±è´¥: {fallback_e}")
                raise

    async def _analyze_multiple_frames(self, frames: List[Tuple[str, float]], prompt: str) -> str:
        """ä½¿ç”¨å¤šå›¾ç‰‡åˆ†ææ–¹æ³•"""
        logger.info(f"å¼€å§‹æ„å»ºåŒ…å«{len(frames)}å¸§çš„åˆ†æè¯·æ±‚")
        
        # å¯¼å…¥MessageBuilderç”¨äºæ„å»ºå¤šå›¾ç‰‡æ¶ˆæ¯
        from src.llm_models.payload_content.message import MessageBuilder, RoleType
        from src.llm_models.utils_model import RequestType
        
        # æ„å»ºåŒ…å«å¤šå¼ å›¾ç‰‡çš„æ¶ˆæ¯
        message_builder = MessageBuilder().set_role(RoleType.User).add_text_content(prompt)
        
        # æ·»åŠ æ‰€æœ‰å¸§å›¾åƒ
        for _i, (frame_base64, _timestamp) in enumerate(frames):
            message_builder.add_image_content("jpeg", frame_base64)
            # logger.info(f"å·²æ·»åŠ ç¬¬{i+1}å¸§åˆ°åˆ†æè¯·æ±‚ (æ—¶é—´: {timestamp:.2f}s, å›¾ç‰‡å¤§å°: {len(frame_base64)} chars)")
        
        message = message_builder.build()
        # logger.info(f"âœ… å¤šå¸§æ¶ˆæ¯æ„å»ºå®Œæˆï¼ŒåŒ…å«{len(frames)}å¼ å›¾ç‰‡")
        
        # è·å–æ¨¡å‹ä¿¡æ¯å’Œå®¢æˆ·ç«¯
        model_info, api_provider, client = self.video_llm._select_model()
        # logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_info.name} è¿›è¡Œå¤šå¸§åˆ†æ")

        # ç›´æ¥æ‰§è¡Œå¤šå›¾ç‰‡è¯·æ±‚
        api_response = await self.video_llm._execute_request(
            api_provider=api_provider,
            client=client,
            request_type=RequestType.RESPONSE,
            model_info=model_info,
            message_list=[message],
            temperature=None,
            max_tokens=None
        )
        
        logger.info(f"è§†é¢‘è¯†åˆ«å®Œæˆï¼Œå“åº”é•¿åº¦: {len(api_response.content or '')} ")
        return api_response.content or "âŒ æœªè·å¾—å“åº”å†…å®¹"

    async def analyze_frames_sequential(self, frames: List[Tuple[str, float]], user_question: str = None) -> str:
        """é€å¸§åˆ†æå¹¶æ±‡æ€»"""
        logger.info(f"å¼€å§‹é€å¸§åˆ†æ{len(frames)}å¸§")
        
        frame_analyses = []
        
        for i, (frame_base64, timestamp) in enumerate(frames):
            try:
                prompt = f"è¯·åˆ†æè¿™ä¸ªè§†é¢‘çš„ç¬¬{i+1}å¸§"
                if self.enable_frame_timing:
                    prompt += f" (æ—¶é—´: {timestamp:.2f}s)"
                prompt += "ã€‚æè¿°ä½ çœ‹åˆ°çš„å†…å®¹ï¼ŒåŒ…æ‹¬äººç‰©ã€åŠ¨ä½œã€åœºæ™¯ã€æ–‡å­—ç­‰ã€‚"
                
                if user_question:
                    prompt += f"\nç‰¹åˆ«å…³æ³¨: {user_question}"
                
                response, _ = await self.video_llm.generate_response_for_image(
                    prompt=prompt,
                    image_base64=frame_base64,
                    image_format="jpeg"
                )
                
                frame_analyses.append(f"ç¬¬{i+1}å¸§ ({timestamp:.2f}s): {response}")
                logger.debug(f"âœ… ç¬¬{i+1}å¸§åˆ†æå®Œæˆ")
                
                # APIè°ƒç”¨é—´éš”
                if i < len(frames) - 1:
                    await asyncio.sleep(self.frame_analysis_delay)
                    
            except Exception as e:
                logger.error(f"âŒ ç¬¬{i+1}å¸§åˆ†æå¤±è´¥: {e}")
                frame_analyses.append(f"ç¬¬{i+1}å¸§: åˆ†æå¤±è´¥ - {e}")
        
        # ç”Ÿæˆæ±‡æ€»
        logger.info("å¼€å§‹ç”Ÿæˆæ±‡æ€»åˆ†æ")
        summary_prompt = f"""åŸºäºä»¥ä¸‹å„å¸§çš„åˆ†æç»“æœï¼Œè¯·æä¾›ä¸€ä¸ªå®Œæ•´çš„è§†é¢‘å†…å®¹æ€»ç»“ï¼š

{chr(10).join(frame_analyses)}

è¯·ç»¼åˆæ‰€æœ‰å¸§çš„ä¿¡æ¯ï¼Œæè¿°è§†é¢‘çš„æ•´ä½“å†…å®¹ã€æ•…äº‹çº¿ã€ä¸»è¦å…ƒç´ å’Œç‰¹ç‚¹ã€‚"""

        if user_question:
            summary_prompt += f"\nç‰¹åˆ«å›ç­”ç”¨æˆ·çš„é—®é¢˜: {user_question}"
        
        try:
            # ä½¿ç”¨æœ€åä¸€å¸§è¿›è¡Œæ±‡æ€»åˆ†æ
            if frames:
                last_frame_base64, _ = frames[-1]
                summary, _ = await self.video_llm.generate_response_for_image(
                    prompt=summary_prompt,
                    image_base64=last_frame_base64,
                    image_format="jpeg"
                )
                logger.info("âœ… é€å¸§åˆ†æå’Œæ±‡æ€»å®Œæˆ")
                return summary
            else:
                return "âŒ æ²¡æœ‰å¯ç”¨äºæ±‡æ€»çš„å¸§"
        except Exception as e:
            logger.error(f"âŒ æ±‡æ€»åˆ†æå¤±è´¥: {e}")
            # å¦‚æœæ±‡æ€»å¤±è´¥ï¼Œè¿”å›å„å¸§åˆ†æç»“æœ
            return f"è§†é¢‘é€å¸§åˆ†æç»“æœï¼š\n\n{chr(10).join(frame_analyses)}"

    async def analyze_video(self, video_path: str, user_question: str = None) -> str:
        """åˆ†æè§†é¢‘çš„ä¸»è¦æ–¹æ³•"""
        try:
            logger.info(f"å¼€å§‹åˆ†æè§†é¢‘: {os.path.basename(video_path)}")
            
            # æå–å¸§
            frames = await self.extract_frames(video_path)
            if not frames:
                return "âŒ æ— æ³•ä»è§†é¢‘ä¸­æå–æœ‰æ•ˆå¸§"
            
            # æ ¹æ®æ¨¡å¼é€‰æ‹©åˆ†ææ–¹æ³•
            if self.analysis_mode == "auto":
                # æ™ºèƒ½é€‰æ‹©ï¼šå°‘äºç­‰äº3å¸§ç”¨æ‰¹é‡ï¼Œå¦åˆ™ç”¨é€å¸§
                mode = "batch" if len(frames) <= 3 else "sequential"
                logger.info(f"è‡ªåŠ¨é€‰æ‹©åˆ†ææ¨¡å¼: {mode} (åŸºäº{len(frames)}å¸§)")
            else:
                mode = self.analysis_mode
            
            # æ‰§è¡Œåˆ†æ
            if mode == "batch":
                result = await self.analyze_frames_batch(frames, user_question)
            else:  # sequential
                result = await self.analyze_frames_sequential(frames, user_question)
            
            logger.info("âœ… è§†é¢‘åˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            error_msg = f"âŒ è§†é¢‘åˆ†æå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return error_msg

    async def analyze_video_from_bytes(self, video_bytes: bytes, filename: str = None, user_question: str = None, prompt: str = None) -> Dict[str, str]:
        """ä»å­—èŠ‚æ•°æ®åˆ†æè§†é¢‘
        
        Args:
            video_bytes: è§†é¢‘å­—èŠ‚æ•°æ®
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼Œä»…ç”¨äºæ—¥å¿—ï¼‰
            user_question: ç”¨æˆ·é—®é¢˜ï¼ˆæ—§å‚æ•°åï¼Œä¿æŒå…¼å®¹æ€§ï¼‰
            prompt: æç¤ºè¯ï¼ˆæ–°å‚æ•°åï¼Œä¸ç³»ç»Ÿè°ƒç”¨ä¿æŒä¸€è‡´ï¼‰
            
        Returns:
            Dict[str, str]: åŒ…å«åˆ†æç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ä¸º {"summary": "åˆ†æç»“æœ"}
        """
        video_hash = None
        video_event = None
        
        try:
            logger.info("å¼€å§‹ä»å­—èŠ‚æ•°æ®åˆ†æè§†é¢‘")
            
            # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä¼ å…¥äº†promptå‚æ•°ï¼Œä½¿ç”¨promptï¼›å¦åˆ™ä½¿ç”¨user_question
            question = prompt if prompt is not None else user_question
            
            # æ£€æŸ¥è§†é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
            if not video_bytes:
                return {"summary": "âŒ è§†é¢‘æ•°æ®ä¸ºç©º"}
            
            # è®¡ç®—è§†é¢‘hashå€¼
            video_hash = self._calculate_video_hash(video_bytes)
            logger.info(f"è§†é¢‘hash: {video_hash}")
            
            # æ”¹è¿›çš„å¹¶å‘æ§åˆ¶ï¼šä½¿ç”¨æ¯ä¸ªè§†é¢‘ç‹¬ç«‹çš„é”å’Œäº‹ä»¶
            async with video_lock_manager:
                if video_hash not in video_locks:
                    video_locks[video_hash] = asyncio.Lock()
                    video_events[video_hash] = asyncio.Event()
                
                video_lock = video_locks[video_hash]
                video_event = video_events[video_hash]
            
            # å°è¯•è·å–è¯¥è§†é¢‘çš„ä¸“ç”¨é”
            if video_lock.locked():
                logger.info(f"â³ ç›¸åŒè§†é¢‘æ­£åœ¨å¤„ç†ä¸­ï¼Œç­‰å¾…å¤„ç†å®Œæˆ... (hash: {video_hash[:16]}...)")
                try:
                    # ç­‰å¾…å¤„ç†å®Œæˆçš„äº‹ä»¶ä¿¡å·ï¼Œæœ€å¤šç­‰å¾…60ç§’
                    await asyncio.wait_for(video_event.wait(), timeout=60.0)
                    logger.info("âœ… ç­‰å¾…ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¤„ç†ç»“æœ")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœäº†
                    existing_video = self._check_video_exists(video_hash)
                    if existing_video:
                        logger.info(f"âœ… æ‰¾åˆ°äº†å¤„ç†ç»“æœï¼Œç›´æ¥è¿”å› (id: {existing_video.id})")
                        return {"summary": existing_video.description}
                    else:
                        logger.warning("âš ï¸ ç­‰å¾…å®Œæˆä½†æœªæ‰¾åˆ°ç»“æœï¼Œå¯èƒ½å¤„ç†å¤±è´¥")
                except asyncio.TimeoutError:
                    logger.warning("âš ï¸ ç­‰å¾…è¶…æ—¶(60ç§’)ï¼Œæ”¾å¼ƒç­‰å¾…")
            
            # è·å–é”å¼€å§‹å¤„ç†
            async with video_lock:
                logger.info(f"ğŸ”’ è·å¾—è§†é¢‘å¤„ç†é”ï¼Œå¼€å§‹å¤„ç† (hash: {video_hash[:16]}...)")
                
                # å†æ¬¡æ£€æŸ¥æ•°æ®åº“ï¼ˆå¯èƒ½åœ¨ç­‰å¾…æœŸé—´å·²ç»æœ‰ç»“æœäº†ï¼‰
                existing_video = self._check_video_exists(video_hash)
                if existing_video:
                    logger.info(f"âœ… è·å¾—é”åå‘ç°å·²æœ‰ç»“æœï¼Œç›´æ¥è¿”å› (id: {existing_video.id})")
                    video_event.set()  # é€šçŸ¥å…¶ä»–ç­‰å¾…è€…
                    return {"summary": existing_video.description}
            
            # æœªæ‰¾åˆ°å·²å­˜åœ¨è®°å½•ï¼Œå¼€å§‹æ–°çš„åˆ†æ
            logger.info("æœªæ‰¾åˆ°å·²å­˜åœ¨çš„è§†é¢‘è®°å½•ï¼Œå¼€å§‹æ–°çš„åˆ†æ")
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶è¿›è¡Œåˆ†æ
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:
                temp_file.write(video_bytes)
                temp_path = temp_file.name
            
            try:
                # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
                if not os.path.exists(temp_path):
                    video_event.set()  # é€šçŸ¥ç­‰å¾…è€…
                    return {"summary": "âŒ ä¸´æ—¶æ–‡ä»¶åˆ›å»ºå¤±è´¥"}
                
                # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è¿›è¡Œåˆ†æ
                result = await self.analyze_video(temp_path, question)
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
            
            # ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
            metadata = {
                "filename": filename,
                "file_size": len(video_bytes),
                "analysis_timestamp": time.time()
            }
            self._store_video_result(
                video_hash=video_hash,
                description=result,
                metadata=metadata
            )
            
            # å¤„ç†å®Œæˆï¼Œé€šçŸ¥ç­‰å¾…è€…å¹¶æ¸…ç†èµ„æº
            video_event.set()
            async with video_lock_manager:
                # æ¸…ç†èµ„æº
                video_locks.pop(video_hash, None)
                video_events.pop(video_hash, None)
            
            return {"summary": result}
                    
        except Exception as e:
            error_msg = f"âŒ ä»å­—èŠ‚æ•°æ®åˆ†æè§†é¢‘å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            
            # å³ä½¿å¤±è´¥ä¹Ÿä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“ï¼Œé¿å…é‡å¤å¤„ç†
            try:
                metadata = {
                    "filename": filename,
                    "file_size": len(video_bytes),
                    "analysis_timestamp": time.time(),
                    "error": str(e)
                }
                self._store_video_result(
                    video_hash=video_hash,
                    description=error_msg,
                    metadata=metadata
                )
                logger.info("âœ… é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°æ•°æ®åº“")
            except Exception as store_e:
                logger.error(f"âŒ ä¿å­˜é”™è¯¯ä¿¡æ¯å¤±è´¥: {store_e}")
            
            # å¤„ç†å¤±è´¥ï¼Œé€šçŸ¥ç­‰å¾…è€…å¹¶æ¸…ç†èµ„æº
            try:
                if video_hash and video_event:
                    async with video_lock_manager:
                        if video_hash in video_events:
                            video_events[video_hash].set()
                        video_locks.pop(video_hash, None)
                        video_events.pop(video_hash, None)
            except Exception as cleanup_e:
                logger.error(f"âŒ æ¸…ç†é”èµ„æºå¤±è´¥: {cleanup_e}")
            
            return {"summary": error_msg}

    def is_supported_video(self, file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„è§†é¢‘æ ¼å¼"""
        supported_formats = {'.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.m4v', '.3gp', '.webm'}
        return Path(file_path).suffix.lower() in supported_formats


# å…¨å±€å®ä¾‹
_video_analyzer = None

def get_video_analyzer() -> VideoAnalyzer:
    """è·å–è§†é¢‘åˆ†æå™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _video_analyzer
    if _video_analyzer is None:
        _video_analyzer = VideoAnalyzer()
    return _video_analyzer
