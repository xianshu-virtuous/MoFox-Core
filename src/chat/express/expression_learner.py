import hashlib
import os
import time
from datetime import datetime
from typing import Any

import aiofiles
import orjson
from sqlalchemy import select

from src.chat.message_receive.chat_stream import get_chat_manager
from src.chat.utils.chat_message_builder import build_anonymous_messages, get_raw_msg_by_timestamp_with_chat_inclusive
from src.chat.utils.prompt import Prompt, global_prompt_manager
from src.common.database.api.crud import CRUDBase
from src.common.database.compatibility import get_db_session
from src.common.database.core.models import Expression
from src.common.database.utils.decorators import cached
from src.common.logger import get_logger
from src.config.config import global_config, model_config
from src.llm_models.utils_model import LLMRequest

# å¯¼å…¥ StyleLearner ç®¡ç†å™¨
from .style_learner import style_learner_manager

MAX_EXPRESSION_COUNT = 300
DECAY_DAYS = 30  # 30å¤©è¡°å‡åˆ°0.01
DECAY_MIN = 0.01  # æœ€å°è¡°å‡å€¼

logger = get_logger("expressor")


def format_create_date(timestamp: float) -> str:
    """
    å°†æ—¶é—´æˆ³æ ¼å¼åŒ–ä¸ºå¯è¯»çš„æ—¥æœŸå­—ç¬¦ä¸²
    """
    try:
        return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
    except (ValueError, OSError):
        return "æœªçŸ¥æ—¶é—´"


def init_prompt() -> None:
    learn_style_prompt = """
{chat_str}

è¯·ä»ä¸Šé¢è¿™æ®µç¾¤èŠä¸­æ¦‚æ‹¬é™¤äº†äººåä¸º"SELF"ä¹‹å¤–çš„äººçš„è¯­è¨€é£æ ¼
1. åªè€ƒè™‘æ–‡å­—ï¼Œä¸è¦è€ƒè™‘è¡¨æƒ…åŒ…å’Œå›¾ç‰‡
2. ä¸è¦æ¶‰åŠå…·ä½“çš„äººåï¼Œåªè€ƒè™‘è¯­è¨€é£æ ¼
3. è¯­è¨€é£æ ¼åŒ…å«ç‰¹æ®Šå†…å®¹å’Œæƒ…æ„Ÿ
4. æ€è€ƒæœ‰æ²¡æœ‰ç‰¹æ®Šçš„æ¢—ï¼Œä¸€å¹¶æ€»ç»“æˆè¯­è¨€é£æ ¼
5. ä¾‹å­ä»…ä¾›å‚è€ƒï¼Œè¯·ä¸¥æ ¼æ ¹æ®ç¾¤èŠå†…å®¹æ€»ç»“!!!

**é‡è¦ï¼šå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œæ¯è¡Œä¸€æ¡è§„å¾‹ï¼š**
å½“"xxx"æ—¶ï¼Œä½¿ç”¨"xxx"

æ ¼å¼è¯´æ˜ï¼š
- å¿…é¡»ä»¥"å½“"å¼€å¤´
- åœºæ™¯æè¿°ç”¨åŒå¼•å·åŒ…è£¹ï¼Œä¸è¶…è¿‡20ä¸ªå­—
- å¿…é¡»åŒ…å«"ä½¿ç”¨"æˆ–"å¯ä»¥"
- è¡¨è¾¾é£æ ¼ç”¨åŒå¼•å·åŒ…è£¹ï¼Œä¸è¶…è¿‡20ä¸ªå­—
- æ¯æ¡è§„å¾‹ç‹¬å ä¸€è¡Œ

ä¾‹å¦‚ï¼š
å½“"å¯¹æŸä»¶äº‹è¡¨ç¤ºååˆ†æƒŠå¹ï¼Œæœ‰äº›æ„å¤–"æ—¶ï¼Œä½¿ç”¨"æˆ‘å˜ä¸ªxxxx"
å½“"è¡¨ç¤ºè®½åˆºçš„èµåŒï¼Œä¸æƒ³è®²é“ç†"æ—¶ï¼Œä½¿ç”¨"å¯¹å¯¹å¯¹"
å½“"æƒ³è¯´æ˜æŸä¸ªå…·ä½“çš„äº‹å®è§‚ç‚¹ï¼Œä½†æ‡’å¾—æ˜è¯´ï¼Œæˆ–è€…ä¸ä¾¿æ˜è¯´ï¼Œæˆ–è¡¨è¾¾ä¸€ç§é»˜å¥‘"æ—¶ï¼Œä½¿ç”¨"æ‡‚çš„éƒ½æ‡‚"
å½“"æ¶‰åŠæ¸¸æˆç›¸å…³æ—¶ï¼Œè¡¨ç¤ºæ„å¤–çš„å¤¸èµï¼Œç•¥å¸¦æˆè°‘æ„å‘³"æ—¶ï¼Œä½¿ç”¨"è¿™ä¹ˆå¼ºï¼"

æ³¨æ„ï¼š
1. ä¸è¦æ€»ç»“ä½ è‡ªå·±ï¼ˆSELFï¼‰çš„å‘è¨€
2. å¦‚æœèŠå¤©å†…å®¹ä¸­æ²¡æœ‰æ˜æ˜¾çš„ç‰¹æ®Šé£æ ¼ï¼Œè¯·åªè¾“å‡º1-2æ¡æœ€æ˜æ˜¾çš„ç‰¹ç‚¹
3. ä¸è¦è¾“å‡ºå…¶ä»–è§£é‡Šæ€§æ–‡å­—ï¼Œåªè¾“å‡ºç¬¦åˆæ ¼å¼çš„è§„å¾‹

ç°åœ¨è¯·ä½ æ¦‚æ‹¬ï¼š
"""
    Prompt(learn_style_prompt, "learn_style_prompt")

    learn_grammar_prompt = """
{chat_str}

è¯·ä»ä¸Šé¢è¿™æ®µç¾¤èŠä¸­æ¦‚æ‹¬é™¤äº†äººåä¸º"SELF"ä¹‹å¤–çš„äººçš„è¯­æ³•å’Œå¥æ³•ç‰¹ç‚¹ï¼Œåªè€ƒè™‘çº¯æ–‡å­—ï¼Œä¸è¦è€ƒè™‘è¡¨æƒ…åŒ…å’Œå›¾ç‰‡
1.ä¸è¦æ€»ç»“ã€å›¾ç‰‡ã€‘ï¼Œã€åŠ¨ç”»è¡¨æƒ…ã€‘ï¼Œ[å›¾ç‰‡]ï¼Œ[åŠ¨ç”»è¡¨æƒ…]ï¼Œä¸æ€»ç»“ è¡¨æƒ…ç¬¦å· at @ å›å¤ å’Œ[å›å¤]
2.ä¸è¦æ¶‰åŠå…·ä½“çš„äººåï¼Œåªè€ƒè™‘è¯­æ³•å’Œå¥æ³•ç‰¹ç‚¹,
3.è¯­æ³•å’Œå¥æ³•ç‰¹ç‚¹è¦åŒ…æ‹¬ï¼Œå¥å­é•¿çŸ­ï¼ˆå…·ä½“å­—æ•°ï¼‰ï¼Œæœ‰ä½•ç§è¯­ç—…ï¼Œå¦‚ä½•æ‹†åˆ†å¥å­ã€‚
4. ä¾‹å­ä»…ä¾›å‚è€ƒï¼Œè¯·ä¸¥æ ¼æ ¹æ®ç¾¤èŠå†…å®¹æ€»ç»“!!!

**é‡è¦ï¼šå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œæ¯è¡Œä¸€æ¡è§„å¾‹ï¼š**
å½“"xxx"æ—¶ï¼Œä½¿ç”¨"xxx"

æ ¼å¼è¯´æ˜ï¼š
- å¿…é¡»ä»¥"å½“"å¼€å¤´
- åœºæ™¯æè¿°ç”¨åŒå¼•å·åŒ…è£¹
- å¿…é¡»åŒ…å«"ä½¿ç”¨"æˆ–"å¯ä»¥"
- å¥æ³•ç‰¹ç‚¹ç”¨åŒå¼•å·åŒ…è£¹
- æ¯æ¡è§„å¾‹ç‹¬å ä¸€è¡Œ

ä¾‹å¦‚ï¼š
å½“"è¡¨è¾¾è§‚ç‚¹è¾ƒå¤æ‚"æ—¶ï¼Œä½¿ç”¨"çœç•¥ä¸»è¯­(3-6ä¸ªå­—)"çš„å¥æ³•
å½“"ä¸ç”¨è¯¦ç»†è¯´æ˜çš„ä¸€èˆ¬è¡¨è¾¾"æ—¶ï¼Œä½¿ç”¨"éå¸¸ç®€æ´çš„å¥å­"çš„å¥æ³•
å½“"éœ€è¦å•çº¯ç®€å•çš„ç¡®è®¤"æ—¶ï¼Œä½¿ç”¨"å•å­—æˆ–å‡ ä¸ªå­—çš„è‚¯å®š(1-2ä¸ªå­—)"çš„å¥æ³•

æ³¨æ„ï¼š
1. ä¸è¦æ€»ç»“ä½ è‡ªå·±ï¼ˆSELFï¼‰çš„å‘è¨€
2. å¦‚æœèŠå¤©å†…å®¹ä¸­æ²¡æœ‰æ˜æ˜¾çš„å¥æ³•ç‰¹ç‚¹ï¼Œè¯·åªè¾“å‡º1-2æ¡æœ€æ˜æ˜¾çš„ç‰¹ç‚¹
3. ä¸è¦è¾“å‡ºå…¶ä»–è§£é‡Šæ€§æ–‡å­—ï¼Œåªè¾“å‡ºç¬¦åˆæ ¼å¼çš„è§„å¾‹

ç°åœ¨è¯·ä½ æ¦‚æ‹¬ï¼š
"""
    Prompt(learn_grammar_prompt, "learn_grammar_prompt")


class ExpressionLearner:
    def __init__(self, chat_id: str) -> None:
        if model_config is None:
            raise RuntimeError("Model config is not initialized")
        self.express_learn_model: LLMRequest = LLMRequest(
            model_set=model_config.model_task_config.replyer, request_type="expressor.learner"
        )
        self.chat_id = chat_id
        self.chat_name = chat_id  # åˆå§‹åŒ–æ—¶ä½¿ç”¨chat_idï¼Œç¨åå¼‚æ­¥æ›´æ–°

        # ç»´æŠ¤æ¯ä¸ªchatçš„ä¸Šæ¬¡å­¦ä¹ æ—¶é—´
        self.last_learning_time: float = time.time()

        # å­¦ä¹ å‚æ•°
        self.min_messages_for_learning = 25  # è§¦å‘å­¦ä¹ æ‰€éœ€çš„æœ€å°‘æ¶ˆæ¯æ•°
        self.min_learning_interval = 300  # æœ€çŸ­å­¦ä¹ æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
        self._chat_name_initialized = False

    @staticmethod
    def _parse_stream_config_to_chat_id(stream_config_str: str) -> str | None:
        """è§£æ'platform:id:type'ä¸ºchat_idï¼ˆä¸get_stream_idä¸€è‡´ï¼‰"""
        try:
            parts = stream_config_str.split(":")
            if len(parts) != 3:
                return None
            platform = parts[0]
            id_str = parts[1]
            stream_type = parts[2]
            is_group = stream_type == "group"
            if is_group:
                components = [platform, str(id_str)]
            else:
                components = [platform, str(id_str), "private"]
            key = "_".join(components)
            return hashlib.md5(key.encode()).hexdigest()
        except Exception:
            return None

    def get_related_chat_ids(self) -> list[str]:
        """æ ¹æ®expression.rulesé…ç½®ï¼Œè·å–ä¸å½“å‰chat_idç›¸å…³çš„æ‰€æœ‰chat_idï¼ˆåŒ…æ‹¬è‡ªèº«ï¼‰
        
        ç”¨äºå…±äº«ç»„åŠŸèƒ½ï¼šåŒä¸€å…±äº«ç»„å†…çš„èŠå¤©æµå¯ä»¥å…±äº«å­¦ä¹ åˆ°çš„è¡¨è¾¾æ–¹å¼
        """
        if global_config is None:
            return [self.chat_id]
        rules = global_config.expression.rules
        current_group = None

        # æ‰¾åˆ°å½“å‰chat_idæ‰€åœ¨çš„ç»„
        for rule in rules:
            if rule.chat_stream_id and self._parse_stream_config_to_chat_id(rule.chat_stream_id) == self.chat_id:
                current_group = rule.group
                break

        # å§‹ç»ˆåŒ…å«å½“å‰ chat_idï¼ˆç¡®ä¿è‡³å°‘èƒ½æŸ¥åˆ°è‡ªå·±çš„æ•°æ®ï¼‰
        related_chat_ids = [self.chat_id]

        if current_group:
            # æ‰¾å‡ºåŒä¸€ç»„çš„æ‰€æœ‰chat_id
            for rule in rules:
                if rule.group == current_group and rule.chat_stream_id:
                    if chat_id_candidate := self._parse_stream_config_to_chat_id(rule.chat_stream_id):
                        if chat_id_candidate not in related_chat_ids:
                            related_chat_ids.append(chat_id_candidate)

        return related_chat_ids

    async def _initialize_chat_name(self):
        """å¼‚æ­¥åˆå§‹åŒ–chat_name"""
        if not self._chat_name_initialized:
            stream_name = await get_chat_manager().get_stream_name(self.chat_id)
            self.chat_name = stream_name or self.chat_id
            self._chat_name_initialized = True

    async def cleanup_expired_expressions(self, expiration_days: int | None = None) -> int:
        """
        æ¸…ç†è¿‡æœŸçš„è¡¨è¾¾æ–¹å¼

        Args:
            expiration_days: è¿‡æœŸå¤©æ•°ï¼Œè¶…è¿‡æ­¤å¤©æ•°æœªæ¿€æ´»çš„è¡¨è¾¾æ–¹å¼å°†è¢«åˆ é™¤ï¼ˆä¸æŒ‡å®šåˆ™ä»é…ç½®è¯»å–ï¼‰

        Returns:
            int: åˆ é™¤çš„è¡¨è¾¾æ–¹å¼æ•°é‡
        """
        # ä»é…ç½®è¯»å–è¿‡æœŸå¤©æ•°
        if expiration_days is None:
            if global_config is None:
                expiration_days = 30  # Default value if config is missing
            else:
                expiration_days = global_config.expression.expiration_days

        current_time = time.time()
        expiration_threshold = current_time - (expiration_days * 24 * 3600)

        try:
            deleted_count = 0
            async with get_db_session() as session:
                # æŸ¥è¯¢è¿‡æœŸçš„è¡¨è¾¾æ–¹å¼ï¼ˆåªæ¸…ç†å½“å‰chat_idçš„ï¼‰
                query = await session.execute(
                    select(Expression).where(
                        (Expression.chat_id == self.chat_id)
                        & (Expression.last_active_time < expiration_threshold)
                    )
                )
                expired_expressions = list(query.scalars())

                if expired_expressions:
                    for expr in expired_expressions:
                        await session.delete(expr)
                        deleted_count += 1

                    await session.commit()
                    logger.info(f"æ¸…ç†äº† {deleted_count} ä¸ªè¿‡æœŸè¡¨è¾¾æ–¹å¼ï¼ˆè¶…è¿‡ {expiration_days} å¤©æœªä½¿ç”¨ï¼‰")

                    # æ¸…é™¤ç¼“å­˜
                    from src.common.database.optimization.cache_manager import get_cache
                    from src.common.database.utils.decorators import generate_cache_key
                    cache = await get_cache()
                    await cache.delete(generate_cache_key("chat_expressions", self.chat_id))
                else:
                    logger.debug(f"æ²¡æœ‰å‘ç°è¿‡æœŸçš„è¡¨è¾¾æ–¹å¼ï¼ˆé˜ˆå€¼ï¼š{expiration_days} å¤©ï¼‰")

            return deleted_count
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸè¡¨è¾¾æ–¹å¼å¤±è´¥: {e}")
            return 0

    def can_learn_for_chat(self) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šèŠå¤©æµæ˜¯å¦å…è®¸å­¦ä¹ è¡¨è¾¾

        Args:
            chat_id: èŠå¤©æµID

        Returns:
            bool: æ˜¯å¦å…è®¸å­¦ä¹ 
        """
        try:
            if global_config is None:
                return False
            use_expression, enable_learning, _ = global_config.expression.get_expression_config_for_chat(self.chat_id)
            return enable_learning
        except Exception as e:
            logger.error(f"æ£€æŸ¥å­¦ä¹ æƒé™å¤±è´¥: {e}")
            return False

    async def should_trigger_learning(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘å­¦ä¹ 

        Args:
            chat_id: èŠå¤©æµID

        Returns:
            bool: æ˜¯å¦åº”è¯¥è§¦å‘å­¦ä¹ 
        """
        current_time = time.time()

        # è·å–è¯¥èŠå¤©æµçš„å­¦ä¹ å¼ºåº¦
        try:
            if global_config is None:
                return False
            use_expression, enable_learning, learning_intensity = (
                global_config.expression.get_expression_config_for_chat(self.chat_id)
            )
        except Exception as e:
            logger.error(f"è·å–èŠå¤©æµ {self.chat_id} çš„å­¦ä¹ é…ç½®å¤±è´¥: {e}")
            return False

        # æ£€æŸ¥æ˜¯å¦å…è®¸å­¦ä¹ 
        if not enable_learning:
            return False

        # æ ¹æ®å­¦ä¹ å¼ºåº¦è®¡ç®—æœ€çŸ­å­¦ä¹ æ—¶é—´é—´éš”
        min_interval = self.min_learning_interval / learning_intensity

        # æ£€æŸ¥æ—¶é—´é—´éš”
        time_diff = current_time - self.last_learning_time
        if time_diff < min_interval:
            return False

        # æ£€æŸ¥æ¶ˆæ¯æ•°é‡ï¼ˆåªæ£€æŸ¥æŒ‡å®šèŠå¤©æµçš„æ¶ˆæ¯ï¼Œæ’é™¤æœºå™¨äººè‡ªå·±çš„æ¶ˆæ¯ï¼‰
        recent_messages = await get_raw_msg_by_timestamp_with_chat_inclusive(
            chat_id=self.chat_id,
            timestamp_start=self.last_learning_time,
            timestamp_end=time.time(),
            filter_bot=True,  # è¿‡æ»¤æ‰æœºå™¨äººè‡ªå·±çš„æ¶ˆæ¯
        )

        if not recent_messages or len(recent_messages) < self.min_messages_for_learning:
            return False

        return True

    async def trigger_learning_for_chat(self) -> bool:
        """
        ä¸ºæŒ‡å®šèŠå¤©æµè§¦å‘å­¦ä¹ 

        Args:
            chat_id: èŠå¤©æµID

        Returns:
            bool: æ˜¯å¦æˆåŠŸè§¦å‘å­¦ä¹ 
        """
        # åˆå§‹åŒ–chat_name
        await self._initialize_chat_name()

        if not await self.should_trigger_learning():
            return False

        try:
            logger.info(f"ä¸ºèŠå¤©æµ {self.chat_name} è§¦å‘è¡¨è¾¾å­¦ä¹ ")

            # ğŸ”¥ æ”¹è¿›3ï¼šåœ¨å­¦ä¹ å‰æ¸…ç†è¿‡æœŸçš„è¡¨è¾¾æ–¹å¼
            await self.cleanup_expired_expressions()

            # å­¦ä¹ è¯­è¨€é£æ ¼
            learnt_style = await self.learn_and_store(type="style", num=25)

            # å­¦ä¹ å¥æ³•ç‰¹ç‚¹
            learnt_grammar = await self.learn_and_store(type="grammar", num=10)

            # æ›´æ–°å­¦ä¹ æ—¶é—´
            self.last_learning_time = time.time()

            if learnt_style or learnt_grammar:
                logger.info(f"èŠå¤©æµ {self.chat_name} è¡¨è¾¾å­¦ä¹ å®Œæˆ")
                return True
            else:
                logger.warning(f"èŠå¤©æµ {self.chat_name} è¡¨è¾¾å­¦ä¹ æœªè·å¾—æœ‰æ•ˆç»“æœ")
                return False

        except Exception as e:
            logger.error(f"ä¸ºèŠå¤©æµ {self.chat_name} è§¦å‘å­¦ä¹ å¤±è´¥: {e}")
            return False

    async def get_expression_by_chat_id(self) -> tuple[list[dict[str, float]], list[dict[str, float]]]:
        """
        è·å–æŒ‡å®šchat_idçš„styleå’Œgrammarè¡¨è¾¾æ–¹å¼ï¼ˆå¸¦10åˆ†é’Ÿç¼“å­˜ï¼‰
        è¿”å›çš„æ¯ä¸ªè¡¨è¾¾æ–¹å¼å­—å…¸ä¸­éƒ½åŒ…å«äº†source_id, ç”¨äºåç»­çš„æ›´æ–°æ“ä½œ

        ä¼˜åŒ–: ä½¿ç”¨CRUDå’Œç¼“å­˜ï¼Œå‡å°‘æ•°æ®åº“è®¿é—®
        """
        # ä½¿ç”¨é™æ€æ–¹æ³•ä»¥æ­£ç¡®å¤„ç†ç¼“å­˜é”®
        return await self._get_expressions_by_chat_id_cached(self.chat_id)

    @staticmethod
    @cached(ttl=600, key_prefix="chat_expressions")
    async def _get_expressions_by_chat_id_cached(chat_id: str) -> tuple[list[dict[str, float]], list[dict[str, float]]]:
        """å†…éƒ¨æ–¹æ³•ï¼šä»æ•°æ®åº“è·å–è¡¨è¾¾æ–¹å¼ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        learnt_style_expressions = []
        learnt_grammar_expressions = []

        # ä½¿ç”¨CRUDæŸ¥è¯¢
        crud = CRUDBase(Expression)
        all_expressions = await crud.get_multi(chat_id=chat_id, limit=10000)

        for expr in all_expressions:
                # ç¡®ä¿create_dateå­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨last_active_time
                create_date = expr.create_date if expr.create_date is not None else expr.last_active_time

                expr_data = {
                    "situation": expr.situation,
                    "style": expr.style,
                    "count": expr.count,
                    "last_active_time": expr.last_active_time,
                    "source_id": chat_id,
                    "type": expr.type,
                    "create_date": create_date,
                }

                # æ ¹æ®ç±»å‹åˆ†ç±»
                if expr.type == "style":
                    learnt_style_expressions.append(expr_data)
                elif expr.type == "grammar":
                    learnt_grammar_expressions.append(expr_data)

        return learnt_style_expressions, learnt_grammar_expressions

    async def _apply_global_decay_to_database(self, current_time: float) -> None:
        """
        å¯¹æ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨è¾¾æ–¹å¼åº”ç”¨å…¨å±€è¡°å‡

        ä¼˜åŒ–: ä½¿ç”¨CRUDæ‰¹é‡å¤„ç†æ‰€æœ‰æ›´æ”¹ï¼Œæœ€åç»Ÿä¸€æäº¤
        """
        try:
            # ä½¿ç”¨CRUDæŸ¥è¯¢æ‰€æœ‰è¡¨è¾¾æ–¹å¼
            crud = CRUDBase(Expression)
            all_expressions = await crud.get_multi(limit=100000)  # è·å–æ‰€æœ‰è¡¨è¾¾æ–¹å¼

            updated_count = 0
            deleted_count = 0

            # éœ€è¦æ‰‹åŠ¨æ“ä½œçš„æƒ…å†µä¸‹ä½¿ç”¨session
            async with get_db_session() as session:
                # æ‰¹é‡å¤„ç†æ‰€æœ‰ä¿®æ”¹
                for expr in all_expressions:
                    # è®¡ç®—æ—¶é—´å·®
                    last_active = expr.last_active_time
                    time_diff_days = (current_time - last_active) / (24 * 3600)  # è½¬æ¢ä¸ºå¤©

                    # è®¡ç®—è¡°å‡å€¼
                    decay_value = self.calculate_decay_factor(time_diff_days)
                    new_count = max(0.01, expr.count - decay_value)

                    if new_count <= 0.01:
                        # å¦‚æœcountå¤ªå°ï¼Œåˆ é™¤è¿™ä¸ªè¡¨è¾¾æ–¹å¼
                        await session.delete(expr)
                        deleted_count += 1
                    else:
                        # æ›´æ–°count
                        expr.count = new_count
                        updated_count += 1

                # ä¼˜åŒ–: ç»Ÿä¸€æäº¤æ‰€æœ‰æ›´æ”¹ï¼ˆä»Næ¬¡æäº¤å‡å°‘åˆ°1æ¬¡ï¼‰
                if updated_count > 0 or deleted_count > 0:
                    await session.commit()
                    logger.info(f"å…¨å±€è¡°å‡å®Œæˆï¼šæ›´æ–°äº† {updated_count} ä¸ªè¡¨è¾¾æ–¹å¼ï¼Œåˆ é™¤äº† {deleted_count} ä¸ªè¡¨è¾¾æ–¹å¼")

        except Exception as e:
            logger.error(f"æ•°æ®åº“å…¨å±€è¡°å‡å¤±è´¥: {e}")

    @staticmethod
    def calculate_decay_factor(time_diff_days: float) -> float:
        """
        è®¡ç®—è¡°å‡å€¼
        å½“æ—¶é—´å·®ä¸º0å¤©æ—¶ï¼Œè¡°å‡å€¼ä¸º0ï¼ˆæœ€è¿‘æ´»è·ƒçš„ä¸è¡°å‡ï¼‰
        å½“æ—¶é—´å·®ä¸º7å¤©æ—¶ï¼Œè¡°å‡å€¼ä¸º0.002ï¼ˆä¸­ç­‰è¡°å‡ï¼‰
        å½“æ—¶é—´å·®ä¸º30å¤©æˆ–æ›´é•¿æ—¶ï¼Œè¡°å‡å€¼ä¸º0.01ï¼ˆé«˜è¡°å‡ï¼‰
        ä½¿ç”¨äºŒæ¬¡å‡½æ•°è¿›è¡Œæ›²çº¿æ’å€¼
        """
        if time_diff_days <= 0:
            return 0.0  # åˆšæ¿€æ´»çš„è¡¨è¾¾å¼ä¸è¡°å‡

        if time_diff_days >= DECAY_DAYS:
            return 0.01  # é•¿æ—¶é—´æœªæ´»è·ƒçš„è¡¨è¾¾å¼å¤§å¹…è¡°å‡

        # ä½¿ç”¨äºŒæ¬¡å‡½æ•°æ’å€¼ï¼šåœ¨0-30å¤©ä¹‹é—´ä»0è¡°å‡åˆ°0.01
        # ä½¿ç”¨ç®€å•çš„äºŒæ¬¡å‡½æ•°ï¼šy = a * x^2
        # å½“x=30æ—¶ï¼Œy=0.01ï¼Œæ‰€ä»¥ a = 0.01 / (30^2) = 0.01 / 900
        a = 0.01 / (DECAY_DAYS**2)
        decay = a * (time_diff_days**2)

        return min(0.01, decay)

    async def learn_and_store(self, type: str, num: int = 10) -> None | list[Any] | list[tuple[str, str, str]]:
        # sourcery skip: use-join
        """
        å­¦ä¹ å¹¶å­˜å‚¨è¡¨è¾¾æ–¹å¼
        type: "style" or "grammar"
        """
        if type == "style":
            type_str = "è¯­è¨€é£æ ¼"
        elif type == "grammar":
            type_str = "å¥æ³•ç‰¹ç‚¹"
        else:
            raise ValueError(f"Invalid type: {type}")

        # æ£€æŸ¥æ˜¯å¦å…è®¸åœ¨æ­¤èŠå¤©æµä¸­å­¦ä¹ ï¼ˆåœ¨å‡½æ•°æœ€å‰é¢æ£€æŸ¥ï¼‰
        if not self.can_learn_for_chat():
            logger.debug(f"èŠå¤©æµ {self.chat_name} ä¸å…è®¸å­¦ä¹ è¡¨è¾¾ï¼Œè·³è¿‡å­¦ä¹ ")
            return []

        res = await self.learn_expression(type, num)

        if res is None:
            return []
        learnt_expressions, chat_id = res

        chat_stream = await get_chat_manager().get_stream(chat_id)
        if chat_stream is None:
            group_name = f"èŠå¤©æµ {chat_id}"
        elif chat_stream.group_info:
            group_name = chat_stream.group_info.group_name
        elif chat_stream.user_info and chat_stream.user_info.user_nickname:
            group_name = f"{chat_stream.user_info.user_nickname}çš„ç§èŠ"
        else:
            group_name = f"èŠå¤©æµ {chat_id}"
        learnt_expressions_str = ""
        for _chat_id, situation, style in learnt_expressions:
            learnt_expressions_str += f"{situation}->{style}\n"
        logger.info(f"åœ¨ {group_name} å­¦ä¹ åˆ°{type_str}:\n{learnt_expressions_str}")

        if not learnt_expressions:
            logger.info(f"æ²¡æœ‰å­¦ä¹ åˆ°{type_str}")
            return []

        # æŒ‰chat_idåˆ†ç»„
        chat_dict: dict[str, list[dict[str, Any]]] = {}
        for chat_id, situation, style in learnt_expressions:
            if chat_id not in chat_dict:
                chat_dict[chat_id] = []
            chat_dict[chat_id].append({"situation": situation, "style": style})

        current_time = time.time()

        # å­˜å‚¨åˆ°æ•°æ®åº“ Expression è¡¨
        CRUDBase(Expression)
        for chat_id, expr_list in chat_dict.items():
            async with get_db_session() as session:
                for new_expr in expr_list:
                    # ğŸ”¥ æ”¹è¿›1ï¼šæ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒæƒ…æ™¯æˆ–ç›¸åŒè¡¨è¾¾çš„æ•°æ®
                    # æƒ…å†µ1ï¼šç›¸åŒ chat_id + type + situationï¼ˆç›¸åŒæƒ…æ™¯ï¼Œä¸åŒè¡¨è¾¾ï¼‰
                    query_same_situation = await session.execute(
                        select(Expression).where(
                            (Expression.chat_id == chat_id)
                            & (Expression.type == type)
                            & (Expression.situation == new_expr["situation"])
                        )
                    )
                    same_situation_expr = query_same_situation.scalar()

                    # æƒ…å†µ2ï¼šç›¸åŒ chat_id + type + styleï¼ˆç›¸åŒè¡¨è¾¾ï¼Œä¸åŒæƒ…æ™¯ï¼‰
                    query_same_style = await session.execute(
                        select(Expression).where(
                            (Expression.chat_id == chat_id)
                            & (Expression.type == type)
                            & (Expression.style == new_expr["style"])
                        )
                    )
                    same_style_expr = query_same_style.scalar()

                    # æƒ…å†µ3ï¼šå®Œå…¨ç›¸åŒï¼ˆç›¸åŒæƒ…æ™¯+ç›¸åŒè¡¨è¾¾ï¼‰
                    query_exact_match = await session.execute(
                        select(Expression).where(
                            (Expression.chat_id == chat_id)
                            & (Expression.type == type)
                            & (Expression.situation == new_expr["situation"])
                            & (Expression.style == new_expr["style"])
                        )
                    )
                    exact_match_expr = query_exact_match.scalar()

                    # ä¼˜å…ˆå¤„ç†å®Œå…¨åŒ¹é…çš„æƒ…å†µ
                    if exact_match_expr:
                        # å®Œå…¨ç›¸åŒï¼šå¢åŠ countï¼Œæ›´æ–°æ—¶é—´
                        expr_obj = exact_match_expr
                        expr_obj.count = expr_obj.count + 1
                        expr_obj.last_active_time = current_time
                        logger.debug(f"å®Œå…¨åŒ¹é…ï¼šæ›´æ–°count {expr_obj.count}")
                    elif same_situation_expr:
                        # ç›¸åŒæƒ…æ™¯ï¼Œä¸åŒè¡¨è¾¾ï¼šè¦†ç›–æ—§çš„è¡¨è¾¾
                        logger.info(f"ç›¸åŒæƒ…æ™¯è¦†ç›–ï¼š'{same_situation_expr.situation}' çš„è¡¨è¾¾ä» '{same_situation_expr.style}' æ›´æ–°ä¸º '{new_expr['style']}'")
                        same_situation_expr.style = new_expr["style"]
                        same_situation_expr.count = same_situation_expr.count + 1
                        same_situation_expr.last_active_time = current_time
                    elif same_style_expr:
                        # ç›¸åŒè¡¨è¾¾ï¼Œä¸åŒæƒ…æ™¯ï¼šè¦†ç›–æ—§çš„æƒ…æ™¯
                        logger.info(f"ç›¸åŒè¡¨è¾¾è¦†ç›–ï¼š'{same_style_expr.style}' çš„æƒ…æ™¯ä» '{same_style_expr.situation}' æ›´æ–°ä¸º '{new_expr['situation']}'")
                        same_style_expr.situation = new_expr["situation"]
                        same_style_expr.count = same_style_expr.count + 1
                        same_style_expr.last_active_time = current_time
                    else:
                        # å®Œå…¨æ–°çš„è¡¨è¾¾æ–¹å¼ï¼šåˆ›å»ºæ–°è®°å½•
                        new_expression = Expression(
                            situation=new_expr["situation"],
                            style=new_expr["style"],
                            count=1,
                            last_active_time=current_time,
                            chat_id=chat_id,
                            type=type,
                            create_date=current_time,  # æ‰‹åŠ¨è®¾ç½®åˆ›å»ºæ—¥æœŸ
                        )
                        session.add(new_expression)
                        logger.debug(f"æ–°å¢è¡¨è¾¾æ–¹å¼ï¼š{new_expr['situation']} -> {new_expr['style']}")

                # é™åˆ¶æœ€å¤§æ•°é‡ - ä½¿ç”¨ get_all_by_sorted è·å–æ’åºç»“æœ
                exprs_result = await session.execute(
                    select(Expression)
                    .where((Expression.chat_id == chat_id) & (Expression.type == type))
                    .order_by(Expression.count.asc())
                )
                exprs = list(exprs_result.scalars())
                if len(exprs) > MAX_EXPRESSION_COUNT:
                    # åˆ é™¤countæœ€å°çš„å¤šä½™è¡¨è¾¾æ–¹å¼
                    for expr in exprs[: len(exprs) - MAX_EXPRESSION_COUNT]:
                        await session.delete(expr)

                # æäº¤åæ¸…é™¤ç›¸å…³ç¼“å­˜
                await session.commit()

            # ğŸ”¥ æ¸…é™¤å…±äº«ç»„å†…æ‰€æœ‰ chat_id çš„è¡¨è¾¾æ–¹å¼ç¼“å­˜
            from src.common.database.optimization.cache_manager import get_cache
            from src.common.database.utils.decorators import generate_cache_key
            cache = await get_cache()
            
            # è·å–å…±äº«ç»„å†…æ‰€æœ‰ chat_id å¹¶æ¸…é™¤å…¶ç¼“å­˜
            related_chat_ids = self.get_related_chat_ids()
            for related_id in related_chat_ids:
                await cache.delete(generate_cache_key("chat_expressions", related_id))
            if len(related_chat_ids) > 1:
                logger.debug(f"å·²æ¸…é™¤å…±äº«ç»„å†… {len(related_chat_ids)} ä¸ª chat_id çš„è¡¨è¾¾æ–¹å¼ç¼“å­˜")

            # ğŸ”¥ è®­ç»ƒ StyleLearnerï¼ˆæ”¯æŒå…±äº«ç»„ï¼‰
            # åªå¯¹ style ç±»å‹çš„è¡¨è¾¾æ–¹å¼è¿›è¡Œè®­ç»ƒï¼ˆgrammar ä¸éœ€è¦è®­ç»ƒåˆ°æ¨¡å‹ï¼‰
            if type == "style":
                try:
                    logger.debug(f"å¼€å§‹è®­ç»ƒ StyleLearner: æºchat_id={chat_id}, å…±äº«ç»„åŒ…å« {len(related_chat_ids)} ä¸ªchat_id, æ ·æœ¬æ•°={len(expr_list)}")

                    # ä¸ºæ¯ä¸ªå…±äº«ç»„å†…çš„ chat_id è®­ç»ƒå…¶ StyleLearner
                    for target_chat_id in related_chat_ids:
                        learner = style_learner_manager.get_learner(target_chat_id)
                        
                        # ä¸ºæ¯ä¸ªå­¦ä¹ åˆ°çš„è¡¨è¾¾æ–¹å¼è®­ç»ƒæ¨¡å‹
                        # ä½¿ç”¨ situation ä½œä¸ºè¾“å…¥ï¼Œstyle ä½œä¸ºç›®æ ‡
                        # è¿™æ˜¯æœ€ç¬¦åˆè¯­ä¹‰çš„æ–¹å¼ï¼šåœºæ™¯ -> è¡¨è¾¾æ–¹å¼
                        success_count = 0
                        for expr in expr_list:
                            situation = expr["situation"]
                            style = expr["style"]

                            # è®­ç»ƒæ˜ å°„å…³ç³»: situation -> style
                            if learner.learn_mapping(situation, style):
                                success_count += 1
                            else:
                                logger.warning(f"è®­ç»ƒå¤±è´¥ (target={target_chat_id}): {situation} -> {style}")

                        # ä¿å­˜æ¨¡å‹
                        if learner.save(style_learner_manager.model_save_path):
                            logger.debug(f"StyleLearner æ¨¡å‹ä¿å­˜æˆåŠŸ: {target_chat_id}")
                        else:
                            logger.error(f"StyleLearner æ¨¡å‹ä¿å­˜å¤±è´¥: {target_chat_id}")

                        if target_chat_id == chat_id:
                            # åªä¸ºæº chat_id è®°å½•è¯¦ç»†æ—¥å¿—
                            logger.info(
                                f"StyleLearner è®­ç»ƒå®Œæˆ (æº): {success_count}/{len(expr_list)} æˆåŠŸ, "
                                f"å½“å‰é£æ ¼æ€»æ•°={len(learner.get_all_styles())}, "
                                f"æ€»æ ·æœ¬æ•°={learner.learning_stats['total_samples']}"
                            )
                        else:
                            logger.debug(
                                f"StyleLearner è®­ç»ƒå®Œæˆ (å…±äº«ç»„æˆå‘˜ {target_chat_id}): {success_count}/{len(expr_list)} æˆåŠŸ"
                            )

                    if len(related_chat_ids) > 1:
                        logger.info(f"å…±äº«ç»„å†…å…± {len(related_chat_ids)} ä¸ª StyleLearner å·²åŒæ­¥è®­ç»ƒ")

                except Exception as e:
                    logger.error(f"è®­ç»ƒ StyleLearner å¤±è´¥: {e}")

            return learnt_expressions
        return None

    async def learn_expression(self, type: str, num: int = 10) -> tuple[list[tuple[str, str, str]], str] | None:
        """ä»æŒ‡å®šèŠå¤©æµå­¦ä¹ è¡¨è¾¾æ–¹å¼

        Args:
            type: "style" or "grammar"
        """
        if type == "style":
            type_str = "è¯­è¨€é£æ ¼"
            prompt = "learn_style_prompt"
        elif type == "grammar":
            type_str = "å¥æ³•ç‰¹ç‚¹"
            prompt = "learn_grammar_prompt"
        else:
            raise ValueError(f"Invalid type: {type}")

        current_time = time.time()

        # è·å–ä¸Šæ¬¡å­¦ä¹ æ—¶é—´ï¼Œè¿‡æ»¤æ‰æœºå™¨äººè‡ªå·±çš„æ¶ˆæ¯å’Œæ— æ„ä¹‰æ¶ˆæ¯
        random_msg: list[dict[str, Any]] | None = await get_raw_msg_by_timestamp_with_chat_inclusive(
            chat_id=self.chat_id,
            timestamp_start=self.last_learning_time,
            timestamp_end=current_time,
            limit=num,
            filter_bot=True,  # è¿‡æ»¤æ‰æœºå™¨äººè‡ªå·±çš„æ¶ˆæ¯ï¼Œé˜²æ­¢å­¦ä¹ è‡ªå·±çš„è¡¨è¾¾æ–¹å¼
            filter_meaningless=True,  # ğŸ”¥ è¿‡æ»¤æ‰è¡¨æƒ…åŒ…ã€é€šçŸ¥ç­‰æ— æ„ä¹‰æ¶ˆæ¯
        )

        # print(random_msg)
        if not random_msg or random_msg == []:
            return None
        # è½¬åŒ–æˆstr
        chat_id: str = random_msg[0]["chat_id"]
        # random_msg_str: str = build_readable_messages(random_msg, timestamp_mode="normal")
        # ğŸ”¥ å¯ç”¨è¡¨è¾¾å­¦ä¹ åœºæ™¯çš„è¿‡æ»¤ï¼Œè¿‡æ»¤æ‰çº¯å›å¤ã€çº¯@ã€çº¯å›¾ç‰‡ç­‰æ— æ„ä¹‰å†…å®¹
        random_msg_str: str = await build_anonymous_messages(random_msg, filter_for_learning=True)
        # print(f"random_msg_str:{random_msg_str}")
        
        # ğŸ”¥ æ£€æŸ¥è¿‡æ»¤åæ˜¯å¦è¿˜æœ‰è¶³å¤Ÿçš„å†…å®¹
        if not random_msg_str or len(random_msg_str.strip()) < 20:
            logger.debug(f"è¿‡æ»¤åæ¶ˆæ¯å†…å®¹ä¸è¶³ï¼Œè·³è¿‡æœ¬æ¬¡{type_str}å­¦ä¹ ")
            return None

        prompt: str = await global_prompt_manager.format_prompt(
            prompt,
            chat_str=random_msg_str,
        )

        logger.debug(f"å­¦ä¹ {type_str}çš„prompt: {prompt}")

        try:
            response, _ = await self.express_learn_model.generate_response_async(prompt, temperature=0.3)
        except Exception as e:
            logger.error(f"å­¦ä¹ {type_str}å¤±è´¥: {e}")
            return None

        if not response or not response.strip():
            logger.warning(f"LLMè¿”å›ç©ºå“åº”ï¼Œæ— æ³•å­¦ä¹ {type_str}")
            return None

        logger.debug(f"å­¦ä¹ {type_str}çš„response: {response}")

        expressions: list[tuple[str, str, str]] = self.parse_expression_response(response, chat_id)

        if not expressions:
            logger.warning(f"ä»LLMå“åº”ä¸­æœªèƒ½è§£æå‡ºä»»ä½•{type_str}ã€‚è¯·æ£€æŸ¥LLMè¾“å‡ºæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            logger.info(f"LLMå®Œæ•´å“åº”:\n{response}")

        return expressions, chat_id

    @staticmethod
    def parse_expression_response(response: str, chat_id: str) -> list[tuple[str, str, str]]:
        """
        è§£æLLMè¿”å›çš„è¡¨è¾¾é£æ ¼æ€»ç»“ï¼Œæ¯ä¸€è¡Œæå–"å½“"å’Œ"ä½¿ç”¨"ä¹‹é—´çš„å†…å®¹ï¼Œå­˜å‚¨ä¸º(situation, style)å…ƒç»„
        æ”¯æŒå¤šç§å¼•å·æ ¼å¼ï¼š"" å’Œ ""
        """
        expressions: list[tuple[str, str, str]] = []
        failed_lines = []

        for line_num, line in enumerate(response.splitlines(), 1):
            line = line.strip()
            if not line:
                continue

            # æ›¿æ¢ä¸­æ–‡å¼•å·ä¸ºè‹±æ–‡å¼•å·ï¼Œä¾¿äºç»Ÿä¸€å¤„ç†
            line_normalized = line.replace('"', '"').replace('"', '"').replace("'", '"').replace("'", '"')

            # æŸ¥æ‰¾"å½“"å’Œä¸‹ä¸€ä¸ªå¼•å·
            idx_when = line_normalized.find('å½“"')
            if idx_when == -1:
                # å°è¯•ä¸å¸¦å¼•å·çš„æ ¼å¼: å½“xxxæ—¶
                idx_when = line_normalized.find("å½“")
                if idx_when == -1:
                    failed_lines.append((line_num, line, "æ‰¾ä¸åˆ°'å½“'å…³é”®å­—"))
                    continue

                # æå–"å½“"å’Œ"æ—¶"ä¹‹é—´çš„å†…å®¹
                idx_shi = line_normalized.find("æ—¶", idx_when)
                if idx_shi == -1:
                    failed_lines.append((line_num, line, "æ‰¾ä¸åˆ°'æ—¶'å…³é”®å­—"))
                    continue
                situation = line_normalized[idx_when + 1:idx_shi].strip('"\'""')
                search_start = idx_shi
            else:
                idx_quote1 = idx_when + 1
                idx_quote2 = line_normalized.find('"', idx_quote1 + 1)
                if idx_quote2 == -1:
                    failed_lines.append((line_num, line, "situationéƒ¨åˆ†å¼•å·ä¸åŒ¹é…"))
                    continue
                situation = line_normalized[idx_quote1 + 1 : idx_quote2]
                search_start = idx_quote2

            # æŸ¥æ‰¾"ä½¿ç”¨"æˆ–"å¯ä»¥"
            idx_use = line_normalized.find('ä½¿ç”¨"', search_start)
            if idx_use == -1:
                idx_use = line_normalized.find('å¯ä»¥"', search_start)
                if idx_use == -1:
                    # å°è¯•ä¸å¸¦å¼•å·çš„æ ¼å¼
                    idx_use = line_normalized.find("ä½¿ç”¨", search_start)
                    if idx_use == -1:
                        idx_use = line_normalized.find("å¯ä»¥", search_start)
                        if idx_use == -1:
                            failed_lines.append((line_num, line, "æ‰¾ä¸åˆ°'ä½¿ç”¨'æˆ–'å¯ä»¥'å…³é”®å­—"))
                            continue

                    # æå–å‰©ä½™éƒ¨åˆ†ä½œä¸ºstyle
                    style = line_normalized[idx_use + 2:].strip('"\'""ï¼Œã€‚')
                    if not style:
                        failed_lines.append((line_num, line, "styleéƒ¨åˆ†ä¸ºç©º"))
                        continue
                else:
                    idx_quote3 = idx_use + 2
                    idx_quote4 = line_normalized.find('"', idx_quote3 + 1)
                    if idx_quote4 == -1:
                        # å¦‚æœæ²¡æœ‰ç»“æŸå¼•å·ï¼Œå–åˆ°è¡Œå°¾
                        style = line_normalized[idx_quote3 + 1:].strip('"\'""')
                    else:
                        style = line_normalized[idx_quote3 + 1 : idx_quote4]
            else:
                idx_quote3 = idx_use + 2
                idx_quote4 = line_normalized.find('"', idx_quote3 + 1)
                if idx_quote4 == -1:
                    # å¦‚æœæ²¡æœ‰ç»“æŸå¼•å·ï¼Œå–åˆ°è¡Œå°¾
                    style = line_normalized[idx_quote3 + 1:].strip('"\'""')
                else:
                    style = line_normalized[idx_quote3 + 1 : idx_quote4]

            # æ¸…ç†å¹¶éªŒè¯
            situation = situation.strip()
            style = style.strip()

            if not situation or not style:
                failed_lines.append((line_num, line, f"situationæˆ–styleä¸ºç©º: situation='{situation}', style='{style}'"))
                continue

            expressions.append((chat_id, situation, style))

        # è®°å½•è§£æå¤±è´¥çš„è¡Œ
        if failed_lines:
            logger.warning(f"è§£æè¡¨è¾¾æ–¹å¼æ—¶æœ‰ {len(failed_lines)} è¡Œå¤±è´¥:")
            for line_num, line, reason in failed_lines[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                logger.warning(f"  è¡Œ{line_num}: {reason}")
                logger.debug(f"    åŸæ–‡: {line}")

        if not expressions:
            logger.warning(f"LLMè¿”å›äº†å†…å®¹ä½†æ— æ³•è§£æä»»ä½•è¡¨è¾¾æ–¹å¼ã€‚å“åº”é¢„è§ˆ:\n{response[:500]}")
        else:
            logger.debug(f"æˆåŠŸè§£æ {len(expressions)} ä¸ªè¡¨è¾¾æ–¹å¼")
        return expressions


init_prompt()


class ExpressionLearnerManager:
    def __init__(self):
        self.expression_learners = {}

        self._ensure_expression_directories()

    async def get_expression_learner(self, chat_id: str) -> ExpressionLearner:
        await self._auto_migrate_json_to_db()
        await self._migrate_old_data_create_date()

        if chat_id not in self.expression_learners:
            self.expression_learners[chat_id] = ExpressionLearner(chat_id)
        return self.expression_learners[chat_id]

    @staticmethod
    def _ensure_expression_directories():
        """
        ç¡®ä¿è¡¨è¾¾æ–¹å¼ç›¸å…³çš„ç›®å½•ç»“æ„å­˜åœ¨
        """
        base_dir = os.path.join("data", "expression")
        directories_to_create = [
            base_dir,
            os.path.join(base_dir, "learnt_style"),
            os.path.join(base_dir, "learnt_grammar"),
        ]

        for directory in directories_to_create:
            try:
                os.makedirs(directory, exist_ok=True)
                logger.debug(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {directory}")
            except Exception as e:
                logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {directory}: {e}")

    @staticmethod
    async def _auto_migrate_json_to_db():
        """
        è‡ªåŠ¨å°†/data/expression/learnt_style å’Œ learnt_grammar ä¸‹æ‰€æœ‰expressions.jsonè¿ç§»åˆ°æ•°æ®åº“ã€‚
        è¿ç§»å®Œæˆååœ¨/data/expression/done.doneå†™å…¥æ ‡è®°æ–‡ä»¶ï¼Œå­˜åœ¨åˆ™è·³è¿‡ã€‚
        """
        base_dir = os.path.join("data", "expression")
        done_flag = os.path.join(base_dir, "done.done")

        # ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
        try:
            os.makedirs(base_dir, exist_ok=True)
            logger.debug(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {base_dir}")
        except Exception as e:
            logger.error(f"åˆ›å»ºè¡¨è¾¾æ–¹å¼ç›®å½•å¤±è´¥: {e}")
            return

        if os.path.exists(done_flag):
            logger.debug("è¡¨è¾¾æ–¹å¼JSONå·²è¿ç§»ï¼Œæ— éœ€é‡å¤è¿ç§»ã€‚")
            return

        logger.info("å¼€å§‹è¿ç§»è¡¨è¾¾æ–¹å¼JSONåˆ°æ•°æ®åº“...")
        migrated_count = 0

        for type in ["learnt_style", "learnt_grammar"]:
            type_str = "style" if type == "learnt_style" else "grammar"
            type_dir = os.path.join(base_dir, type)
            if not os.path.exists(type_dir):
                logger.debug(f"ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {type_dir}")
                continue

            try:
                chat_ids = os.listdir(type_dir)
                logger.debug(f"åœ¨ {type_dir} ä¸­æ‰¾åˆ° {len(chat_ids)} ä¸ªèŠå¤©IDç›®å½•")
            except Exception as e:
                logger.error(f"è¯»å–ç›®å½•å¤±è´¥ {type_dir}: {e}")
                continue

            for chat_id in chat_ids:
                expr_file = os.path.join(type_dir, chat_id, "expressions.json")
                if not os.path.exists(expr_file):
                    continue
                try:
                    async with aiofiles.open(expr_file, encoding="utf-8") as f:
                        content = await f.read()
                        expressions = orjson.loads(content)

                    if not isinstance(expressions, list):
                        logger.warning(f"è¡¨è¾¾æ–¹å¼æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {expr_file}")
                        continue

                    for expr in expressions:
                        if not isinstance(expr, dict):
                            continue

                        situation = expr.get("situation")
                        style_val = expr.get("style")
                        count = expr.get("count", 1)
                        last_active_time = expr.get("last_active_time", time.time())

                        if not situation or not style_val:
                            logger.warning(f"è¡¨è¾¾æ–¹å¼ç¼ºå°‘å¿…è¦å­—æ®µï¼Œè·³è¿‡: {expr}")
                            continue

                        # æŸ¥é‡ï¼šåŒchat_id+type+situation+style
                        async with get_db_session() as session:
                            query = await session.execute(
                                select(Expression).where(
                                    (Expression.chat_id == chat_id)
                                    & (Expression.type == type_str)
                                    & (Expression.situation == situation)
                                    & (Expression.style == style_val)
                                )
                            )
                            existing_expr = query.scalar()
                            if existing_expr:
                                expr_obj = existing_expr
                                expr_obj.count = max(expr_obj.count, count)
                                expr_obj.last_active_time = max(expr_obj.last_active_time, last_active_time)
                            else:
                                new_expression = Expression(
                                    situation=situation,
                                    style=style_val,
                                    count=count,
                                    last_active_time=last_active_time,
                                    chat_id=chat_id,
                                    type=type_str,
                                    create_date=last_active_time,  # è¿ç§»æ—¶ä½¿ç”¨last_active_timeä½œä¸ºåˆ›å»ºæ—¶é—´
                                )
                                session.add(new_expression)

                                migrated_count += 1
                    logger.info(f"å·²è¿ç§» {expr_file} åˆ°æ•°æ®åº“ï¼ŒåŒ…å« {len(expressions)} ä¸ªè¡¨è¾¾æ–¹å¼")
                except orjson.JSONDecodeError as e:
                    logger.error(f"JSONè§£æå¤±è´¥ {expr_file}: {e}")
                except Exception as e:
                    logger.error(f"è¿ç§»è¡¨è¾¾æ–¹å¼ {expr_file} å¤±è´¥: {e}")

        # æ ‡è®°è¿ç§»å®Œæˆ
        try:
            # ç¡®ä¿done.doneæ–‡ä»¶çš„çˆ¶ç›®å½•å­˜åœ¨
            done_parent_dir = os.path.dirname(done_flag)
            if not os.path.exists(done_parent_dir):
                os.makedirs(done_parent_dir, exist_ok=True)
                logger.debug(f"ä¸ºdone.doneåˆ›å»ºçˆ¶ç›®å½•: {done_parent_dir}")

            async with aiofiles.open(done_flag, "w", encoding="utf-8") as f:
                await f.write("done\n")
            logger.info(f"è¡¨è¾¾æ–¹å¼JSONè¿ç§»å·²å®Œæˆï¼Œå…±è¿ç§» {migrated_count} ä¸ªè¡¨è¾¾æ–¹å¼ï¼Œå·²å†™å…¥done.doneæ ‡è®°æ–‡ä»¶")
        except PermissionError as e:
            logger.error(f"æƒé™ä¸è¶³ï¼Œæ— æ³•å†™å…¥done.doneæ ‡è®°æ–‡ä»¶: {e}")
        except OSError as e:
            logger.error(f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯ï¼Œæ— æ³•å†™å…¥done.doneæ ‡è®°æ–‡ä»¶: {e}")
        except Exception as e:
            logger.error(f"å†™å…¥done.doneæ ‡è®°æ–‡ä»¶å¤±è´¥: {e}")

    @staticmethod
    async def _migrate_old_data_create_date():
        """
        ä¸ºæ²¡æœ‰create_dateçš„è€æ•°æ®è®¾ç½®åˆ›å»ºæ—¥æœŸ
        ä½¿ç”¨last_active_timeä½œä¸ºcreate_dateçš„é»˜è®¤å€¼
        """
        try:
            async with get_db_session() as session:
                # æŸ¥æ‰¾æ‰€æœ‰create_dateä¸ºç©ºçš„è¡¨è¾¾æ–¹å¼
                old_expressions_result = await session.execute(
                    select(Expression).where(Expression.create_date.is_(None))
                )
                old_expressions = old_expressions_result.scalars().all()
                updated_count = 0

                for expr in old_expressions:
                    # ä½¿ç”¨last_active_timeä½œä¸ºcreate_date
                    expr.create_date = expr.last_active_time
                    updated_count += 1

                if updated_count > 0:
                    logger.info(f"å·²ä¸º {updated_count} ä¸ªè€çš„è¡¨è¾¾æ–¹å¼è®¾ç½®åˆ›å»ºæ—¥æœŸ")
        except Exception as e:
            logger.error(f"è¿ç§»è€æ•°æ®åˆ›å»ºæ—¥æœŸå¤±è´¥: {e}")


expression_learner_manager = ExpressionLearnerManager()
