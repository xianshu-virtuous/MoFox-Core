# -*- coding: utf-8 -*-
"""
ç»“æ„åŒ–è®°å¿†å•å…ƒè®¾è®¡
å®ç°é«˜è´¨é‡ã€ç»“æ„åŒ–çš„è®°å¿†å•å…ƒï¼Œç¬¦åˆæ–‡æ¡£è®¾è®¡è§„èŒƒ
"""

import time
import uuid
import orjson
from typing import Dict, List, Optional, Any, Union, Iterable
from dataclasses import dataclass, field, asdict
from datetime import datetime
from enum import Enum
import hashlib

import numpy as np
from src.common.logger import get_logger

logger = get_logger(__name__)


class MemoryType(Enum):
    """è®°å¿†ç±»å‹åˆ†ç±»"""
    PERSONAL_FACT = "personal_fact"      # ä¸ªäººäº‹å®ï¼ˆå§“åã€èŒä¸šã€ä½å€ç­‰ï¼‰
    EVENT = "event"                     # äº‹ä»¶ï¼ˆé‡è¦ç»å†ã€çº¦ä¼šç­‰ï¼‰
    PREFERENCE = "preference"           # åå¥½ï¼ˆå–œå¥½ã€ä¹ æƒ¯ç­‰ï¼‰
    OPINION = "opinion"                 # è§‚ç‚¹ï¼ˆå¯¹äº‹ç‰©çš„çœ‹æ³•ï¼‰
    RELATIONSHIP = "relationship"       # å…³ç³»ï¼ˆä¸ä»–äººçš„å…³ç³»ï¼‰
    EMOTION = "emotion"                 # æƒ…æ„ŸçŠ¶æ€
    KNOWLEDGE = "knowledge"             # çŸ¥è¯†ä¿¡æ¯
    SKILL = "skill"                     # æŠ€èƒ½èƒ½åŠ›
    GOAL = "goal"                       # ç›®æ ‡è®¡åˆ’
    EXPERIENCE = "experience"           # ç»éªŒæ•™è®­
    CONTEXTUAL = "contextual"            # ä¸Šä¸‹æ–‡ä¿¡æ¯


class ConfidenceLevel(Enum):
    """ç½®ä¿¡åº¦ç­‰çº§"""
    LOW = 1        # ä½ç½®ä¿¡åº¦ï¼Œå¯èƒ½ä¸å‡†ç¡®
    MEDIUM = 2     # ä¸­ç­‰ç½®ä¿¡åº¦ï¼Œæœ‰ä¸€å®šä¾æ®
    HIGH = 3       # é«˜ç½®ä¿¡åº¦ï¼Œæœ‰æ˜ç¡®æ¥æº
    VERIFIED = 4   # å·²éªŒè¯ï¼Œéå¸¸å¯é 


class ImportanceLevel(Enum):
    """é‡è¦æ€§ç­‰çº§"""
    LOW = 1        # ä½é‡è¦æ€§ï¼Œæ™®é€šä¿¡æ¯
    NORMAL = 2     # ä¸€èˆ¬é‡è¦æ€§ï¼Œæ—¥å¸¸ä¿¡æ¯
    HIGH = 3       # é«˜é‡è¦æ€§ï¼Œé‡è¦ä¿¡æ¯
    CRITICAL = 4   # å…³é”®é‡è¦æ€§ï¼Œæ ¸å¿ƒä¿¡æ¯


@dataclass
class ContentStructure:
    """ä¸»è°“å®¾ç»“æ„ï¼ŒåŒ…å«è‡ªç„¶è¯­è¨€æè¿°"""

    subject: Union[str, List[str]]
    predicate: str
    object: Union[str, Dict]
    display: str = ""

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "subject": self.subject,
            "predicate": self.predicate,
            "object": self.object,
            "display": self.display
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "ContentStructure":
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹"""
        return cls(
            subject=data.get("subject", ""),
            predicate=data.get("predicate", ""),
            object=data.get("object", ""),
            display=data.get("display", "")
        )

    def to_subject_list(self) -> List[str]:
        """å°†ä¸»è¯­è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼"""
        if isinstance(self.subject, list):
            return [s for s in self.subject if isinstance(s, str) and s.strip()]
        if isinstance(self.subject, str) and self.subject.strip():
            return [self.subject.strip()]
        return []

    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        if self.display:
            return self.display
        subjects = "ã€".join(self.to_subject_list()) or str(self.subject)
        object_str = self.object if isinstance(self.object, str) else str(self.object)
        return f"{subjects} {self.predicate} {object_str}".strip()


@dataclass
class MemoryMetadata:
    """è®°å¿†å…ƒæ•°æ® - ç®€åŒ–ç‰ˆæœ¬"""
    # åŸºç¡€ä¿¡æ¯
    memory_id: str                  # å”¯ä¸€æ ‡è¯†ç¬¦
    user_id: str                    # ç”¨æˆ·ID
    chat_id: Optional[str] = None   # èŠå¤©IDï¼ˆç¾¤èŠæˆ–ç§èŠï¼‰

    # æ—¶é—´ä¿¡æ¯
    created_at: float = 0.0         # åˆ›å»ºæ—¶é—´æˆ³
    last_accessed: float = 0.0      # æœ€åè®¿é—®æ—¶é—´
    last_modified: float = 0.0      # æœ€åä¿®æ”¹æ—¶é—´

    # æ¿€æ´»é¢‘ç‡ç®¡ç†
    last_activation_time: float = 0.0    # æœ€åæ¿€æ´»æ—¶é—´
    activation_frequency: int = 0        # æ¿€æ´»é¢‘ç‡ï¼ˆå•ä½æ—¶é—´å†…çš„æ¿€æ´»æ¬¡æ•°ï¼‰
    total_activations: int = 0           # æ€»æ¿€æ´»æ¬¡æ•°

    # ç»Ÿè®¡ä¿¡æ¯
    access_count: int = 0           # è®¿é—®æ¬¡æ•°
    relevance_score: float = 0.0    # ç›¸å…³åº¦è¯„åˆ†

    # ä¿¡å¿ƒå’Œé‡è¦æ€§ï¼ˆæ ¸å¿ƒå­—æ®µï¼‰
    confidence: ConfidenceLevel = ConfidenceLevel.MEDIUM
    importance: ImportanceLevel = ImportanceLevel.NORMAL

    # é—å¿˜æœºåˆ¶ç›¸å…³
    forgetting_threshold: float = 0.0  # é—å¿˜é˜ˆå€¼ï¼ˆåŠ¨æ€è®¡ç®—ï¼‰
    last_forgetting_check: float = 0.0 # ä¸Šæ¬¡é—å¿˜æ£€æŸ¥æ—¶é—´

    # æ¥æºä¿¡æ¯
    source_context: Optional[str] = None    # æ¥æºä¸Šä¸‹æ–‡ç‰‡æ®µ

    def __post_init__(self):
        """ååˆå§‹åŒ–å¤„ç†"""
        if not self.memory_id:
            self.memory_id = str(uuid.uuid4())

        current_time = time.time()

        if self.created_at == 0:
            self.created_at = current_time

        if self.last_accessed == 0:
            self.last_accessed = current_time

        if self.last_modified == 0:
            self.last_modified = current_time

        if self.last_activation_time == 0:
            self.last_activation_time = current_time

        if self.last_forgetting_check == 0:
            self.last_forgetting_check = current_time

    def update_access(self):
        """æ›´æ–°è®¿é—®ä¿¡æ¯"""
        current_time = time.time()
        self.last_accessed = current_time
        self.access_count += 1
        self.total_activations += 1

        # æ›´æ–°æ¿€æ´»é¢‘ç‡
        self._update_activation_frequency(current_time)

    def _update_activation_frequency(self, current_time: float):
        """æ›´æ–°æ¿€æ´»é¢‘ç‡ï¼ˆ24å°æ—¶å†…çš„æ¿€æ´»æ¬¡æ•°ï¼‰"""
        from datetime import datetime, timedelta

        # å¦‚æœè¶…è¿‡24å°æ—¶ï¼Œé‡ç½®æ¿€æ´»é¢‘ç‡
        if current_time - self.last_activation_time > 86400:  # 24å°æ—¶ = 86400ç§’
            self.activation_frequency = 1
        else:
            self.activation_frequency += 1

        self.last_activation_time = current_time

    def update_relevance(self, new_score: float):
        """æ›´æ–°ç›¸å…³åº¦è¯„åˆ†"""
        self.relevance_score = max(0.0, min(1.0, new_score))
        self.last_modified = time.time()

    def calculate_forgetting_threshold(self) -> float:
        """è®¡ç®—é—å¿˜é˜ˆå€¼ï¼ˆå¤©æ•°ï¼‰"""
        # åŸºç¡€å¤©æ•°
        base_days = 30.0

        # é‡è¦æ€§æƒé‡ (1-4 -> 0-3)
        importance_weight = (self.importance.value - 1) * 15  # 0, 15, 30, 45

        # ç½®ä¿¡åº¦æƒé‡ (1-4 -> 0-3)
        confidence_weight = (self.confidence.value - 1) * 10  # 0, 10, 20, 30

        # æ¿€æ´»é¢‘ç‡æƒé‡ï¼ˆæ¯5æ¬¡æ¿€æ´»å¢åŠ 1å¤©ï¼‰
        frequency_weight = min(self.activation_frequency, 20) * 0.5  # æœ€å¤š10å¤©

        # è®¡ç®—æœ€ç»ˆé˜ˆå€¼
        threshold = base_days + importance_weight + confidence_weight + frequency_weight

        # è®¾ç½®æœ€å°å’Œæœ€å¤§é˜ˆå€¼
        return max(7.0, min(threshold, 365.0))  # 7å¤©åˆ°1å¹´ä¹‹é—´

    def should_forget(self, current_time: Optional[float] = None) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é—å¿˜"""
        if current_time is None:
            current_time = time.time()

        # è®¡ç®—é—å¿˜é˜ˆå€¼
        self.forgetting_threshold = self.calculate_forgetting_threshold()

        # è®¡ç®—è·ç¦»æœ€åæ¿€æ´»çš„æ—¶é—´
        days_since_activation = (current_time - self.last_activation_time) / 86400

        return days_since_activation > self.forgetting_threshold

    def is_dormant(self, current_time: Optional[float] = None, inactive_days: int = 90) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¤„äºä¼‘çœ çŠ¶æ€ï¼ˆé•¿æœŸæœªæ¿€æ´»ï¼‰"""
        if current_time is None:
            current_time = time.time()

        days_since_last_access = (current_time - self.last_accessed) / 86400
        return days_since_last_access > inactive_days

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "memory_id": self.memory_id,
            "user_id": self.user_id,
            "chat_id": self.chat_id,
            "created_at": self.created_at,
            "last_accessed": self.last_accessed,
            "last_modified": self.last_modified,
            "last_activation_time": self.last_activation_time,
            "activation_frequency": self.activation_frequency,
            "total_activations": self.total_activations,
            "access_count": self.access_count,
            "relevance_score": self.relevance_score,
            "confidence": self.confidence.value,
            "importance": self.importance.value,
            "forgetting_threshold": self.forgetting_threshold,
            "last_forgetting_check": self.last_forgetting_check,
            "source_context": self.source_context
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "MemoryMetadata":
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹"""
        return cls(
            memory_id=data.get("memory_id", ""),
            user_id=data.get("user_id", ""),
            chat_id=data.get("chat_id"),
            created_at=data.get("created_at", 0),
            last_accessed=data.get("last_accessed", 0),
            last_modified=data.get("last_modified", 0),
            last_activation_time=data.get("last_activation_time", 0),
            activation_frequency=data.get("activation_frequency", 0),
            total_activations=data.get("total_activations", 0),
            access_count=data.get("access_count", 0),
            relevance_score=data.get("relevance_score", 0.0),
            confidence=ConfidenceLevel(data.get("confidence", ConfidenceLevel.MEDIUM.value)),
            importance=ImportanceLevel(data.get("importance", ImportanceLevel.NORMAL.value)),
            forgetting_threshold=data.get("forgetting_threshold", 0.0),
            last_forgetting_check=data.get("last_forgetting_check", 0),
            source_context=data.get("source_context")
        )


@dataclass
class MemoryChunk:
    """ç»“æ„åŒ–è®°å¿†å•å…ƒ - æ ¸å¿ƒæ•°æ®ç»“æ„"""

    # å…ƒæ•°æ®
    metadata: MemoryMetadata

    # å†…å®¹ç»“æ„
    content: ContentStructure         # ä¸»è°“å®¾ç»“æ„
    memory_type: MemoryType          # è®°å¿†ç±»å‹

    # æ‰©å±•ä¿¡æ¯
    keywords: List[str] = field(default_factory=list)      # å…³é”®è¯åˆ—è¡¨
    tags: List[str] = field(default_factory=list)         # æ ‡ç­¾åˆ—è¡¨
    categories: List[str] = field(default_factory=list)   # åˆ†ç±»åˆ—è¡¨

    # è¯­ä¹‰ä¿¡æ¯
    embedding: Optional[List[float]] = None               # è¯­ä¹‰å‘é‡
    semantic_hash: Optional[str] = None                  # è¯­ä¹‰å“ˆå¸Œå€¼

    # å…³è”ä¿¡æ¯
    related_memories: List[str] = field(default_factory=list)  # å…³è”è®°å¿†IDåˆ—è¡¨
    temporal_context: Optional[Dict[str, Any]] = None   # æ—¶é—´ä¸Šä¸‹æ–‡

    def __post_init__(self):
        """ååˆå§‹åŒ–å¤„ç†"""
        if self.embedding and len(self.embedding) > 0:
            self._generate_semantic_hash()

    def _generate_semantic_hash(self):
        """ç”Ÿæˆè¯­ä¹‰å“ˆå¸Œå€¼"""
        if not self.embedding:
            return

        try:
            # ä½¿ç”¨å‘é‡å’Œå†…å®¹ç”Ÿæˆç¨³å®šçš„å“ˆå¸Œ
            content_str = f"{self.content.subject}:{self.content.predicate}:{str(self.content.object)}"
            embedding_str = ",".join(map(str, [round(x, 6) for x in self.embedding]))

            hash_input = f"{content_str}|{embedding_str}"
            hash_object = hashlib.sha256(hash_input.encode('utf-8'))
            self.semantic_hash = hash_object.hexdigest()[:16]

        except Exception as e:
            logger.warning(f"ç”Ÿæˆè¯­ä¹‰å“ˆå¸Œå¤±è´¥: {e}")
            self.semantic_hash = str(uuid.uuid4())[:16]

    @property
    def memory_id(self) -> str:
        """è·å–è®°å¿†ID"""
        return self.metadata.memory_id

    @property
    def user_id(self) -> str:
        """è·å–ç”¨æˆ·ID"""
        return self.metadata.user_id

    @property
    def text_content(self) -> str:
        """è·å–æ–‡æœ¬å†…å®¹ï¼ˆä¼˜å…ˆä½¿ç”¨displayï¼‰"""
        return str(self.content)

    @property
    def display(self) -> str:
        """è·å–å±•ç¤ºæ–‡æœ¬"""
        return self.content.display or str(self.content)

    @property
    def subjects(self) -> List[str]:
        """è·å–ä¸»è¯­åˆ—è¡¨"""
        return self.content.to_subject_list()

    def update_access(self):
        """æ›´æ–°è®¿é—®ä¿¡æ¯"""
        self.metadata.update_access()

    def update_relevance(self, new_score: float):
        """æ›´æ–°ç›¸å…³åº¦è¯„åˆ†"""
        self.metadata.update_relevance(new_score)

    def should_forget(self, current_time: Optional[float] = None) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é—å¿˜"""
        return self.metadata.should_forget(current_time)

    def is_dormant(self, current_time: Optional[float] = None, inactive_days: int = 90) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¤„äºä¼‘çœ çŠ¶æ€ï¼ˆé•¿æœŸæœªæ¿€æ´»ï¼‰"""
        return self.metadata.is_dormant(current_time, inactive_days)

    def calculate_forgetting_threshold(self) -> float:
        """è®¡ç®—é—å¿˜é˜ˆå€¼ï¼ˆå¤©æ•°ï¼‰"""
        return self.metadata.calculate_forgetting_threshold()

    def add_keyword(self, keyword: str):
        """æ·»åŠ å…³é”®è¯"""
        if keyword and keyword not in self.keywords:
            self.keywords.append(keyword.strip())

    def add_tag(self, tag: str):
        """æ·»åŠ æ ‡ç­¾"""
        if tag and tag not in self.tags:
            self.tags.append(tag.strip())

    def add_category(self, category: str):
        """æ·»åŠ åˆ†ç±»"""
        if category and category not in self.categories:
            self.categories.append(category.strip())

    def add_related_memory(self, memory_id: str):
        """æ·»åŠ å…³è”è®°å¿†"""
        if memory_id and memory_id not in self.related_memories:
            self.related_memories.append(memory_id)

    def set_embedding(self, embedding: List[float]):
        """è®¾ç½®è¯­ä¹‰å‘é‡"""
        self.embedding = embedding
        self._generate_semantic_hash()

    def calculate_similarity(self, other: "MemoryChunk") -> float:
        """è®¡ç®—ä¸å¦ä¸€ä¸ªè®°å¿†å—çš„ç›¸ä¼¼åº¦"""
        if not self.embedding or not other.embedding:
            return 0.0

        try:
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            v1 = np.array(self.embedding)
            v2 = np.array(other.embedding)

            dot_product = np.dot(v1, v2)
            norm1 = np.linalg.norm(v1)
            norm2 = np.linalg.norm(v2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            similarity = dot_product / (norm1 * norm2)
            return max(0.0, min(1.0, similarity))

        except Exception as e:
            logger.warning(f"è®¡ç®—è®°å¿†ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå®Œæ•´çš„å­—å…¸æ ¼å¼"""
        return {
            "metadata": self.metadata.to_dict(),
            "content": self.content.to_dict(),
            "memory_type": self.memory_type.value,
            "keywords": self.keywords,
            "tags": self.tags,
            "categories": self.categories,
            "embedding": self.embedding,
            "semantic_hash": self.semantic_hash,
            "related_memories": self.related_memories,
            "temporal_context": self.temporal_context
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "MemoryChunk":
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹"""
        metadata = MemoryMetadata.from_dict(data.get("metadata", {}))
        content = ContentStructure.from_dict(data.get("content", {}))

        chunk = cls(
            metadata=metadata,
            content=content,
            memory_type=MemoryType(data.get("memory_type", MemoryType.CONTEXTUAL.value)),
            keywords=data.get("keywords", []),
            tags=data.get("tags", []),
            categories=data.get("categories", []),
            embedding=data.get("embedding"),
            semantic_hash=data.get("semantic_hash"),
            related_memories=data.get("related_memories", []),
            temporal_context=data.get("temporal_context")
        )

        return chunk

    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        return orjson.dumps(self.to_dict(), ensure_ascii=False).decode('utf-8')

    @classmethod
    def from_json(cls, json_str: str) -> "MemoryChunk":
        """ä»JSONå­—ç¬¦ä¸²åˆ›å»ºå®ä¾‹"""
        try:
            data = orjson.loads(json_str)
            return cls.from_dict(data)
        except Exception as e:
            logger.error(f"ä»JSONåˆ›å»ºè®°å¿†å—å¤±è´¥: {e}")
            raise

    def is_similar_to(self, other: "MemoryChunk", threshold: float = 0.8) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸å¦ä¸€ä¸ªè®°å¿†å—ç›¸ä¼¼"""
        if self.semantic_hash and other.semantic_hash:
            return self.semantic_hash == other.semantic_hash

        return self.calculate_similarity(other) >= threshold

    def merge_with(self, other: "MemoryChunk") -> bool:
        """ä¸å¦ä¸€ä¸ªè®°å¿†å—åˆå¹¶ï¼ˆå¦‚æœç›¸ä¼¼ï¼‰"""
        if not self.is_similar_to(other):
            return False

        try:
            # åˆå¹¶å…³é”®è¯
            for keyword in other.keywords:
                self.add_keyword(keyword)

            # åˆå¹¶æ ‡ç­¾
            for tag in other.tags:
                self.add_tag(tag)

            # åˆå¹¶åˆ†ç±»
            for category in other.categories:
                self.add_category(category)

            # åˆå¹¶å…³è”è®°å¿†
            for memory_id in other.related_memories:
                self.add_related_memory(memory_id)

            # æ›´æ–°å…ƒæ•°æ®
            self.metadata.last_modified = time.time()
            self.metadata.access_count += other.metadata.access_count
            self.metadata.relevance_score = max(self.metadata.relevance_score, other.metadata.relevance_score)

            # æ›´æ–°ç½®ä¿¡åº¦
            if other.metadata.confidence.value > self.metadata.confidence.value:
                self.metadata.confidence = other.metadata.confidence

            # æ›´æ–°é‡è¦æ€§
            if other.metadata.importance.value > self.metadata.importance.value:
                self.metadata.importance = other.metadata.importance

            logger.debug(f"è®°å¿†å— {self.memory_id} åˆå¹¶äº†è®°å¿†å— {other.memory_id}")
            return True

        except Exception as e:
            logger.error(f"åˆå¹¶è®°å¿†å—å¤±è´¥: {e}")
            return False

    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        type_emoji = {
            MemoryType.PERSONAL_FACT: "ğŸ‘¤",
            MemoryType.EVENT: "ğŸ“…",
            MemoryType.PREFERENCE: "â¤ï¸",
            MemoryType.OPINION: "ğŸ’­",
            MemoryType.RELATIONSHIP: "ğŸ‘¥",
            MemoryType.EMOTION: "ğŸ˜Š",
            MemoryType.KNOWLEDGE: "ğŸ“š",
            MemoryType.SKILL: "ğŸ› ï¸",
            MemoryType.GOAL: "ğŸ¯",
            MemoryType.EXPERIENCE: "ğŸ’¡",
            MemoryType.CONTEXTUAL: "ğŸ“"
        }

        emoji = type_emoji.get(self.memory_type, "ğŸ“")
        confidence_icon = "â—" * self.metadata.confidence.value
        importance_icon = "â˜…" * self.metadata.importance.value

        return f"{emoji} [{self.memory_type.value}] {self.display} {confidence_icon} {importance_icon}"

    def __repr__(self) -> str:
        """è°ƒè¯•è¡¨ç¤º"""
        return f"MemoryChunk(id={self.memory_id[:8]}..., type={self.memory_type.value}, user={self.user_id})"


def _build_display_text(subjects: Iterable[str], predicate: str, obj: Union[str, Dict]) -> str:
    """æ ¹æ®ä¸»è°“å®¾ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°"""
    subjects_clean = [s.strip() for s in subjects if s and isinstance(s, str)]
    subject_part = "ã€".join(subjects_clean) if subjects_clean else "å¯¹è¯å‚ä¸è€…"

    if isinstance(obj, dict):
        object_candidates = []
        for key, value in obj.items():
            if isinstance(value, (str, int, float)):
                object_candidates.append(f"{key}:{value}")
            elif isinstance(value, list):
                compact = "ã€".join(str(item) for item in value[:3])
                object_candidates.append(f"{key}:{compact}")
        object_part = "ï¼Œ".join(object_candidates) if object_candidates else str(obj)
    else:
        object_part = str(obj).strip()

    predicate_clean = predicate.strip()
    if not predicate_clean:
        return f"{subject_part} {object_part}".strip()

    if object_part:
        return f"{subject_part}{predicate_clean}{object_part}".strip()
    return f"{subject_part}{predicate_clean}".strip()


def create_memory_chunk(
    user_id: str,
    subject: Union[str, List[str]],
    predicate: str,
    obj: Union[str, Dict],
    memory_type: MemoryType,
    chat_id: Optional[str] = None,
    source_context: Optional[str] = None,
    importance: ImportanceLevel = ImportanceLevel.NORMAL,
    confidence: ConfidenceLevel = ConfidenceLevel.MEDIUM,
    display: Optional[str] = None,
    **kwargs
) -> MemoryChunk:
    """ä¾¿æ·çš„å†…å­˜å—åˆ›å»ºå‡½æ•°"""
    metadata = MemoryMetadata(
        memory_id="",
        user_id=user_id,
        chat_id=chat_id,
        created_at=time.time(),
        last_accessed=0,
        last_modified=0,
        confidence=confidence,
        importance=importance,
        source_context=source_context
    )

    subjects: List[str]
    if isinstance(subject, list):
        subjects = [s for s in subject if isinstance(s, str) and s.strip()]
        subject_payload: Union[str, List[str]] = subjects
    else:
        cleaned = subject.strip() if isinstance(subject, str) else ""
        subjects = [cleaned] if cleaned else []
        subject_payload = cleaned

    display_text = display or _build_display_text(subjects, predicate, obj)

    content = ContentStructure(
        subject=subject_payload,
        predicate=predicate,
        object=obj,
        display=display_text
    )

    chunk = MemoryChunk(
        metadata=metadata,
        content=content,
        memory_type=memory_type,
        **kwargs
    )

    return chunk