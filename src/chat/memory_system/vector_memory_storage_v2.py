"""
åŸºäºVector DBçš„ç»Ÿä¸€è®°å¿†å­˜å‚¨ç³»ç»Ÿ V2
ä½¿ç”¨ChromaDBä½œä¸ºåº•å±‚å­˜å‚¨ï¼Œæ›¿ä»£JSONå­˜å‚¨æ–¹å¼

ä¸»è¦ç‰¹æ€§:
- ç»Ÿä¸€çš„å‘é‡å­˜å‚¨æ¥å£
- é«˜æ•ˆçš„è¯­ä¹‰æ£€ç´¢
- å…ƒæ•°æ®è¿‡æ»¤æ”¯æŒ
- æ‰¹é‡æ“ä½œä¼˜åŒ–
- è‡ªåŠ¨æ¸…ç†è¿‡æœŸè®°å¿†
"""

import asyncio
import threading
import time
from dataclasses import dataclass
from datetime import datetime
from typing import Any

import orjson

from src.chat.memory_system.memory_chunk import ConfidenceLevel, ImportanceLevel, MemoryChunk
from src.chat.memory_system.memory_forgetting_engine import MemoryForgettingEngine
from src.chat.memory_system.memory_metadata_index import MemoryMetadataIndex, MemoryMetadataIndexEntry
from src.chat.utils.utils import get_embedding
from src.common.logger import get_logger
from src.common.vector_db import vector_db_service

logger = get_logger(__name__)

# å…¨å±€æšä¸¾æ˜ å°„è¡¨ç¼“å­˜
_ENUM_MAPPINGS_CACHE = {}


def _build_enum_mapping(enum_class: type) -> dict[str, Any]:
    """æ„å»ºæšä¸¾ç±»çš„å®Œæ•´æ˜ å°„è¡¨

    Args:
        enum_class: æšä¸¾ç±»

    Returns:
        Dict[str, Any]: åŒ…å«å„ç§æ˜ å°„æ ¼å¼çš„å­—å…¸
    """
    cache_key = f"{enum_class.__module__}.{enum_class.__name__}"

    # å¦‚æœå·²ç»ç¼“å­˜è¿‡ï¼Œç›´æ¥è¿”å›
    if cache_key in _ENUM_MAPPINGS_CACHE:
        return _ENUM_MAPPINGS_CACHE[cache_key]

    mapping = {
        "name_to_enum": {},  # æšä¸¾åç§° -> æšä¸¾å®ä¾‹ (HIGH -> ImportanceLevel.HIGH)
        "value_to_enum": {},  # æ•´æ•°å€¼ -> æšä¸¾å®ä¾‹ (3 -> ImportanceLevel.HIGH)
        "value_str_to_enum": {},  # å­—ç¬¦ä¸²value -> æšä¸¾å®ä¾‹ ("3" -> ImportanceLevel.HIGH)
        "enum_value_to_name": {},  # æšä¸¾å®ä¾‹ -> åç§°æ˜ å°„ (åå‘)
        "all_possible_strings": set(),  # æ‰€æœ‰å¯èƒ½çš„å­—ç¬¦ä¸²è¡¨ç¤º
    }

    for member in enum_class:
        # åç§°æ˜ å°„ (æ”¯æŒå¤§å°å†™)
        mapping["name_to_enum"][member.name] = member
        mapping["name_to_enum"][member.name.lower()] = member
        mapping["name_to_enum"][member.name.upper()] = member

        # å€¼æ˜ å°„
        mapping["value_to_enum"][member.value] = member
        mapping["value_str_to_enum"][str(member.value)] = member

        # åå‘æ˜ å°„
        mapping["enum_value_to_name"][member] = member.name

        # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„å­—ç¬¦ä¸²è¡¨ç¤º
        mapping["all_possible_strings"].add(member.name)
        mapping["all_possible_strings"].add(member.name.lower())
        mapping["all_possible_strings"].add(member.name.upper())
        mapping["all_possible_strings"].add(str(member.value))

    # ç¼“å­˜ç»“æœ
    _ENUM_MAPPINGS_CACHE[cache_key] = mapping
    logger.debug(
        f"æ„å»ºæšä¸¾æ˜ å°„è¡¨: {enum_class.__name__} -> {len(mapping['name_to_enum'])} ä¸ªåç§°æ˜ å°„, {len(mapping['value_to_enum'])} ä¸ªå€¼æ˜ å°„"
    )

    return mapping


@dataclass
class VectorStorageConfig:
    """Vectorå­˜å‚¨é…ç½®"""

    # é›†åˆé…ç½®
    memory_collection: str = "unified_memory_v2"
    metadata_collection: str = "memory_metadata_v2"

    # æ£€ç´¢é…ç½®
    similarity_threshold: float = 0.5  # é™ä½é˜ˆå€¼ä»¥æé«˜å¬å›ç‡ï¼ˆ0.5-0.6 æ˜¯åˆç†èŒƒå›´ï¼‰
    search_limit: int = 20
    batch_size: int = 100

    # æ€§èƒ½é…ç½®
    enable_caching: bool = True
    cache_size_limit: int = 1000
    auto_cleanup_interval: int = 3600  # 1å°æ—¶

    # é—å¿˜é…ç½®
    enable_forgetting: bool = True
    retention_hours: int = 24 * 30  # 30å¤©

    @classmethod
    def from_global_config(cls):
        """ä»å…¨å±€é…ç½®åˆ›å»ºå®ä¾‹"""
        from src.config.config import global_config

        memory_cfg = global_config.memory

        return cls(
            memory_collection=getattr(memory_cfg, "vector_db_memory_collection", "unified_memory_v2"),
            metadata_collection=getattr(memory_cfg, "vector_db_metadata_collection", "memory_metadata_v2"),
            similarity_threshold=getattr(memory_cfg, "vector_db_similarity_threshold", 0.5),
            search_limit=getattr(memory_cfg, "vector_db_search_limit", 20),
            batch_size=getattr(memory_cfg, "vector_db_batch_size", 100),
            enable_caching=getattr(memory_cfg, "vector_db_enable_caching", True),
            cache_size_limit=getattr(memory_cfg, "vector_db_cache_size_limit", 1000),
            auto_cleanup_interval=getattr(memory_cfg, "vector_db_auto_cleanup_interval", 3600),
            enable_forgetting=getattr(memory_cfg, "enable_memory_forgetting", True),
            retention_hours=getattr(memory_cfg, "vector_db_retention_hours", 720),
        )


class VectorMemoryStorage:
    @property
    def keyword_index(self) -> dict:
        """
        åŠ¨æ€æ„å»ºå…³é”®è¯å€’æ’ç´¢å¼•ï¼ˆä»…å…¼å®¹æ—§æ¥å£ï¼ŒåŸºäºå½“å‰ç¼“å­˜ï¼‰
        è¿”å›: {keyword: [memory_id, ...]}
        """
        index = {}
        for memory in self.memory_cache.values():
            for kw in getattr(memory, "keywords", []):
                if not kw:
                    continue
                kw_norm = kw.strip().lower()
                if kw_norm:
                    index.setdefault(kw_norm, []).append(getattr(memory.metadata, "memory_id", None))
        return index

    """åŸºäºVector DBçš„è®°å¿†å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, config: VectorStorageConfig | None = None):
        # é»˜è®¤ä»å…¨å±€é…ç½®è¯»å–ï¼Œå¦‚æœæ²¡æœ‰ä¼ å…¥config
        if config is None:
            try:
                self.config = VectorStorageConfig.from_global_config()
                logger.info("âœ… Vectorå­˜å‚¨é…ç½®å·²ä»å…¨å±€é…ç½®åŠ è½½")
            except Exception as e:
                logger.warning(f"ä»å…¨å±€é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
                self.config = VectorStorageConfig()
        else:
            self.config = config

        # ä»é…ç½®ä¸­è·å–æ‰¹å¤„ç†å¤§å°å’Œé›†åˆåç§°
        self.batch_size = self.config.batch_size
        self.collection_name = self.config.memory_collection
        self.vector_db_service = vector_db_service

        # å†…å­˜ç¼“å­˜
        self.memory_cache: dict[str, MemoryChunk] = {}
        self.cache_timestamps: dict[str, float] = {}
        self._cache = self.memory_cache  # åˆ«åï¼Œå…¼å®¹æ—§ä»£ç 

        # å…ƒæ•°æ®ç´¢å¼•ç®¡ç†å™¨ï¼ˆJSONæ–‡ä»¶ç´¢å¼•ï¼‰
        self.metadata_index = MemoryMetadataIndex()

        # é—å¿˜å¼•æ“
        self.forgetting_engine: MemoryForgettingEngine | None = None
        if self.config.enable_forgetting:
            self.forgetting_engine = MemoryForgettingEngine()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_memories": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "total_searches": 0,
            "total_stores": 0,
            "last_cleanup_time": 0.0,
            "forgetting_stats": {},
        }

        # çº¿ç¨‹é”
        self._lock = threading.RLock()

        # å®šæ—¶æ¸…ç†ä»»åŠ¡
        self._cleanup_task = None
        self._stop_cleanup = False

        # åˆå§‹åŒ–ç³»ç»Ÿ
        self._initialize_storage()
        self._start_cleanup_task()

    def _initialize_storage(self):
        """åˆå§‹åŒ–Vector DBå­˜å‚¨"""
        try:
            # åˆ›å»ºè®°å¿†é›†åˆ
            vector_db_service.get_or_create_collection(
                name=self.config.memory_collection,
                metadata={"description": "ç»Ÿä¸€è®°å¿†å­˜å‚¨V2", "hnsw:space": "cosine", "version": "2.0"},
            )

            # åˆ›å»ºå…ƒæ•°æ®é›†åˆï¼ˆç”¨äºå¤æ‚æŸ¥è¯¢ï¼‰
            vector_db_service.get_or_create_collection(
                name=self.config.metadata_collection,
                metadata={"description": "è®°å¿†å…ƒæ•°æ®ç´¢å¼•", "hnsw:space": "cosine", "version": "2.0"},
            )

            # è·å–å½“å‰è®°å¿†æ€»æ•°
            self.stats["total_memories"] = vector_db_service.count(self.config.memory_collection)

            logger.info(f"Vectorè®°å¿†å­˜å‚¨åˆå§‹åŒ–å®Œæˆï¼Œå½“å‰è®°å¿†æ•°: {self.stats['total_memories']}")

        except Exception as e:
            logger.error(f"Vectorå­˜å‚¨ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise

    def _start_cleanup_task(self):
        """å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡"""
        if self.config.auto_cleanup_interval > 0:

            def cleanup_worker():
                while not self._stop_cleanup:
                    try:
                        time.sleep(self.config.auto_cleanup_interval)
                        if not self._stop_cleanup:
                            asyncio.create_task(self._perform_auto_cleanup())
                    except Exception as e:
                        logger.error(f"å®šæ—¶æ¸…ç†ä»»åŠ¡å‡ºé”™: {e}")

            self._cleanup_task = threading.Thread(target=cleanup_worker, daemon=True)
            self._cleanup_task.start()
            logger.info(f"å®šæ—¶æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨ï¼Œé—´éš”: {self.config.auto_cleanup_interval}ç§’")

    async def _perform_auto_cleanup(self):
        """æ‰§è¡Œè‡ªåŠ¨æ¸…ç†"""
        try:
            current_time = time.time()

            # æ¸…ç†è¿‡æœŸç¼“å­˜
            if self.config.enable_caching:
                expired_keys = [
                    memory_id
                    for memory_id, timestamp in self.cache_timestamps.items()
                    if current_time - timestamp > 3600  # 1å°æ—¶è¿‡æœŸ
                ]

                for key in expired_keys:
                    self.memory_cache.pop(key, None)
                    self.cache_timestamps.pop(key, None)

                if expired_keys:
                    logger.debug(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜é¡¹")

            # æ‰§è¡Œé—å¿˜æ£€æŸ¥
            if self.forgetting_engine:
                await self.perform_forgetting_check()

            self.stats["last_cleanup_time"] = current_time

        except Exception as e:
            logger.error(f"è‡ªåŠ¨æ¸…ç†å¤±è´¥: {e}")

    def _memory_to_vector_format(self, memory: MemoryChunk) -> dict[str, Any]:
        """å°†MemoryChunkè½¬æ¢ä¸ºå‘é‡å­˜å‚¨æ ¼å¼"""
        try:
            # è·å–memory_id
            memory_id = getattr(memory.metadata, "memory_id", None) or getattr(memory, "memory_id", None)

            # ç”Ÿæˆå‘é‡è¡¨ç¤ºçš„æ–‡æœ¬
            display_text = (
                getattr(memory, "display", None) or getattr(memory, "text_content", None) or str(memory.content)
            )
            if not display_text.strip():
                logger.warning(f"è®°å¿† {memory_id} ç¼ºå°‘æœ‰æ•ˆçš„æ˜¾ç¤ºæ–‡æœ¬")
                display_text = f"{memory.memory_type.value}: {', '.join(memory.subjects)}"

            # æ„å»ºå…ƒæ•°æ® - ä¿®å¤æšä¸¾å€¼å’Œåˆ—è¡¨åºåˆ—åŒ–
            metadata = {
                "memory_id": memory_id,
                "user_id": memory.metadata.user_id or "unknown",
                "memory_type": memory.memory_type.value,
                "importance": memory.metadata.importance.name,  # ä½¿ç”¨ .name è€Œä¸æ˜¯æšä¸¾å¯¹è±¡
                "confidence": memory.metadata.confidence.name,  # ä½¿ç”¨ .name è€Œä¸æ˜¯æšä¸¾å¯¹è±¡
                "created_at": memory.metadata.created_at,
                "last_accessed": memory.metadata.last_accessed or memory.metadata.created_at,
                "access_count": memory.metadata.access_count,
                "subjects": orjson.dumps(memory.subjects).decode("utf-8"),  # åˆ—è¡¨è½¬JSONå­—ç¬¦ä¸²
                "keywords": orjson.dumps(memory.keywords).decode("utf-8"),  # åˆ—è¡¨è½¬JSONå­—ç¬¦ä¸²
                "tags": orjson.dumps(memory.tags).decode("utf-8"),  # åˆ—è¡¨è½¬JSONå­—ç¬¦ä¸²
                "categories": orjson.dumps(memory.categories).decode("utf-8"),  # åˆ—è¡¨è½¬JSONå­—ç¬¦ä¸²
                "relevance_score": memory.metadata.relevance_score,
            }

            # æ·»åŠ å¯é€‰å­—æ®µ
            if memory.metadata.source_context:
                metadata["source_context"] = str(memory.metadata.source_context)

            if memory.content.predicate:
                metadata["predicate"] = memory.content.predicate

            if memory.content.object:
                if isinstance(memory.content.object, (dict, list)):
                    metadata["object"] = orjson.dumps(memory.content.object).decode()
                else:
                    metadata["object"] = str(memory.content.object)

            return {
                "id": memory_id,
                "embedding": None,  # å°†ç”±vector_db_serviceç”Ÿæˆ
                "metadata": metadata,
                "document": display_text,
            }

        except Exception as e:
            memory_id = getattr(memory.metadata, "memory_id", None) or getattr(memory, "memory_id", "unknown")
            logger.error(f"è½¬æ¢è®°å¿† {memory_id} åˆ°å‘é‡æ ¼å¼å¤±è´¥: {e}", exc_info=True)
            raise

    def _vector_result_to_memory(self, document: str, metadata: dict[str, Any]) -> MemoryChunk | None:
        """å°†Vector DBç»“æœè½¬æ¢ä¸ºMemoryChunk"""
        try:
            # ä»å…ƒæ•°æ®ä¸­æ¢å¤å®Œæ•´è®°å¿†
            if "memory_data" in metadata:
                memory_dict = orjson.loads(metadata["memory_data"])
                return MemoryChunk.from_dict(memory_dict)

            # å…œåº•ï¼šä»åŸºç¡€å­—æ®µé‡å»ºï¼ˆä½¿ç”¨æ–°çš„ç»“æ„åŒ–æ ¼å¼ï¼‰
            logger.warning(f"æœªæ‰¾åˆ°memory_dataï¼Œä½¿ç”¨å…œåº•é€»è¾‘é‡å»ºè®°å¿† (id={metadata.get('memory_id', 'unknown')})")

            # æ„å»ºç¬¦åˆMemoryChunk.from_dictæœŸæœ›çš„ç»“æ„
            memory_dict = {
                "metadata": {
                    "memory_id": metadata.get("memory_id", f"recovered_{int(time.time())}"),
                    "user_id": metadata.get("user_id", "unknown"),
                    "created_at": metadata.get("timestamp", time.time()),
                    "last_accessed": metadata.get("last_access_time", time.time()),
                    "last_modified": metadata.get("timestamp", time.time()),
                    "access_count": metadata.get("access_count", 0),
                    "relevance_score": 0.0,
                    "confidence": self._parse_enum_value(
                        metadata.get("confidence", 2), ConfidenceLevel, ConfidenceLevel.MEDIUM
                    ),
                    "importance": self._parse_enum_value(
                        metadata.get("importance", 2), ImportanceLevel, ImportanceLevel.NORMAL
                    ),
                    "source_context": None,
                },
                "content": {
                    "subject": "",
                    "predicate": "",
                    "object": "",
                    "display": document,  # ä½¿ç”¨documentä½œä¸ºæ˜¾ç¤ºæ–‡æœ¬
                },
                "memory_type": metadata.get("memory_type", "contextual"),
                "keywords": orjson.loads(metadata.get("keywords", "[]"))
                if isinstance(metadata.get("keywords"), str)
                else metadata.get("keywords", []),
                "tags": [],
                "categories": [],
                "embedding": None,
                "semantic_hash": None,
                "related_memories": [],
                "temporal_context": None,
            }

            return MemoryChunk.from_dict(memory_dict)

        except Exception as e:
            logger.error(f"è½¬æ¢Vectorç»“æœåˆ°MemoryChunkå¤±è´¥: {e}", exc_info=True)
            return None

    def _parse_enum_value(self, value: Any, enum_class: type, default: Any) -> Any:
        """è§£ææšä¸¾å€¼ï¼Œæ”¯æŒå­—ç¬¦ä¸²ã€æ•´æ•°å’Œæšä¸¾å®ä¾‹

        Args:
            value: è¦è§£æçš„å€¼ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²ã€æ•´æ•°æˆ–æšä¸¾å®ä¾‹ï¼‰
            enum_class: ç›®æ ‡æšä¸¾ç±»
            default: é»˜è®¤å€¼

        Returns:
            è§£æåçš„æšä¸¾å®ä¾‹
        """
        if value is None:
            return default

        # å¦‚æœå·²ç»æ˜¯æšä¸¾å®ä¾‹ï¼Œç›´æ¥è¿”å›
        if isinstance(value, enum_class):
            return value

        # å¦‚æœæ˜¯æ•´æ•°ï¼Œå°è¯•æŒ‰valueå€¼åŒ¹é…
        if isinstance(value, int):
            try:
                for member in enum_class:
                    if member.value == value:
                        return member
                # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„ï¼Œè¿”å›é»˜è®¤å€¼
                logger.warning(f"æ— æ³•æ‰¾åˆ°{enum_class.__name__}ä¸­value={value}çš„æšä¸¾é¡¹ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                return default
            except Exception as e:
                logger.warning(f"è§£æ{enum_class.__name__}æ•´æ•°å€¼{value}æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                return default

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•æŒ‰åç§°æˆ–valueå€¼åŒ¹é…
        if isinstance(value, str):
            str_value = value.strip().upper()

            # å…ˆå°è¯•æŒ‰æšä¸¾åç§°åŒ¹é…
            try:
                if hasattr(enum_class, str_value):
                    return getattr(enum_class, str_value)
            except AttributeError:
                pass

            # å†å°è¯•æŒ‰valueå€¼åŒ¹é…ï¼ˆå¦‚æœvalueæ˜¯å­—ç¬¦ä¸²å½¢å¼çš„æ•°å­—ï¼‰
            try:
                int_value = int(str_value)
                return self._parse_enum_value(int_value, enum_class, default)
            except ValueError:
                pass

            # æœ€åå°è¯•æŒ‰å°å†™åç§°åŒ¹é…
            try:
                for member in enum_class:
                    if member.value.upper() == str_value:
                        return member
                logger.warning(f"æ— æ³•æ‰¾åˆ°{enum_class.__name__}ä¸­åç§°æˆ–valueä¸º'{value}'çš„æšä¸¾é¡¹ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                return default
            except Exception as e:
                logger.warning(f"è§£æ{enum_class.__name__}å­—ç¬¦ä¸²å€¼'{value}'æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                return default

        # å…¶ä»–ç±»å‹ï¼Œè¿”å›é»˜è®¤å€¼
        logger.warning(f"ä¸æ”¯æŒçš„{enum_class.__name__}å€¼ç±»å‹: {type(value)}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        return default

    def _get_from_cache(self, memory_id: str) -> MemoryChunk | None:
        """ä»ç¼“å­˜è·å–è®°å¿†"""
        if not self.config.enable_caching:
            return None

        with self._lock:
            if memory_id in self.memory_cache:
                self.cache_timestamps[memory_id] = time.time()
                self.stats["cache_hits"] += 1
                return self.memory_cache[memory_id]

            self.stats["cache_misses"] += 1
            return None

    def _add_to_cache(self, memory: MemoryChunk):
        """æ·»åŠ è®°å¿†åˆ°ç¼“å­˜"""
        if not self.config.enable_caching:
            return

        with self._lock:
            # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
            if len(self.memory_cache) >= self.config.cache_size_limit:
                # ç§»é™¤æœ€è€çš„ç¼“å­˜é¡¹
                oldest_id = min(self.cache_timestamps.keys(), key=lambda k: self.cache_timestamps[k])
                self.memory_cache.pop(oldest_id, None)
                self.cache_timestamps.pop(oldest_id, None)

            memory_id = getattr(memory.metadata, "memory_id", None) or getattr(memory, "memory_id", None)
            if memory_id:
                self.memory_cache[memory_id] = memory
                self.cache_timestamps[memory_id] = time.time()

    async def store_memories(self, memories: list[MemoryChunk]) -> int:
        """æ‰¹é‡å­˜å‚¨è®°å¿†"""
        if not memories:
            return 0

        start_time = datetime.now()
        success_count = 0

        try:
            # è½¬æ¢ä¸ºå‘é‡æ ¼å¼
            vector_data_list = []
            for memory in memories:
                try:
                    vector_data = self._memory_to_vector_format(memory)
                    vector_data_list.append(vector_data)
                except Exception as e:
                    memory_id = getattr(memory.metadata, "memory_id", None) or getattr(memory, "memory_id", "unknown")
                    logger.error(f"å¤„ç†è®°å¿† {memory_id} å¤±è´¥: {e}")
                    continue

            if not vector_data_list:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„è®°å¿†æ•°æ®å¯å­˜å‚¨")
                return 0

            # æ‰¹é‡å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            for i in range(0, len(vector_data_list), self.batch_size):
                batch = vector_data_list[i : i + self.batch_size]

                try:
                    # ç”Ÿæˆembeddings
                    embeddings = []
                    for item in batch:
                        try:
                            embedding = await get_embedding(item["document"])
                            embeddings.append(embedding)
                        except Exception as e:
                            logger.error(f"ç”Ÿæˆembeddingå¤±è´¥: {e}")
                            # ä½¿ç”¨é›¶å‘é‡ä½œä¸ºåå¤‡
                            embeddings.append([0.0] * 768)  # é»˜è®¤ç»´åº¦

                    # vector_db_service.add éœ€è¦embeddingså‚æ•°
                    self.vector_db_service.add(
                        collection_name=self.collection_name,
                        embeddings=embeddings,
                        ids=[item["id"] for item in batch],
                        documents=[item["document"] for item in batch],
                        metadatas=[item["metadata"] for item in batch],
                    )
                    success = True

                    if success:
                        # æ›´æ–°ç¼“å­˜å’Œå…ƒæ•°æ®ç´¢å¼•
                        metadata_entries = []
                        for item in batch:
                            memory_id = item["id"]
                            # ä»åŸå§‹ memories åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”çš„ MemoryChunk
                            memory = next(
                                (
                                    m
                                    for m in memories
                                    if (getattr(m.metadata, "memory_id", None) or getattr(m, "memory_id", None))
                                    == memory_id
                                ),
                                None,
                            )
                            if memory:
                                # æ›´æ–°ç¼“å­˜
                                self._cache[memory_id] = memory
                                success_count += 1

                                # åˆ›å»ºå…ƒæ•°æ®ç´¢å¼•æ¡ç›®
                                try:
                                    index_entry = MemoryMetadataIndexEntry(
                                        memory_id=memory_id,
                                        user_id=memory.metadata.user_id or "unknown",
                                        memory_type=memory.memory_type.value,
                                        subjects=memory.subjects,
                                        objects=[str(memory.content.object)] if memory.content.object else [],
                                        keywords=memory.keywords,
                                        tags=memory.tags,
                                        importance=memory.metadata.importance.value,
                                        confidence=memory.metadata.confidence.value,
                                        created_at=memory.metadata.created_at,
                                        access_count=memory.metadata.access_count,
                                        chat_id=memory.metadata.chat_id,
                                        content_preview=str(memory.content)[:100] if memory.content else None,
                                    )
                                    metadata_entries.append(index_entry)
                                except Exception as e:
                                    logger.warning(f"åˆ›å»ºå…ƒæ•°æ®ç´¢å¼•æ¡ç›®å¤±è´¥ (memory_id={memory_id}): {e}")

                        # æ‰¹é‡æ›´æ–°å…ƒæ•°æ®ç´¢å¼•
                        if metadata_entries:
                            try:
                                self.metadata_index.batch_add_or_update(metadata_entries)
                                logger.debug(f"æ›´æ–°å…ƒæ•°æ®ç´¢å¼•: {len(metadata_entries)} æ¡")
                            except Exception as e:
                                logger.error(f"æ‰¹é‡æ›´æ–°å…ƒæ•°æ®ç´¢å¼•å¤±è´¥: {e}")
                    else:
                        logger.warning(f"æ‰¹æ¬¡å­˜å‚¨å¤±è´¥ï¼Œè·³è¿‡ {len(batch)} æ¡è®°å¿†")

                except Exception as e:
                    logger.error(f"æ‰¹é‡å­˜å‚¨å¤±è´¥: {e}", exc_info=True)
                    continue

            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"æˆåŠŸå­˜å‚¨ {success_count}/{len(memories)} æ¡è®°å¿†ï¼Œè€—æ—¶ {duration:.2f}ç§’")

            # ä¿å­˜å…ƒæ•°æ®ç´¢å¼•åˆ°ç£ç›˜
            if success_count > 0:
                try:
                    self.metadata_index.save()
                    logger.debug("å…ƒæ•°æ®ç´¢å¼•å·²ä¿å­˜åˆ°ç£ç›˜")
                except Exception as e:
                    logger.error(f"ä¿å­˜å…ƒæ•°æ®ç´¢å¼•å¤±è´¥: {e}")

            return success_count

        except Exception as e:
            logger.error(f"æ‰¹é‡å­˜å‚¨è®°å¿†å¤±è´¥: {e}", exc_info=True)
            return success_count

    async def store_memory(self, memory: MemoryChunk) -> bool:
        """å­˜å‚¨å•æ¡è®°å¿†"""
        result = await self.store_memories([memory])
        return result > 0

    async def search_similar_memories(
        self,
        query_text: str,
        limit: int = 10,
        similarity_threshold: float | None = None,
        filters: dict[str, Any] | None = None,
        # æ–°å¢ï¼šå…ƒæ•°æ®è¿‡æ»¤å‚æ•°ï¼ˆç”¨äºJSONç´¢å¼•ç²—ç­›ï¼‰
        metadata_filters: dict[str, Any] | None = None,
    ) -> list[tuple[MemoryChunk, float]]:
        """
        æœç´¢ç›¸ä¼¼è®°å¿†ï¼ˆæ··åˆç´¢å¼•æ¨¡å¼ï¼‰

        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            limit: è¿”å›æ•°é‡é™åˆ¶
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            filters: ChromaDB whereæ¡ä»¶ï¼ˆä¿ç•™ç”¨äºå…¼å®¹ï¼‰
            metadata_filters: JSONå…ƒæ•°æ®ç´¢å¼•è¿‡æ»¤æ¡ä»¶ï¼Œæ”¯æŒ:
                - memory_types: List[str]
                - subjects: List[str]
                - keywords: List[str]
                - tags: List[str]
                - importance_min: int
                - importance_max: int
                - created_after: float
                - created_before: float
                - user_id: str
        """
        if not query_text.strip():
            return []

        try:
            # === é˜¶æ®µä¸€ï¼šJSONå…ƒæ•°æ®ç²—ç­›ï¼ˆå¯é€‰ï¼‰ ===
            candidate_ids: list[str] | None = None
            if metadata_filters:
                logger.debug(f"[JSONå…ƒæ•°æ®ç²—ç­›] å¼€å§‹ï¼Œè¿‡æ»¤æ¡ä»¶: {metadata_filters}")
                candidate_ids = self.metadata_index.search(
                    memory_types=metadata_filters.get("memory_types"),
                    subjects=metadata_filters.get("subjects"),
                    keywords=metadata_filters.get("keywords"),
                    tags=metadata_filters.get("tags"),
                    importance_min=metadata_filters.get("importance_min"),
                    importance_max=metadata_filters.get("importance_max"),
                    created_after=metadata_filters.get("created_after"),
                    created_before=metadata_filters.get("created_before"),
                    user_id=metadata_filters.get("user_id"),
                    limit=self.config.search_limit * 2,  # ç²—ç­›è¿”å›æ›´å¤šå€™é€‰
                    flexible_mode=True,  # ä½¿ç”¨çµæ´»åŒ¹é…æ¨¡å¼
                )
                logger.debug(f"[JSONå…ƒæ•°æ®ç²—ç­›] å®Œæˆï¼Œç­›é€‰å‡º {len(candidate_ids)} ä¸ªå€™é€‰ID")

                # å¦‚æœç²—ç­›åæ²¡æœ‰ç»“æœï¼Œå›é€€åˆ°å…¨éƒ¨è®°å¿†æœç´¢
                if not candidate_ids:
                    total_memories = len(self.metadata_index.index)
                    logger.warning(
                        f"JSONå…ƒæ•°æ®ç²—ç­›åæ— å€™é€‰ï¼Œå¯ç”¨å›é€€æœºåˆ¶ï¼šåœ¨å…¨éƒ¨ {total_memories} æ¡è®°å¿†ä¸­è¿›è¡Œå‘é‡æœç´¢"
                    )
                    logger.info("ğŸ’¡ æç¤ºï¼šè¿™å¯èƒ½æ˜¯å› ä¸ºæŸ¥è¯¢æ¡ä»¶è¿‡äºä¸¥æ ¼ï¼Œæˆ–ç›¸å…³è®°å¿†çš„å…ƒæ•°æ®ä¸æŸ¥è¯¢æ¡ä»¶ä¸å®Œå…¨åŒ¹é…")
                    candidate_ids = None  # è®¾ä¸ºNoneè¡¨ç¤ºä¸é™åˆ¶å€™é€‰ID
                else:
                    logger.debug("[JSONå…ƒæ•°æ®ç²—ç­›] æˆåŠŸç­›é€‰å‡ºå€™é€‰ï¼Œè¿›å…¥å‘é‡ç²¾ç­›é˜¶æ®µ")

            # === é˜¶æ®µäºŒï¼šå‘é‡ç²¾ç­› ===
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = await get_embedding(query_text)
            if not query_embedding:
                return []

            threshold = similarity_threshold or self.config.similarity_threshold

            # æ„å»ºwhereæ¡ä»¶
            where_conditions = filters or {}

            # å¦‚æœæœ‰å€™é€‰IDåˆ—è¡¨ï¼Œæ·»åŠ åˆ°whereæ¡ä»¶
            if candidate_ids:
                # ChromaDBçš„whereæ¡ä»¶éœ€è¦ä½¿ç”¨$inæ“ä½œç¬¦
                where_conditions["memory_id"] = {"$in": candidate_ids}
                logger.debug(f"[å‘é‡ç²¾ç­›] é™åˆ¶åœ¨ {len(candidate_ids)} ä¸ªå€™é€‰IDå†…æœç´¢")
            else:
                logger.debug("[å‘é‡ç²¾ç­›] åœ¨å…¨éƒ¨è®°å¿†ä¸­æœç´¢ï¼ˆå…ƒæ•°æ®ç­›é€‰æ— ç»“æœå›é€€ï¼‰")

            # æŸ¥è¯¢Vector DB
            logger.debug(f"[å‘é‡ç²¾ç­›] å¼€å§‹ï¼Œlimit={min(limit, self.config.search_limit)}")
            results = vector_db_service.query(
                collection_name=self.config.memory_collection,
                query_embeddings=[query_embedding],
                n_results=min(limit, self.config.search_limit),
                where=where_conditions if where_conditions else None,
            )

            # å¤„ç†ç»“æœ
            similar_memories = []

            if results.get("documents") and results["documents"][0]:
                documents = results["documents"][0]
                distances = results.get("distances", [[]])[0]
                metadatas = results.get("metadatas", [[]])[0]
                ids = results.get("ids", [[]])[0]

                logger.debug(
                    f"å‘é‡æ£€ç´¢è¿”å›åŸå§‹ç»“æœï¼šdocuments={len(documents)}, ids={len(ids)}, metadatas={len(metadatas)}"
                )
                for i, (doc, metadata, memory_id) in enumerate(zip(documents, metadatas, ids, strict=False)):
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    distance = distances[i] if i < len(distances) else 1.0
                    similarity = 1 - distance  # ChromaDBè¿”å›è·ç¦»ï¼Œè½¬æ¢ä¸ºç›¸ä¼¼åº¦

                    if similarity < threshold:
                        continue

                    # é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
                    memory = self._get_from_cache(memory_id)

                    if not memory:
                        # ä»Vectorç»“æœé‡å»º
                        memory = self._vector_result_to_memory(doc, metadata)
                        if memory:
                            self._add_to_cache(memory)

                    if memory:
                        similar_memories.append((memory, similarity))
                        # è®°å½•å•æ¡ç»“æœçš„å…³é”®æ—¥å¿—ï¼ˆidï¼Œç›¸ä¼¼åº¦ï¼Œç®€çŸ­æ–‡æœ¬ï¼‰
                        try:
                            short_text = (
                                (str(memory.content)[:120])
                                if hasattr(memory, "content")
                                else (doc[:120] if isinstance(doc, str) else "")
                            )
                        except Exception:
                            short_text = ""
                        logger.debug(f"æ£€ç´¢ç»“æœ - id={memory_id}, similarity={similarity:.4f}, summary={short_text}")

            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            similar_memories.sort(key=lambda x: x[1], reverse=True)

            self.stats["total_searches"] += 1
            logger.debug(
                f"æœç´¢ç›¸ä¼¼è®°å¿†: query='{query_text[:60]}...', limit={limit}, threshold={threshold}, filters={where_conditions}, è¿”å›æ•°={len(similar_memories)}"
            )
            logger.debug(f"æœç´¢ç›¸ä¼¼è®°å¿† è¯¦ç»†ç»“æœæ•°={len(similar_memories)}")

            return similar_memories

        except Exception as e:
            logger.error(f"æœç´¢ç›¸ä¼¼è®°å¿†å¤±è´¥: {e}")
            return []

    async def get_memory_by_id(self, memory_id: str) -> MemoryChunk | None:
        """æ ¹æ®IDè·å–è®°å¿†"""
        # é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
        memory = self._get_from_cache(memory_id)
        if memory:
            return memory

        try:
            # ä»Vector DBè·å–
            results = vector_db_service.get(collection_name=self.config.memory_collection, ids=[memory_id])

            if results.get("documents") and results["documents"]:
                document = results["documents"][0]
                metadata = results["metadatas"][0] if results.get("metadatas") else {}

                memory = self._vector_result_to_memory(document, metadata)
                if memory:
                    self._add_to_cache(memory)

                return memory

        except Exception as e:
            logger.error(f"è·å–è®°å¿† {memory_id} å¤±è´¥: {e}")

        return None

    async def get_memories_by_filters(self, filters: dict[str, Any], limit: int = 100) -> list[MemoryChunk]:
        """æ ¹æ®è¿‡æ»¤æ¡ä»¶è·å–è®°å¿†"""
        try:
            results = vector_db_service.get(collection_name=self.config.memory_collection, where=filters, limit=limit)

            memories = []
            if results.get("documents"):
                documents = results["documents"]
                metadatas = results.get("metadatas", [{}] * len(documents))
                ids = results.get("ids", [])

                logger.debug(f"æŒ‰è¿‡æ»¤æ¡ä»¶è·å–è¿”å›: docs={len(documents)}, ids={len(ids)}")
                for i, (doc, metadata) in enumerate(zip(documents, metadatas, strict=False)):
                    memory_id = ids[i] if i < len(ids) else None

                    # é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
                    if memory_id:
                        memory = self._get_from_cache(memory_id)
                        if memory:
                            memories.append(memory)
                            logger.debug(f"è¿‡æ»¤è·å–å‘½ä¸­ç¼“å­˜: id={memory_id}")
                            continue

                    # ä»Vectorç»“æœé‡å»º
                    memory = self._vector_result_to_memory(doc, metadata)
                    if memory:
                        memories.append(memory)
                        if memory_id:
                            self._add_to_cache(memory)
                        logger.debug(f"è¿‡æ»¤è·å–ç»“æœ: id={memory_id}, meta_keys={list(metadata.keys())}")

            return memories

        except Exception as e:
            logger.error(f"æ ¹æ®è¿‡æ»¤æ¡ä»¶è·å–è®°å¿†å¤±è´¥: {e}")
            return []

    async def update_memory(self, memory: MemoryChunk) -> bool:
        """æ›´æ–°è®°å¿†"""
        try:
            memory_id = getattr(memory.metadata, "memory_id", None) or getattr(memory, "memory_id", None)
            if not memory_id:
                logger.error("æ— æ³•æ›´æ–°è®°å¿†ï¼šç¼ºå°‘memory_id")
                return False

            # å…ˆåˆ é™¤æ—§è®°å¿†
            await self.delete_memory(memory_id)

            # é‡æ–°å­˜å‚¨æ›´æ–°åçš„è®°å¿†
            return await self.store_memory(memory)

        except Exception as e:
            memory_id = getattr(memory.metadata, "memory_id", None) or getattr(memory, "memory_id", "unknown")
            logger.error(f"æ›´æ–°è®°å¿† {memory_id} å¤±è´¥: {e}")
            return False

    async def delete_memory(self, memory_id: str) -> bool:
        """åˆ é™¤è®°å¿†"""
        try:
            # ä»Vector DBåˆ é™¤
            vector_db_service.delete(collection_name=self.config.memory_collection, ids=[memory_id])

            # ä»ç¼“å­˜åˆ é™¤
            with self._lock:
                self.memory_cache.pop(memory_id, None)
                self.cache_timestamps.pop(memory_id, None)

            self.stats["total_memories"] = max(0, self.stats["total_memories"] - 1)
            logger.debug(f"åˆ é™¤è®°å¿†: {memory_id}")

            return True

        except Exception as e:
            logger.error(f"åˆ é™¤è®°å¿† {memory_id} å¤±è´¥: {e}")
            return False

    async def delete_memories_by_filters(self, filters: dict[str, Any]) -> int:
        """æ ¹æ®è¿‡æ»¤æ¡ä»¶æ‰¹é‡åˆ é™¤è®°å¿†"""
        try:
            # å…ˆè·å–è¦åˆ é™¤çš„è®°å¿†ID
            results = vector_db_service.get(
                collection_name=self.config.memory_collection, where=filters, include=["metadatas"]
            )

            if not results.get("ids"):
                return 0

            memory_ids = results["ids"]

            # æ‰¹é‡åˆ é™¤
            vector_db_service.delete(collection_name=self.config.memory_collection, where=filters)

            # ä»ç¼“å­˜åˆ é™¤
            with self._lock:
                for memory_id in memory_ids:
                    self.memory_cache.pop(memory_id, None)
                    self.cache_timestamps.pop(memory_id, None)

            deleted_count = len(memory_ids)
            self.stats["total_memories"] = max(0, self.stats["total_memories"] - deleted_count)
            logger.info(f"æ‰¹é‡åˆ é™¤è®°å¿†: {deleted_count} æ¡")

            return deleted_count

        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ é™¤è®°å¿†å¤±è´¥: {e}")
            return 0

    async def perform_forgetting_check(self) -> dict[str, Any]:
        """æ‰§è¡Œé—å¿˜æ£€æŸ¥"""
        if not self.forgetting_engine:
            return {"error": "é—å¿˜å¼•æ“æœªå¯ç”¨"}

        try:
            # è·å–æ‰€æœ‰è®°å¿†è¿›è¡Œé—å¿˜æ£€æŸ¥
            # æ³¨æ„ï¼šå¯¹äºå¤§å‹æ•°æ®é›†ï¼Œè¿™é‡Œåº”è¯¥åˆ†æ‰¹å¤„ç†
            current_time = time.time()
            cutoff_time = current_time - (self.config.retention_hours * 3600)

            # å…ˆåˆ é™¤æ˜æ˜¾è¿‡æœŸçš„è®°å¿†
            expired_filters = {"timestamp": {"$lt": cutoff_time}}
            expired_count = await self.delete_memories_by_filters(expired_filters)

            # å¯¹å‰©ä½™è®°å¿†æ‰§è¡Œæ™ºèƒ½é—å¿˜æ£€æŸ¥
            # è¿™é‡Œä¸ºäº†æ€§èƒ½è€ƒè™‘ï¼Œåªæ£€æŸ¥ä¸€éƒ¨åˆ†è®°å¿†
            sample_memories = await self.get_memories_by_filters({}, limit=500)

            if sample_memories:
                result = await self.forgetting_engine.perform_forgetting_check(sample_memories)

                # é—å¿˜æ ‡è®°çš„è®°å¿†
                forgetting_ids = result.get("normal_forgetting", []) + result.get("force_forgetting", [])
                forgotten_count = 0

                for memory_id in forgetting_ids:
                    if await self.delete_memory(memory_id):
                        forgotten_count += 1

                result["forgotten_count"] = forgotten_count
                result["expired_count"] = expired_count

                # æ›´æ–°ç»Ÿè®¡
                self.stats["forgetting_stats"] = self.forgetting_engine.get_forgetting_stats()

                logger.info(f"é—å¿˜æ£€æŸ¥å®Œæˆ: è¿‡æœŸåˆ é™¤ {expired_count}, æ™ºèƒ½é—å¿˜ {forgotten_count}")
                return result

            return {"expired_count": expired_count, "forgotten_count": 0}

        except Exception as e:
            logger.error(f"æ‰§è¡Œé—å¿˜æ£€æŸ¥å¤±è´¥: {e}")
            return {"error": str(e)}

    def get_storage_stats(self) -> dict[str, Any]:
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        try:
            current_total = vector_db_service.count(self.config.memory_collection)
            self.stats["total_memories"] = current_total
        except Exception:
            pass

        return {
            **self.stats,
            "cache_size": len(self.memory_cache),
            "collection_name": self.config.memory_collection,
            "storage_type": "vector_db_v2",
            "uptime": time.time() - self.stats.get("start_time", time.time()),
        }

    def stop(self):
        """åœæ­¢å­˜å‚¨ç³»ç»Ÿ"""
        self._stop_cleanup = True

        if self._cleanup_task and self._cleanup_task.is_alive():
            logger.info("æ­£åœ¨åœæ­¢å®šæ—¶æ¸…ç†ä»»åŠ¡...")

        # æ¸…ç©ºç¼“å­˜
        with self._lock:
            self.memory_cache.clear()
            self.cache_timestamps.clear()

        logger.info("Vectorè®°å¿†å­˜å‚¨ç³»ç»Ÿå·²åœæ­¢")


# å…¨å±€å®ä¾‹ï¼ˆå¯é€‰ï¼‰
_global_vector_storage = None


def get_vector_memory_storage(config: VectorStorageConfig | None = None) -> VectorMemoryStorage:
    """è·å–å…¨å±€Vectorè®°å¿†å­˜å‚¨å®ä¾‹"""
    global _global_vector_storage

    if _global_vector_storage is None:
        _global_vector_storage = VectorMemoryStorage(config)

    return _global_vector_storage


# å…¼å®¹æ€§æ¥å£
class VectorMemoryStorageAdapter:
    """é€‚é…å™¨ç±»ï¼Œæä¾›ä¸åŸUnifiedMemoryStorageå…¼å®¹çš„æ¥å£"""

    def __init__(self, config: VectorStorageConfig | None = None):
        self.storage = VectorMemoryStorage(config)

    async def store_memories(self, memories: list[MemoryChunk]) -> int:
        return await self.storage.store_memories(memories)

    async def search_similar_memories(
        self, query_text: str, limit: int = 10, scope_id: str | None = None, filters: dict[str, Any] | None = None
    ) -> list[tuple[str, float]]:
        results = await self.storage.search_similar_memories(query_text, limit, filters=filters)
        # è½¬æ¢ä¸ºåŸæ ¼å¼ï¼š(memory_id, similarity)
        return [
            (getattr(memory.metadata, "memory_id", None) or getattr(memory, "memory_id", "unknown"), similarity)
            for memory, similarity in results
        ]

    def get_stats(self) -> dict[str, Any]:
        return self.storage.get_storage_stats()


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    async def test_vector_storage():
        storage = VectorMemoryStorage()

        # åˆ›å»ºæµ‹è¯•è®°å¿†
        from src.chat.memory_system.memory_chunk import MemoryType

        test_memory = MemoryChunk(
            memory_id="test_001",
            user_id="test_user",
            text_content="ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥",
            memory_type=MemoryType.FACT,
            keywords=["å¤©æ°”", "æ•£æ­¥"],
            importance=0.7,
        )

        # å­˜å‚¨è®°å¿†
        success = await storage.store_memory(test_memory)
        print(f"å­˜å‚¨ç»“æœ: {success}")

        # æœç´¢è®°å¿†
        results = await storage.search_similar_memories("å¤©æ°”æ€ä¹ˆæ ·", limit=5)
        print(f"æœç´¢ç»“æœ: {len(results)} æ¡")

        for memory, similarity in results:
            print(f"  - {memory.text_content[:50]}... (ç›¸ä¼¼åº¦: {similarity:.3f})")

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = storage.get_storage_stats()
        print(f"å­˜å‚¨ç»Ÿè®¡: {stats}")

        storage.stop()

    asyncio.run(test_vector_storage())
