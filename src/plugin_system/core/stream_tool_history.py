"""
æµå¼å·¥å…·å†å²è®°å½•ç®¡ç†å™¨
ç”¨äºåœ¨èŠå¤©æµçº§åˆ«ç®¡ç†å·¥å…·è°ƒç”¨å†å²ï¼Œæ”¯æŒæ™ºèƒ½ç¼“å­˜å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥
"""

import time
from dataclasses import dataclass, field
from typing import Any

import orjson

from src.common.cache_manager import tool_cache
from src.common.logger import get_logger

logger = get_logger("stream_tool_history")


@dataclass(slots=True)
class ToolCallRecord:
    """å·¥å…·è°ƒç”¨è®°å½•"""
    tool_name: str
    args: dict[str, Any]
    result: dict[str, Any] | None = None
    status: str = "success"  # success, error, pending
    timestamp: float = field(default_factory=time.time)
    execution_time: float | None = None  # æ‰§è¡Œè€—æ—¶(ç§’)
    cache_hit: bool = False  # æ˜¯å¦å‘½ä¸­ç¼“å­˜
    result_preview: str = ""  # ç»“æœé¢„è§ˆ
    error_message: str = ""  # é”™è¯¯ä¿¡æ¯

    def __post_init__(self):
        """åå¤„ç†ï¼šç”Ÿæˆç»“æœé¢„è§ˆ"""
        if self.result and not self.result_preview:
            content = self.result.get("content", "")
            # è”ç½‘æœç´¢ç­‰é‡è¦å·¥å…·ä¸æˆªæ–­ç»“æœ
            no_truncate_tools = {"web_search", "web_surfing", "knowledge_search"}
            should_truncate = self.tool_name not in no_truncate_tools
            max_length = 500 if should_truncate else 10000  # è”ç½‘æœç´¢ç»™æ›´å¤§çš„é™åˆ¶
            
            if isinstance(content, str):
                if len(content) > max_length:
                    self.result_preview = content[:max_length] + "..."
                else:
                    self.result_preview = content
            elif isinstance(content, list | dict):
                try:
                    json_str = orjson.dumps(content, option=orjson.OPT_NON_STR_KEYS).decode("utf-8")
                    if len(json_str) > max_length:
                        self.result_preview = json_str[:max_length] + "..."
                    else:
                        self.result_preview = json_str
                except Exception:
                    str_content = str(content)
                    if len(str_content) > max_length:
                        self.result_preview = str_content[:max_length] + "..."
                    else:
                        self.result_preview = str_content
            else:
                str_content = str(content)
                if len(str_content) > max_length:
                    self.result_preview = str_content[:max_length] + "..."
                else:
                    self.result_preview = str_content


class StreamToolHistoryManager:
    """æµå¼å·¥å…·å†å²è®°å½•ç®¡ç†å™¨

    æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
    1. å·¥å…·è°ƒç”¨å†å²çš„æŒä¹…åŒ–ç®¡ç†
    2. æ™ºèƒ½ç¼“å­˜é›†æˆå’Œç»“æœå»é‡
    3. ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å†å²è®°å½•æ£€ç´¢
    4. æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡
    """

    def __init__(self, chat_id: str, max_history: int = 20, enable_memory_cache: bool = True):
        """åˆå§‹åŒ–å†å²è®°å½•ç®¡ç†å™¨

        Args:
            chat_id: èŠå¤©IDï¼Œç”¨äºéš”ç¦»ä¸åŒèŠå¤©æµçš„å†å²è®°å½•
            max_history: æœ€å¤§å†å²è®°å½•æ•°é‡
            enable_memory_cache: æ˜¯å¦å¯ç”¨å†…å­˜ç¼“å­˜
        """
        self.chat_id = chat_id
        self.max_history = max_history
        self.enable_memory_cache = enable_memory_cache

        # å†…å­˜ä¸­çš„å†å²è®°å½•ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åˆ—
        self._history: list[ToolCallRecord] = []

        # æ€§èƒ½ç»Ÿè®¡
        self._stats = {
            "total_calls": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "total_execution_time": 0.0,
            "average_execution_time": 0.0,
        }

        logger.info(f"[{chat_id}] å·¥å…·å†å²è®°å½•ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å†å²: {max_history}")

    async def add_tool_call(self, record: ToolCallRecord) -> None:
        """æ·»åŠ å·¥å…·è°ƒç”¨è®°å½•

        Args:
            record: å·¥å…·è°ƒç”¨è®°å½•
        """
        # ç»´æŠ¤å†å²è®°å½•å¤§å°
        if len(self._history) >= self.max_history:
            # ç§»é™¤æœ€æ—§çš„è®°å½•
            removed_record = self._history.pop(0)
            logger.debug(f"[{self.chat_id}] ç§»é™¤æ—§è®°å½•: {removed_record.tool_name}")

        # æ·»åŠ æ–°è®°å½•
        self._history.append(record)

        # æ›´æ–°ç»Ÿè®¡
        self._stats["total_calls"] += 1
        if record.cache_hit:
            self._stats["cache_hits"] += 1
        else:
            self._stats["cache_misses"] += 1

        if record.execution_time is not None:
            self._stats["total_execution_time"] += record.execution_time
            self._stats["average_execution_time"] = self._stats["total_execution_time"] / self._stats["total_calls"]

        logger.debug(f"[{self.chat_id}] æ·»åŠ å·¥å…·è°ƒç”¨è®°å½•: {record.tool_name}, ç¼“å­˜å‘½ä¸­: {record.cache_hit}")

    async def get_cached_result(self, tool_name: str, args: dict[str, Any]) -> dict[str, Any] | None:
        """ä»ç¼“å­˜æˆ–å†å²è®°å½•ä¸­è·å–ç»“æœ

        Args:
            tool_name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°

        Returns:
            ç¼“å­˜çš„ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        # é¦–å…ˆæ£€æŸ¥å†…å­˜ä¸­çš„å†å²è®°å½•
        if self.enable_memory_cache:
            memory_result = self._search_memory_cache(tool_name, args)
            if memory_result:
                logger.info(f"[{self.chat_id}] å†…å­˜ç¼“å­˜å‘½ä¸­: {tool_name}")
                return memory_result

        # ç„¶åæ£€æŸ¥å…¨å±€ç¼“å­˜ç³»ç»Ÿ
        try:
            # è¿™é‡Œéœ€è¦å·¥å…·å®ä¾‹æ¥è·å–æ–‡ä»¶è·¯å¾„ï¼Œä½†ä¸ºäº†è§£è€¦ï¼Œæˆ‘ä»¬å…ˆå°è¯•ä»å†å²è®°å½•ä¸­æ¨æ–­
            tool_file_path = self._infer_tool_path(tool_name)

            # å°è¯•è¯­ä¹‰ç¼“å­˜ï¼ˆå¦‚æœå¯ä»¥æ¨æ–­å‡ºè¯­ä¹‰æŸ¥è¯¢å‚æ•°ï¼‰
            semantic_query = self._extract_semantic_query(tool_name, args)

            cached_result = await tool_cache.get(
                tool_name=tool_name,
                function_args=args,
                tool_file_path=tool_file_path,
                semantic_query=semantic_query,
            )

            if cached_result:
                logger.info(f"[{self.chat_id}] å…¨å±€ç¼“å­˜å‘½ä¸­: {tool_name}")

                # å°†ç»“æœåŒæ­¥åˆ°å†…å­˜ç¼“å­˜
                if self.enable_memory_cache:
                    record = ToolCallRecord(
                        tool_name=tool_name,
                        args=args,
                        result=cached_result,
                        status="success",
                        cache_hit=True,
                        timestamp=time.time(),
                    )
                    await self.add_tool_call(record)

                return cached_result

        except Exception as e:
            logger.warning(f"[{self.chat_id}] ç¼“å­˜æŸ¥è¯¢å¤±è´¥: {e}")

        return None

    async def cache_result(self, tool_name: str, args: dict[str, Any], result: dict[str, Any],
                          execution_time: float | None = None,
                          tool_file_path: str | None = None,
                          ttl: int | None = None) -> None:
        """ç¼“å­˜å·¥å…·è°ƒç”¨ç»“æœ

        Args:
            tool_name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°
            result: æ‰§è¡Œç»“æœ
            execution_time: æ‰§è¡Œè€—æ—¶
            tool_file_path: å·¥å…·æ–‡ä»¶è·¯å¾„
            ttl: ç¼“å­˜TTL
        """
        # æ·»åŠ åˆ°å†…å­˜å†å²è®°å½•
        record = ToolCallRecord(
            tool_name=tool_name,
            args=args,
            result=result,
            status="success",
            execution_time=execution_time,
            cache_hit=False,
            timestamp=time.time(),
        )
        await self.add_tool_call(record)

        # åŒæ­¥åˆ°å…¨å±€ç¼“å­˜ç³»ç»Ÿ
        try:
            if tool_file_path is None:
                tool_file_path = self._infer_tool_path(tool_name)

            # å°è¯•è¯­ä¹‰ç¼“å­˜
            semantic_query = self._extract_semantic_query(tool_name, args)

            await tool_cache.set(
                tool_name=tool_name,
                function_args=args,
                tool_file_path=tool_file_path,
                data=result,
                ttl=ttl,
                semantic_query=semantic_query,
            )

            logger.debug(f"[{self.chat_id}] ç»“æœå·²ç¼“å­˜: {tool_name}")

        except Exception as e:
            logger.warning(f"[{self.chat_id}] ç¼“å­˜è®¾ç½®å¤±è´¥: {e}")

    def get_recent_history(self, count: int = 5, status_filter: str | None = None) -> list[ToolCallRecord]:
        """è·å–æœ€è¿‘çš„å†å²è®°å½•

        Args:
            count: è¿”å›çš„è®°å½•æ•°é‡
            status_filter: çŠ¶æ€è¿‡æ»¤å™¨ï¼Œå¯é€‰å€¼ï¼šsuccess, error, pending

        Returns:
            å†å²è®°å½•åˆ—è¡¨
        """
        history = self._history.copy()

        # åº”ç”¨çŠ¶æ€è¿‡æ»¤
        if status_filter:
            history = [record for record in history if record.status == status_filter]

        # è¿”å›æœ€è¿‘çš„è®°å½•
        return history[-count:] if history else []

    def format_for_prompt(self, max_records: int = 5, include_results: bool = True) -> str:
        """æ ¼å¼åŒ–å†å²è®°å½•ä¸ºæç¤ºè¯

        Args:
            max_records: æœ€å¤§è®°å½•æ•°é‡
            include_results: æ˜¯å¦åŒ…å«ç»“æœé¢„è§ˆ

        Returns:
            æ ¼å¼åŒ–çš„æç¤ºè¯å­—ç¬¦ä¸²
        """
        if not self._history:
            return ""

        recent_records = self._history[-max_records:]

        lines = ["## ğŸ”§ æœ€è¿‘å·¥å…·è°ƒç”¨è®°å½•"]
        for i, record in enumerate(recent_records, 1):
            status_icon = "success" if record.status == "success" else "error" if record.status == "error" else "pending"

            # æ ¼å¼åŒ–å‚æ•°
            args_preview = self._format_args_preview(record.args)

            # åŸºç¡€ä¿¡æ¯
            lines.append(f"{i}. {status_icon} **{record.tool_name}**({args_preview})")

            # æ·»åŠ æ‰§è¡Œæ—¶é—´å’Œç¼“å­˜ä¿¡æ¯
            if record.execution_time is not None:
                time_info = f"{record.execution_time:.2f}s"
                cache_info = "ğŸ¯ç¼“å­˜" if record.cache_hit else "ğŸ”æ‰§è¡Œ"
                lines.append(f"   â±ï¸ {time_info} | {cache_info}")

            # æ·»åŠ ç»“æœé¢„è§ˆ
            if include_results and record.result_preview:
                lines.append(f"   ğŸ“ ç»“æœ: {record.result_preview}")

            # æ·»åŠ é”™è¯¯ä¿¡æ¯
            if record.status == "error" and record.error_message:
                lines.append(f"   âŒ é”™è¯¯: {record.error_message}")

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if self._stats["total_calls"] > 0:
            cache_hit_rate = (self._stats["cache_hits"] / self._stats["total_calls"]) * 100
            avg_time = self._stats["average_execution_time"]
            lines.append(f"\nğŸ“Š å·¥å…·ç»Ÿè®¡: æ€»è®¡{self._stats['total_calls']}æ¬¡ | ç¼“å­˜å‘½ä¸­ç‡{cache_hit_rate:.1f}% | å¹³å‡è€—æ—¶{avg_time:.2f}s")

        return "\n".join(lines)

    def get_stats(self) -> dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        cache_hit_rate = 0.0
        if self._stats["total_calls"] > 0:
            cache_hit_rate = (self._stats["cache_hits"] / self._stats["total_calls"]) * 100

        return {
            **self._stats,
            "cache_hit_rate": cache_hit_rate,
            "history_size": len(self._history),
            "chat_id": self.chat_id,
        }

    def clear_history(self) -> None:
        """æ¸…é™¤å†å²è®°å½•"""
        self._history.clear()
        logger.info(f"[{self.chat_id}] å·¥å…·å†å²è®°å½•å·²æ¸…é™¤")

    def _search_memory_cache(self, tool_name: str, args: dict[str, Any]) -> dict[str, Any] | None:
        """åœ¨å†…å­˜å†å²è®°å½•ä¸­æœç´¢ç¼“å­˜

        Args:
            tool_name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°

        Returns:
            åŒ¹é…çš„ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        for record in reversed(self._history):  # ä»æœ€æ–°çš„å¼€å§‹æœç´¢
            if (record.tool_name == tool_name and
                record.status == "success" and
                record.args == args):
                return record.result
        return None

    def _infer_tool_path(self, tool_name: str) -> str:
        """æ¨æ–­å·¥å…·æ–‡ä»¶è·¯å¾„

        Args:
            tool_name: å·¥å…·åç§°

        Returns:
            æ¨æ–­çš„æ–‡ä»¶è·¯å¾„
        """
        # åŸºäºå·¥å…·åç§°æ¨æ–­è·¯å¾„ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°
        # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ˜ å°„é€»è¾‘
        tool_path_mapping = {
            "web_search": "src/plugins/built_in/web_search_tool/tools/web_search.py",
            "memory_create": "src/memory_graph/tools/memory_tools.py",
            "memory_search": "src/memory_graph/tools/memory_tools.py",
            "user_profile_update": "src/plugins/built_in/affinity_flow_chatter/tools/user_profile_tool.py",
            "chat_stream_impression_update": "src/plugins/built_in/affinity_flow_chatter/tools/chat_stream_impression_tool.py",
        }

        return tool_path_mapping.get(tool_name, f"src/plugins/tools/{tool_name}.py")

    def _extract_semantic_query(self, tool_name: str, args: dict[str, Any]) -> str | None:
        """æå–è¯­ä¹‰æŸ¥è¯¢å‚æ•°

        Args:
            tool_name: å·¥å…·åç§°
            args: å·¥å…·å‚æ•°

        Returns:
            è¯­ä¹‰æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        # ä¸ºä¸åŒå·¥å…·å®šä¹‰è¯­ä¹‰æŸ¥è¯¢å‚æ•°æ˜ å°„
        semantic_query_mapping = {
            "web_search": "query",
            "memory_search": "query",
            "knowledge_search": "query",
        }

        query_key = semantic_query_mapping.get(tool_name)
        if query_key and query_key in args:
            return str(args[query_key])

        return None

    def _format_args_preview(self, args: dict[str, Any], max_length: int = 100) -> str:
        """æ ¼å¼åŒ–å‚æ•°é¢„è§ˆ

        Args:
            args: å‚æ•°å­—å…¸
            max_length: æœ€å¤§é•¿åº¦

        Returns:
            æ ¼å¼åŒ–çš„å‚æ•°é¢„è§ˆå­—ç¬¦ä¸²
        """
        if not args:
            return ""

        try:
            args_str = orjson.dumps(args, option=orjson.OPT_SORT_KEYS).decode("utf-8")
            if len(args_str) > max_length:
                args_str = args_str[:max_length] + "..."
            return args_str
        except Exception:
            # å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
            parts = []
            for k, v in list(args.items())[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªå‚æ•°
                parts.append(f"{k}={str(v)[:20]}")
            result = ", ".join(parts)
            if len(parts) >= 3 or len(result) > max_length:
                result += "..."
            return result


# å†…å­˜ä¼˜åŒ–ï¼šå…¨å±€ç®¡ç†å™¨å­—å…¸ï¼ŒæŒ‰chat_idç´¢å¼•ï¼Œæ·»åŠ  LRU æ·˜æ±°
_stream_managers: dict[str, StreamToolHistoryManager] = {}
_stream_managers_last_used: dict[str, float] = {}  # è®°å½•æœ€åä½¿ç”¨æ—¶é—´
_STREAM_MANAGERS_MAX_SIZE = 100  # æœ€å¤§ä¿ç•™æ•°é‡


def _evict_old_stream_managers() -> None:
    """å†…å­˜ä¼˜åŒ–ï¼šæ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„ stream manager"""
    import time

    if len(_stream_managers) < _STREAM_MANAGERS_MAX_SIZE:
        return

    # æŒ‰æœ€åä½¿ç”¨æ—¶é—´æ’åºï¼Œæ·˜æ±°æœ€æ—§çš„ 20%
    evict_count = max(1, len(_stream_managers) // 5)
    sorted_by_time = sorted(
        _stream_managers_last_used.items(),
        key=lambda x: x[1]
    )

    evicted = []
    for chat_id, _ in sorted_by_time[:evict_count]:
        if chat_id in _stream_managers:
            del _stream_managers[chat_id]
        if chat_id in _stream_managers_last_used:
            del _stream_managers_last_used[chat_id]
        evicted.append(chat_id)

    if evicted:
        logger.info(f"ğŸ”§ StreamToolHistoryManager LRUæ·˜æ±°: é‡Šæ”¾äº† {len(evicted)} ä¸ªä¸æ´»è·ƒçš„ç®¡ç†å™¨")


def get_stream_tool_history_manager(chat_id: str) -> StreamToolHistoryManager:
    """è·å–æŒ‡å®šèŠå¤©çš„å·¥å…·å†å²è®°å½•ç®¡ç†å™¨

    Args:
        chat_id: èŠå¤©ID

    Returns:
        å·¥å…·å†å²è®°å½•ç®¡ç†å™¨å®ä¾‹
    """
    import time

    # ğŸ”§ æ›´æ–°æœ€åä½¿ç”¨æ—¶é—´
    _stream_managers_last_used[chat_id] = time.time()

    if chat_id not in _stream_managers:
        # ğŸ”§ æ£€æŸ¥æ˜¯å¦éœ€è¦æ·˜æ±°
        _evict_old_stream_managers()
        _stream_managers[chat_id] = StreamToolHistoryManager(chat_id)
    return _stream_managers[chat_id]


def cleanup_stream_manager(chat_id: str) -> None:
    """æ¸…ç†æŒ‡å®šèŠå¤©çš„ç®¡ç†å™¨

    Args:
        chat_id: èŠå¤©ID
    """
    if chat_id in _stream_managers:
        del _stream_managers[chat_id]
    if chat_id in _stream_managers_last_used:
        del _stream_managers_last_used[chat_id]
    logger.info(f"å·²æ¸…ç†èŠå¤© {chat_id} çš„å·¥å…·å†å²è®°å½•ç®¡ç†å™¨")
