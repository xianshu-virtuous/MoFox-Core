"""
LLM å·¥å…·æ¥å£ï¼šå®šä¹‰è®°å¿†ç³»ç»Ÿçš„å·¥å…· schema å’Œæ‰§è¡Œé€»è¾‘
"""

from __future__ import annotations

from typing import Any, Dict, List, Optional, Tuple

from src.common.logger import get_logger
from src.memory_graph.core.builder import MemoryBuilder
from src.memory_graph.core.extractor import MemoryExtractor
from src.memory_graph.models import Memory, MemoryStatus
from src.memory_graph.storage.graph_store import GraphStore
from src.memory_graph.storage.persistence import PersistenceManager
from src.memory_graph.storage.vector_store import VectorStore
from src.memory_graph.utils.embeddings import EmbeddingGenerator

logger = get_logger(__name__)


class MemoryTools:
    """
    è®°å¿†ç³»ç»Ÿå·¥å…·é›†
    
    æä¾›ç»™ LLM ä½¿ç”¨çš„å·¥å…·æ¥å£ï¼š
    1. create_memory: åˆ›å»ºæ–°è®°å¿†
    2. link_memories: å…³è”ä¸¤ä¸ªè®°å¿†
    3. search_memories: æœç´¢è®°å¿†
    """

    def __init__(
        self,
        vector_store: VectorStore,
        graph_store: GraphStore,
        persistence_manager: PersistenceManager,
        embedding_generator: Optional[EmbeddingGenerator] = None,
    ):
        """
        åˆå§‹åŒ–å·¥å…·é›†
        
        Args:
            vector_store: å‘é‡å­˜å‚¨
            graph_store: å›¾å­˜å‚¨
            persistence_manager: æŒä¹…åŒ–ç®¡ç†å™¨
            embedding_generator: åµŒå…¥ç”Ÿæˆå™¨ï¼ˆå¯é€‰ï¼‰
        """
        self.vector_store = vector_store
        self.graph_store = graph_store
        self.persistence_manager = persistence_manager
        self._initialized = False

        # åˆå§‹åŒ–ç»„ä»¶
        self.extractor = MemoryExtractor()
        self.builder = MemoryBuilder(
            vector_store=vector_store,
            graph_store=graph_store,
            embedding_generator=embedding_generator,
        )

    async def _ensure_initialized(self):
        """ç¡®ä¿å‘é‡å­˜å‚¨å·²åˆå§‹åŒ–"""
        if not self._initialized:
            await self.vector_store.initialize()
            self._initialized = True

    @staticmethod
    def get_create_memory_schema() -> Dict[str, Any]:
        """
        è·å– create_memory å·¥å…·çš„ JSON schema
        
        Returns:
            å·¥å…· schema å®šä¹‰
        """
        return {
            "name": "create_memory",
            "description": """åˆ›å»ºä¸€ä¸ªæ–°çš„è®°å¿†èŠ‚ç‚¹ï¼Œè®°å½•å¯¹è¯ä¸­æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚

ğŸ¯ **æ ¸å¿ƒåŸåˆ™**ï¼šä¸»åŠ¨è®°å½•ã€ç§¯ææ„å»ºã€ä¸°å¯Œç»†èŠ‚

âœ… **ä¼˜å…ˆåˆ›å»ºè®°å¿†çš„åœºæ™¯**ï¼ˆé¼“åŠ±è®°å½•ï¼‰ï¼š
1. **ä¸ªäººä¿¡æ¯**ï¼šå§“åã€æ˜µç§°ã€å¹´é¾„ã€èŒä¸šã€èº«ä»½ã€æ‰€åœ¨åœ°ã€è”ç³»æ–¹å¼ç­‰
2. **å…´è¶£çˆ±å¥½**ï¼šå–œæ¬¢/ä¸å–œæ¬¢çš„äº‹ç‰©ã€å¨±ä¹åå¥½ã€è¿åŠ¨çˆ±å¥½ã€é¥®é£Ÿå£å‘³ç­‰
3. **ç”Ÿæ´»çŠ¶æ€**ï¼šå·¥ä½œå­¦ä¹ çŠ¶æ€ã€ç”Ÿæ´»ä¹ æƒ¯ã€ä½œæ¯æ—¶é—´ã€æ—¥å¸¸å®‰æ’ç­‰
4. **ç»å†äº‹ä»¶**ï¼šæ­£åœ¨åšçš„äº‹ã€å®Œæˆçš„ä»»åŠ¡ã€å‚ä¸çš„æ´»åŠ¨ã€é‡åˆ°çš„é—®é¢˜ç­‰
5. **è§‚ç‚¹æ€åº¦**ï¼šå¯¹äº‹ç‰©çš„çœ‹æ³•ã€ä»·å€¼è§‚ã€æƒ…ç»ªè¡¨è¾¾ã€è¯„ä»·æ„è§ç­‰
6. **è®¡åˆ’ç›®æ ‡**ï¼šæœªæ¥æ‰“ç®—ã€å­¦ä¹ è®¡åˆ’ã€å·¥ä½œç›®æ ‡ã€å¾…åŠäº‹é¡¹ç­‰
7. **äººé™…å…³ç³»**ï¼šæåˆ°çš„æœ‹å‹ã€å®¶äººã€åŒäº‹ã€è®¤è¯†çš„äººç­‰
8. **æŠ€èƒ½çŸ¥è¯†**ï¼šæŒæ¡çš„æŠ€èƒ½ã€å­¦ä¹ çš„çŸ¥è¯†ã€ä¸“ä¸šé¢†åŸŸã€ä½¿ç”¨çš„å·¥å…·ç­‰
9. **ç‰©å“èµ„æº**ï¼šæ‹¥æœ‰çš„ç‰©å“ã€ä½¿ç”¨çš„è®¾å¤‡ã€å–œæ¬¢çš„å“ç‰Œç­‰
10. **æ—¶é—´åœ°ç‚¹**ï¼šé‡è¦æ—¶é—´èŠ‚ç‚¹ã€å¸¸å»çš„åœ°ç‚¹ã€æ´»åŠ¨åœºæ‰€ç­‰

âš ï¸ **æš‚ä¸åˆ›å»ºçš„æƒ…å†µ**ï¼ˆä»…é™ä»¥ä¸‹ï¼‰ï¼š
- çº¯ç²¹çš„æ‹›å‘¼è¯­ï¼ˆå•çº¯çš„"ä½ å¥½"ã€"å†è§"ï¼‰
- å®Œå…¨æ— æ„ä¹‰çš„è¯­æ°”è¯ï¼ˆå•çº¯çš„"å“¦"ã€"å—¯"ï¼‰
- æ˜ç¡®çš„ç³»ç»ŸæŒ‡ä»¤ï¼ˆå¦‚"åˆ‡æ¢æ¨¡å¼"ã€"é‡å¯"ï¼‰

ï¿½ **è®°å¿†æ‹†åˆ†å»ºè®®**ï¼š
- ä¸€å¥è¯åŒ…å«å¤šä¸ªä¿¡æ¯ç‚¹ â†’ æ‹†æˆå¤šæ¡è®°å¿†ï¼ˆæ›´åˆ©äºåç»­æ£€ç´¢ï¼‰
- ä¾‹å¦‚ï¼š"æˆ‘æœ€è¿‘åœ¨å­¦Pythonå’Œæœºå™¨å­¦ä¹ ï¼Œæƒ³æ‰¾å·¥ä½œ"
  â†’ æ‹†æˆ3æ¡ï¼š
  1. "ç”¨æˆ·æ­£åœ¨å­¦ä¹ Python"ï¼ˆäº‹ä»¶ï¼‰
  2. "ç”¨æˆ·æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ "ï¼ˆäº‹ä»¶ï¼‰
  3. "ç”¨æˆ·æƒ³æ‰¾å·¥ä½œ"ï¼ˆäº‹ä»¶/ç›®æ ‡ï¼‰

ğŸ“Œ **è®°å¿†è´¨é‡å»ºè®®**ï¼š
- è®°å½•æ—¶å°½é‡è¡¥å……æ—¶é—´ï¼ˆ"ä»Šå¤©"ã€"æœ€è¿‘"ã€"æ˜¨å¤©"ç­‰ï¼‰
- åŒ…å«å…·ä½“ç»†èŠ‚ï¼ˆè¶Šå…·ä½“è¶Šå¥½ï¼‰
- ä¸»ä½“æ˜ç¡®ï¼ˆä¼˜å…ˆä½¿ç”¨"ç”¨æˆ·"æˆ–å…·ä½“äººåï¼Œé¿å…"æˆ‘"ï¼‰

è®°å¿†ç»“æ„ï¼šä¸»ä½“ + ç±»å‹ + ä¸»é¢˜ + å®¢ä½“ï¼ˆå¯é€‰ï¼‰+ å±æ€§ï¼ˆè¶Šè¯¦ç»†è¶Šå¥½ï¼‰""",
            "parameters": {
                "type": "object",
                "properties": {
                    "subject": {
                        "type": "string",
                        "description": "è®°å¿†çš„ä¸»ä½“ï¼ˆè°çš„ä¿¡æ¯ï¼‰ï¼š\n- å¯¹è¯ä¸­çš„ç”¨æˆ·ç»Ÿä¸€ä½¿ç”¨'ç”¨æˆ·'\n- æåˆ°çš„å…·ä½“äººç‰©ä½¿ç”¨å…¶åå­—ï¼ˆå¦‚'å°æ˜'ã€'å¼ ä¸‰'ï¼‰\n- é¿å…ä½¿ç”¨'æˆ‘'ã€'ä»–'ç­‰ä»£è¯",
                    },
                    "memory_type": {
                        "type": "string",
                        "enum": ["äº‹ä»¶", "äº‹å®", "å…³ç³»", "è§‚ç‚¹"],
                        "description": "é€‰æ‹©æœ€åˆé€‚çš„è®°å¿†ç±»å‹ï¼š\n\nã€äº‹ä»¶ã€‘æ—¶é—´ç›¸å…³çš„åŠ¨ä½œæˆ–å‘ç”Ÿçš„äº‹ï¼ˆç”¨'æ­£åœ¨'ã€'å®Œæˆäº†'ã€'å‚åŠ 'ç­‰åŠ¨è¯ï¼‰\n  ä¾‹ï¼šæ­£åœ¨å­¦ä¹ Pythonã€å®Œæˆäº†é¡¹ç›®ã€å‚åŠ ä¼šè®®ã€å»æ—…è¡Œ\n\nã€äº‹å®ã€‘ç›¸å¯¹ç¨³å®šçš„å®¢è§‚ä¿¡æ¯ï¼ˆç”¨'æ˜¯'ã€'æœ‰'ã€'åœ¨'ç­‰æè¿°çŠ¶æ€ï¼‰\n  ä¾‹ï¼šèŒä¸šæ˜¯å·¥ç¨‹å¸ˆã€ä½åœ¨åŒ—äº¬ã€æœ‰ä¸€åªçŒ«ã€ä¼šè¯´è‹±è¯­\n\nã€è§‚ç‚¹ã€‘ä¸»è§‚çœ‹æ³•ã€å–œå¥½ã€æ€åº¦ï¼ˆç”¨'å–œæ¬¢'ã€'è®¤ä¸º'ã€'è§‰å¾—'ç­‰ï¼‰\n  ä¾‹ï¼šå–œæ¬¢Pythonã€è®¤ä¸ºAIå¾ˆé‡è¦ã€è§‰å¾—ç´¯ã€è®¨åŒåŠ ç­\n\nã€å…³ç³»ã€‘äººä¸äººä¹‹é—´çš„å…³ç³»\n  ä¾‹ï¼šè®¤è¯†äº†æœ‹å‹ã€æ˜¯åŒäº‹ã€å®¶äººå…³ç³»",
                    },
                    "topic": {
                        "type": "string",
                        "description": "è®°å¿†çš„æ ¸å¿ƒå†…å®¹ï¼ˆåšä»€ä¹ˆ/æ˜¯ä»€ä¹ˆ/å…³äºä»€ä¹ˆï¼‰ï¼š\n- å°½é‡å…·ä½“æ˜ç¡®ï¼ˆ'å­¦ä¹ Pythonç¼–ç¨‹' ä¼˜äº 'å­¦ä¹ 'ï¼‰\n- åŒ…å«å…³é”®åŠ¨è¯æˆ–æ ¸å¿ƒæ¦‚å¿µ\n- å¯ä»¥åŒ…å«æ—¶é—´çŠ¶æ€ï¼ˆ'æ­£åœ¨å­¦ä¹ 'ã€'å·²å®Œæˆ'ã€'è®¡åˆ’åš'ï¼‰",
                    },
                    "object": {
                        "type": "string",
                        "description": "å¯é€‰ï¼šè®°å¿†æ¶‰åŠçš„å¯¹è±¡æˆ–ç›®æ ‡ï¼š\n- äº‹ä»¶çš„å¯¹è±¡ï¼ˆå­¦ä¹ çš„æ˜¯ä»€ä¹ˆã€è´­ä¹°çš„æ˜¯ä»€ä¹ˆï¼‰\n- è§‚ç‚¹çš„å¯¹è±¡ï¼ˆå–œæ¬¢çš„æ˜¯ä»€ä¹ˆã€è®¨åŒçš„æ˜¯ä»€ä¹ˆï¼‰\n- å¯ä»¥ç•™ç©ºï¼ˆå¦‚æœtopicå·²ç»è¶³å¤Ÿå®Œæ•´ï¼‰",
                    },
                    "attributes": {
                        "type": "object",
                        "description": "è®°å¿†çš„è¯¦ç»†å±æ€§ï¼ˆå»ºè®®å°½é‡å¡«å†™ï¼Œè¶Šè¯¦ç»†è¶Šå¥½ï¼‰ï¼š",
                        "properties": {
                            "æ—¶é—´": {
                                "type": "string",
                                "description": "æ—¶é—´ä¿¡æ¯ï¼ˆå¼ºçƒˆå»ºè®®å¡«å†™ï¼‰ï¼š\n- å…·ä½“æ—¥æœŸï¼š'2025-11-05'ã€'2025å¹´11æœˆ'\n- ç›¸å¯¹æ—¶é—´ï¼š'ä»Šå¤©'ã€'æ˜¨å¤©'ã€'ä¸Šå‘¨'ã€'æœ€è¿‘'ã€'3å¤©å‰'\n- æ—¶é—´æ®µï¼š'ä»Šå¤©ä¸‹åˆ'ã€'ä¸Šä¸ªæœˆ'ã€'è¿™å­¦æœŸ'",
                            },
                            "åœ°ç‚¹": {
                                "type": "string", 
                                "description": "åœ°ç‚¹ä¿¡æ¯ï¼ˆå¦‚æ¶‰åŠï¼‰ï¼š\n- å…·ä½“åœ°å€ã€åŸå¸‚åã€å›½å®¶\n- åœºæ‰€ç±»å‹ï¼š'åœ¨å®¶'ã€'å…¬å¸'ã€'å­¦æ ¡'ã€'å’–å•¡åº—'"
                            },
                            "åŸå› ": {
                                "type": "string", 
                                "description": "ä¸ºä»€ä¹ˆè¿™æ ·åš/è¿™æ ·æƒ³ï¼ˆå¦‚æ˜ç¡®æåˆ°ï¼‰"
                            },
                            "æ–¹å¼": {
                                "type": "string", 
                                "description": "æ€ä¹ˆåšçš„/é€šè¿‡ä»€ä¹ˆæ–¹å¼ï¼ˆå¦‚æ˜ç¡®æåˆ°ï¼‰"
                            },
                            "ç»“æœ": {
                                "type": "string",
                                "description": "ç»“æœå¦‚ä½•/äº§ç”Ÿä»€ä¹ˆå½±å“ï¼ˆå¦‚æ˜ç¡®æåˆ°ï¼‰"
                            },
                            "çŠ¶æ€": {
                                "type": "string",
                                "description": "å½“å‰è¿›å±•ï¼š'è¿›è¡Œä¸­'ã€'å·²å®Œæˆ'ã€'è®¡åˆ’ä¸­'ã€'æš‚åœ'ç­‰"
                            },
                            "ç¨‹åº¦": {
                                "type": "string",
                                "description": "ç¨‹åº¦æè¿°ï¼ˆå¦‚'éå¸¸'ã€'æ¯”è¾ƒ'ã€'æœ‰ç‚¹'ã€'ä¸å¤ª'ï¼‰"
                            },
                        },
                        "additionalProperties": True,
                    },
                    "importance": {
                        "type": "number",
                        "minimum": 0.0,
                        "maximum": 1.0,
                        "description": "é‡è¦æ€§è¯„åˆ†ï¼ˆé»˜è®¤0.5ï¼Œæ—¥å¸¸å¯¹è¯å»ºè®®0.5-0.7ï¼‰ï¼š\n\n0.3-0.4: æ¬¡è¦ç»†èŠ‚ï¼ˆå¶ç„¶æåŠçš„çäº‹ï¼‰\n0.5-0.6: æ—¥å¸¸ä¿¡æ¯ï¼ˆä¸€èˆ¬æ€§çš„åˆ†äº«ã€æ™®é€šçˆ±å¥½ï¼‰â† æ¨èé»˜è®¤å€¼\n0.7-0.8: é‡è¦ä¿¡æ¯ï¼ˆæ˜ç¡®çš„åå¥½ã€é‡è¦è®¡åˆ’ã€æ ¸å¿ƒçˆ±å¥½ï¼‰\n0.9-1.0: å…³é”®ä¿¡æ¯ï¼ˆèº«ä»½ä¿¡æ¯ã€é‡å¤§å†³å®šã€å¼ºçƒˆæƒ…æ„Ÿï¼‰\n\nğŸ’¡ å»ºè®®ï¼šæ—¥å¸¸å¯¹è¯ä¸­å¤§éƒ¨åˆ†è®°å¿†ä½¿ç”¨0.5-0.6ï¼Œé™¤éç”¨æˆ·ç‰¹åˆ«å¼ºè°ƒ",
                    },
                },
                "required": ["subject", "memory_type", "topic"],
            },
        }

    @staticmethod
    def get_link_memories_schema() -> Dict[str, Any]:
        """
        è·å– link_memories å·¥å…·çš„ JSON schema
        
        Returns:
            å·¥å…· schema å®šä¹‰
        """
        return {
            "name": "link_memories",
            "description": """æ‰‹åŠ¨å…³è”ä¸¤ä¸ªå·²å­˜åœ¨çš„è®°å¿†ã€‚

âš ï¸ ä½¿ç”¨å»ºè®®ï¼š
- ç³»ç»Ÿä¼šè‡ªåŠ¨å‘ç°è®°å¿†é—´çš„å…³è”å…³ç³»ï¼Œé€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨æ­¤å·¥å…·
- ä»…åœ¨ä»¥ä¸‹æƒ…å†µä½¿ç”¨ï¼š
  1. ç”¨æˆ·æ˜ç¡®æŒ‡å‡ºä¸¤ä¸ªè®°å¿†ä¹‹é—´çš„å…³ç³»
  2. å‘ç°æ˜æ˜¾çš„å› æœå…³ç³»ä½†ç³»ç»Ÿæœªè‡ªåŠ¨å…³è”
  3. éœ€è¦å»ºç«‹ç‰¹æ®Šçš„å¼•ç”¨å…³ç³»

å…³ç³»ç±»å‹è¯´æ˜ï¼š
- å¯¼è‡´ï¼šAäº‹ä»¶/è¡Œä¸ºå¯¼è‡´Bäº‹ä»¶/ç»“æœï¼ˆå› æœå…³ç³»ï¼‰
- å¼•ç”¨ï¼šAè®°å¿†å¼•ç”¨/åŸºäºBè®°å¿†ï¼ˆçŸ¥è¯†å…³è”ï¼‰
- ç›¸ä¼¼ï¼šAå’ŒBæè¿°ç›¸ä¼¼çš„å†…å®¹ï¼ˆä¸»é¢˜ç›¸ä¼¼ï¼‰
- ç›¸åï¼šAå’ŒBè¡¨è¾¾ç›¸åçš„è§‚ç‚¹ï¼ˆå¯¹æ¯”å…³ç³»ï¼‰
- å…³è”ï¼šAå’ŒBå­˜åœ¨ä¸€èˆ¬æ€§å…³è”ï¼ˆå…¶ä»–å…³ç³»ï¼‰""",
            "parameters": {
                "type": "object",
                "properties": {
                    "source_memory_description": {
                        "type": "string",
                        "description": "æºè®°å¿†çš„å…³é”®æè¿°ï¼ˆç”¨äºæœç´¢å®šä½ï¼Œéœ€è¦è¶³å¤Ÿå…·ä½“ï¼‰",
                    },
                    "target_memory_description": {
                        "type": "string",
                        "description": "ç›®æ ‡è®°å¿†çš„å…³é”®æè¿°ï¼ˆç”¨äºæœç´¢å®šä½ï¼Œéœ€è¦è¶³å¤Ÿå…·ä½“ï¼‰",
                    },
                    "relation_type": {
                        "type": "string",
                        "enum": ["å¯¼è‡´", "å¼•ç”¨", "ç›¸ä¼¼", "ç›¸å", "å…³è”"],
                        "description": "å…³ç³»ç±»å‹ï¼ˆä»ä¸Šè¿°5ç§ç±»å‹ä¸­é€‰æ‹©æœ€åˆé€‚çš„ï¼‰",
                    },
                    "importance": {
                        "type": "number",
                        "minimum": 0.0,
                        "maximum": 1.0,
                        "description": "å…³ç³»çš„é‡è¦æ€§ï¼ˆ0.0-1.0ï¼‰ï¼š\n- 0.5-0.6: ä¸€èˆ¬å…³è”\n- 0.7-0.8: é‡è¦å…³è”\n- 0.9-1.0: å…³é”®å…³è”\né»˜è®¤0.6",
                    },
                },
                "required": [
                    "source_memory_description",
                    "target_memory_description",
                    "relation_type",
                ],
            },
        }

    @staticmethod
    def get_search_memories_schema() -> Dict[str, Any]:
        """
        è·å– search_memories å·¥å…·çš„ JSON schema
        
        Returns:
            å·¥å…· schema å®šä¹‰
        """
        return {
            "name": "search_memories",
            "description": """æœç´¢ç›¸å…³çš„è®°å¿†ï¼Œç”¨äºå›å¿†å’ŒæŸ¥æ‰¾å†å²ä¿¡æ¯ã€‚

ä½¿ç”¨åœºæ™¯ï¼š
- ç”¨æˆ·è¯¢é—®ä¹‹å‰çš„å¯¹è¯å†…å®¹
- éœ€è¦å›å¿†ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ã€åå¥½ã€ç»å†
- æŸ¥æ‰¾ç›¸å…³çš„å†å²äº‹ä»¶æˆ–è§‚ç‚¹
- åŸºäºä¸Šä¸‹æ–‡è¡¥å……ä¿¡æ¯

æœç´¢ç‰¹æ€§ï¼š
- è¯­ä¹‰æœç´¢ï¼šåŸºäºå†…å®¹ç›¸ä¼¼åº¦åŒ¹é…
- å›¾éå†ï¼šè‡ªåŠ¨æ‰©å±•ç›¸å…³è”çš„è®°å¿†
- æ—¶é—´è¿‡æ»¤ï¼šæŒ‰æ—¶é—´èŒƒå›´ç­›é€‰
- ç±»å‹è¿‡æ»¤ï¼šæŒ‰è®°å¿†ç±»å‹ç­›é€‰""",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢æŸ¥è¯¢ï¼ˆç”¨è‡ªç„¶è¯­è¨€æè¿°è¦æŸ¥æ‰¾çš„å†…å®¹ï¼Œå¦‚'ç”¨æˆ·çš„èŒä¸š'ã€'æœ€è¿‘çš„é¡¹ç›®'ã€'Pythonç›¸å…³çš„è®°å¿†'ï¼‰",
                    },
                    "memory_types": {
                        "type": "array",
                        "items": {
                            "type": "string",
                            "enum": ["äº‹ä»¶", "äº‹å®", "å…³ç³»", "è§‚ç‚¹"],
                        },
                        "description": "è®°å¿†ç±»å‹è¿‡æ»¤ï¼ˆå¯é€‰ï¼Œç•™ç©ºè¡¨ç¤ºæœç´¢æ‰€æœ‰ç±»å‹ï¼‰",
                    },
                    "time_range": {
                        "type": "object",
                        "properties": {
                            "start": {
                                "type": "string",
                                "description": "å¼€å§‹æ—¶é—´ï¼ˆå¦‚'3å¤©å‰'ã€'ä¸Šå‘¨'ã€'2025-11-01'ï¼‰",
                            },
                            "end": {
                                "type": "string",
                                "description": "ç»“æŸæ—¶é—´ï¼ˆå¦‚'ä»Šå¤©'ã€'ç°åœ¨'ã€'2025-11-05'ï¼‰",
                            },
                        },
                        "description": "æ—¶é—´èŒƒå›´ï¼ˆå¯é€‰ï¼Œç”¨äºæŸ¥æ‰¾ç‰¹å®šæ—¶é—´æ®µçš„è®°å¿†ï¼‰",
                    },
                    "top_k": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 50,
                        "description": "è¿”å›ç»“æœæ•°é‡ï¼ˆ1-50ï¼Œé»˜è®¤10ï¼‰ã€‚æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼š\n- å¿«é€ŸæŸ¥æ‰¾ï¼š3-5æ¡\n- ä¸€èˆ¬æœç´¢ï¼š10æ¡\n- å…¨é¢äº†è§£ï¼š20-30æ¡",
                    },
                    "expand_depth": {
                        "type": "integer",
                        "minimum": 0,
                        "maximum": 3,
                        "description": "å›¾æ‰©å±•æ·±åº¦ï¼ˆ0-3ï¼Œé»˜è®¤1ï¼‰ï¼š\n- 0: ä»…è¿”å›ç›´æ¥åŒ¹é…çš„è®°å¿†\n- 1: åŒ…å«ä¸€åº¦ç›¸å…³çš„è®°å¿†ï¼ˆæ¨èï¼‰\n- 2-3: åŒ…å«æ›´å¤šé—´æ¥ç›¸å…³çš„è®°å¿†ï¼ˆç”¨äºæ·±åº¦æ¢ç´¢ï¼‰",
                    },
                },
                "required": ["query"],
            },
        }

    async def create_memory(self, **params) -> Dict[str, Any]:
        """
        æ‰§è¡Œ create_memory å·¥å…·
        
        Args:
            **params: å·¥å…·å‚æ•°
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(f"åˆ›å»ºè®°å¿†: {params.get('subject')} - {params.get('topic')}")

            # 0. ç¡®ä¿åˆå§‹åŒ–
            await self._ensure_initialized()

            # 1. æå–å‚æ•°
            extracted = self.extractor.extract_from_tool_params(params)

            # 2. æ„å»ºè®°å¿†
            memory = await self.builder.build_memory(extracted)

            # 3. æ·»åŠ åˆ°å­˜å‚¨ï¼ˆæš‚å­˜çŠ¶æ€ï¼‰
            await self._add_memory_to_stores(memory)

            # 4. ä¿å­˜åˆ°ç£ç›˜
            await self.persistence_manager.save_graph_store(self.graph_store)

            logger.info(f"è®°å¿†åˆ›å»ºæˆåŠŸ: {memory.id}")

            return {
                "success": True,
                "memory_id": memory.id,
                "message": f"è®°å¿†å·²åˆ›å»º: {extracted['subject']} - {extracted['topic']}",
                "nodes_count": len(memory.nodes),
                "edges_count": len(memory.edges),
            }

        except Exception as e:
            logger.error(f"è®°å¿†åˆ›å»ºå¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "è®°å¿†åˆ›å»ºå¤±è´¥",
            }

    async def link_memories(self, **params) -> Dict[str, Any]:
        """
        æ‰§è¡Œ link_memories å·¥å…·
        
        Args:
            **params: å·¥å…·å‚æ•°
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(
                f"å…³è”è®°å¿†: {params.get('source_memory_description')} -> "
                f"{params.get('target_memory_description')}"
            )

            # 1. æå–å‚æ•°
            extracted = self.extractor.extract_link_params(params)

            # 2. æŸ¥æ‰¾æºè®°å¿†å’Œç›®æ ‡è®°å¿†
            source_memory = await self._find_memory_by_description(
                extracted["source_description"]
            )
            target_memory = await self._find_memory_by_description(
                extracted["target_description"]
            )

            if not source_memory:
                return {
                    "success": False,
                    "error": "æ‰¾ä¸åˆ°æºè®°å¿†",
                    "message": f"æœªæ‰¾åˆ°åŒ¹é…çš„æºè®°å¿†: {extracted['source_description']}",
                }

            if not target_memory:
                return {
                    "success": False,
                    "error": "æ‰¾ä¸åˆ°ç›®æ ‡è®°å¿†",
                    "message": f"æœªæ‰¾åˆ°åŒ¹é…çš„ç›®æ ‡è®°å¿†: {extracted['target_description']}",
                }

            # 3. åˆ›å»ºå…³è”è¾¹
            edge = await self.builder.link_memories(
                source_memory=source_memory,
                target_memory=target_memory,
                relation_type=extracted["relation_type"],
                importance=extracted["importance"],
            )

            # 4. æ·»åŠ è¾¹åˆ°å›¾å­˜å‚¨
            self.graph_store.graph.add_edge(
                edge.source_id,
                edge.target_id,
                relation=edge.relation,
                edge_type=edge.edge_type.value,
                importance=edge.importance,
                **edge.metadata
            )

            # 5. ä¿å­˜
            await self.persistence_manager.save_graph_store(self.graph_store)

            logger.info(f"è®°å¿†å…³è”æˆåŠŸ: {source_memory.id} -> {target_memory.id}")

            return {
                "success": True,
                "message": f"è®°å¿†å·²å…³è”: {extracted['relation_type']}",
                "source_memory_id": source_memory.id,
                "target_memory_id": target_memory.id,
                "relation_type": extracted["relation_type"],
            }

        except Exception as e:
            logger.error(f"è®°å¿†å…³è”å¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "è®°å¿†å…³è”å¤±è´¥",
            }

    async def search_memories(self, **params) -> Dict[str, Any]:
        """
        æ‰§è¡Œ search_memories å·¥å…·
        
        ä½¿ç”¨å¤šç­–ç•¥æ£€ç´¢ä¼˜åŒ–ï¼š
        1. æŸ¥è¯¢åˆ†è§£ï¼ˆè¯†åˆ«ä¸»è¦å®ä½“å’Œæ¦‚å¿µï¼‰
        2. å¤šæŸ¥è¯¢å¹¶è¡Œæ£€ç´¢
        3. ç»“æœèåˆå’Œé‡æ’
        
        Args:
            **params: å·¥å…·å‚æ•°
                - query: æŸ¥è¯¢å­—ç¬¦ä¸²
                - top_k: è¿”å›ç»“æœæ•°ï¼ˆé»˜è®¤10ï¼‰
                - expand_depth: æ‰©å±•æ·±åº¦ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
                - use_multi_query: æ˜¯å¦ä½¿ç”¨å¤šæŸ¥è¯¢ç­–ç•¥ï¼ˆé»˜è®¤Trueï¼‰
                - context: æŸ¥è¯¢ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æœç´¢ç»“æœ
        """
        try:
            query = params.get("query", "")
            top_k = params.get("top_k", 10)
            expand_depth = params.get("expand_depth", 1)
            use_multi_query = params.get("use_multi_query", True)
            context = params.get("context", None)

            logger.info(f"æœç´¢è®°å¿†: {query} (top_k={top_k}, multi_query={use_multi_query})")

            # 0. ç¡®ä¿åˆå§‹åŒ–
            await self._ensure_initialized()

            # 1. æ ¹æ®ç­–ç•¥é€‰æ‹©æ£€ç´¢æ–¹å¼
            if use_multi_query:
                # å¤šæŸ¥è¯¢ç­–ç•¥
                similar_nodes = await self._multi_query_search(query, top_k, context)
            else:
                # ä¼ ç»Ÿå•æŸ¥è¯¢ç­–ç•¥
                similar_nodes = await self._single_query_search(query, top_k)

            # 2. æå–è®°å¿†ID
            memory_ids = set()
            for node_id, similarity, metadata in similar_nodes:
                if "memory_ids" in metadata:
                    ids = metadata["memory_ids"]
                    # ç¡®ä¿æ˜¯åˆ—è¡¨
                    if isinstance(ids, str):
                        import json
                        try:
                            ids = json.loads(ids)
                        except:
                            ids = [ids]
                    if isinstance(ids, list):
                        memory_ids.update(ids)

            # 3. è·å–å®Œæ•´è®°å¿†
            memories = []
            for memory_id in list(memory_ids)[:top_k]:
                memory = self.graph_store.get_memory_by_id(memory_id)
                if memory:
                    memories.append(memory)

            # 4. æ ¼å¼åŒ–ç»“æœ
            results = []
            for memory in memories:
                result = {
                    "memory_id": memory.id,
                    "importance": memory.importance,
                    "created_at": memory.created_at.isoformat(),
                    "summary": self._summarize_memory(memory),
                }
                results.append(result)

            logger.info(f"æœç´¢å®Œæˆ: æ‰¾åˆ° {len(results)} æ¡è®°å¿†")

            return {
                "success": True,
                "results": results,
                "total": len(results),
                "query": query,
                "strategy": "multi_query" if use_multi_query else "single_query",
            }

        except Exception as e:
            logger.error(f"è®°å¿†æœç´¢å¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "è®°å¿†æœç´¢å¤±è´¥",
                "results": [],
            }

    async def _generate_multi_queries_simple(
        self, query: str, context: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[str, float]]:
        """
        ç®€åŒ–ç‰ˆå¤šæŸ¥è¯¢ç”Ÿæˆï¼ˆç›´æ¥åœ¨ Tools å±‚å®ç°ï¼Œé¿å…å¾ªç¯ä¾èµ–ï¼‰
        
        è®©å°æ¨¡å‹ç›´æ¥ç”Ÿæˆ3-5ä¸ªä¸åŒè§’åº¦çš„æŸ¥è¯¢è¯­å¥ã€‚
        """
        try:
            from src.llm_models.utils_model import LLMRequest
            from src.config.config import model_config
            
            llm = LLMRequest(
                model_set=model_config.model_task_config.utils_small,
                request_type="memory.multi_query"
            )
            
            participants = context.get("participants", []) if context else []
            prompt = f"""ä¸ºæŸ¥è¯¢ç”Ÿæˆ3-5ä¸ªä¸åŒè§’åº¦çš„æœç´¢è¯­å¥ï¼ˆJSONæ ¼å¼ï¼‰ã€‚

**æŸ¥è¯¢ï¼š** {query}
**å‚ä¸è€…ï¼š** {', '.join(participants) if participants else 'æ— '}

**åŸåˆ™ï¼š** å¯¹å¤æ‚æŸ¥è¯¢ï¼ˆå¦‚"æ°ç‘å–µå¦‚ä½•è¯„ä»·æ–°çš„è®°å¿†ç³»ç»Ÿ"ï¼‰ï¼Œåº”ç”Ÿæˆï¼š
1. å®Œæ•´æŸ¥è¯¢ï¼ˆæƒé‡1.0ï¼‰
2. æ¯ä¸ªå…³é”®æ¦‚å¿µç‹¬ç«‹æŸ¥è¯¢ï¼ˆæƒé‡0.8ï¼‰- é‡è¦ï¼
3. ä¸»ä½“+åŠ¨ä½œï¼ˆæƒé‡0.6ï¼‰

**è¾“å‡ºJSONï¼š**
```json
{{"queries": [{{"text": "æŸ¥è¯¢1", "weight": 1.0}}, {{"text": "æŸ¥è¯¢2", "weight": 0.8}}]}}
```"""

            response, _ = await llm.generate_response_async(prompt, temperature=0.3, max_tokens=250)
            
            import json, re
            response = re.sub(r'```json\s*', '', response)
            response = re.sub(r'```\s*$', '', response).strip()
            
            data = json.loads(response)
            queries = data.get("queries", [])
            
            result = [(item.get("text", "").strip(), float(item.get("weight", 0.5))) 
                     for item in queries if item.get("text", "").strip()]
            
            if result:
                logger.info(f"ç”ŸæˆæŸ¥è¯¢: {[q for q, _ in result]}")
                return result
                
        except Exception as e:
            logger.warning(f"å¤šæŸ¥è¯¢ç”Ÿæˆå¤±è´¥: {e}")
        
        return [(query, 1.0)]

    async def _single_query_search(
        self, query: str, top_k: int
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """
        ä¼ ç»Ÿçš„å•æŸ¥è¯¢æœç´¢
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            top_k: è¿”å›ç»“æœæ•°
            
        Returns:
            ç›¸ä¼¼èŠ‚ç‚¹åˆ—è¡¨ [(node_id, similarity, metadata), ...]
        """
        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        if self.builder.embedding_generator:
            query_embedding = await self.builder.embedding_generator.generate(query)
        else:
            logger.warning("æœªé…ç½®åµŒå…¥ç”Ÿæˆå™¨ï¼Œä½¿ç”¨éšæœºå‘é‡")
            import numpy as np
            query_embedding = np.random.rand(384).astype(np.float32)

        # å‘é‡æœç´¢
        similar_nodes = await self.vector_store.search_similar_nodes(
            query_embedding=query_embedding,
            limit=top_k * 2,  # å¤šå–ä¸€äº›ï¼Œåç»­è¿‡æ»¤
        )

        return similar_nodes

    async def _multi_query_search(
        self, query: str, top_k: int, context: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """
        å¤šæŸ¥è¯¢ç­–ç•¥æœç´¢ï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        ç›´æ¥ä½¿ç”¨å°æ¨¡å‹ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢ï¼Œæ— éœ€å¤æ‚çš„åˆ†è§£å’Œç»„åˆã€‚
        
        æ­¥éª¤ï¼š
        1. è®©å°æ¨¡å‹ç”Ÿæˆ3-5ä¸ªä¸åŒè§’åº¦çš„æŸ¥è¯¢
        2. ä¸ºæ¯ä¸ªæŸ¥è¯¢ç”ŸæˆåµŒå…¥
        3. å¹¶è¡Œæœç´¢å¹¶èåˆç»“æœ
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            top_k: è¿”å›ç»“æœæ•°
            context: æŸ¥è¯¢ä¸Šä¸‹æ–‡
            
        Returns:
            èåˆåçš„ç›¸ä¼¼èŠ‚ç‚¹åˆ—è¡¨
        """
        try:
            # 1. ä½¿ç”¨å°æ¨¡å‹ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢
            multi_queries = await self._generate_multi_queries_simple(query, context)
            
            logger.debug(f"ç”Ÿæˆ {len(multi_queries)} ä¸ªæŸ¥è¯¢: {multi_queries}")

            # 2. ç”Ÿæˆæ‰€æœ‰æŸ¥è¯¢çš„åµŒå…¥
            if not self.builder.embedding_generator:
                logger.warning("æœªé…ç½®åµŒå…¥ç”Ÿæˆå™¨ï¼Œå›é€€åˆ°å•æŸ¥è¯¢æ¨¡å¼")
                return await self._single_query_search(query, top_k)

            query_embeddings = []
            query_weights = []

            for sub_query, weight in multi_queries:
                embedding = await self.builder.embedding_generator.generate(sub_query)
                query_embeddings.append(embedding)
                query_weights.append(weight)

            # 3. å¤šæŸ¥è¯¢èåˆæœç´¢
            similar_nodes = await self.vector_store.search_with_multiple_queries(
                query_embeddings=query_embeddings,
                query_weights=query_weights,
                limit=top_k * 2,  # å¤šå–ä¸€äº›ï¼Œåç»­è¿‡æ»¤
                fusion_strategy="weighted_max",
            )

            logger.info(f"å¤šæŸ¥è¯¢æ£€ç´¢å®Œæˆ: {len(similar_nodes)} ä¸ªèŠ‚ç‚¹")

            return similar_nodes

        except Exception as e:
            logger.warning(f"å¤šæŸ¥è¯¢æœç´¢å¤±è´¥ï¼Œå›é€€åˆ°å•æŸ¥è¯¢æ¨¡å¼: {e}", exc_info=True)
            return await self._single_query_search(query, top_k)

    async def _add_memory_to_stores(self, memory: Memory):
        """å°†è®°å¿†æ·»åŠ åˆ°å­˜å‚¨"""
        # 1. æ·»åŠ åˆ°å›¾å­˜å‚¨
        self.graph_store.add_memory(memory)

        # 2. æ·»åŠ æœ‰åµŒå…¥çš„èŠ‚ç‚¹åˆ°å‘é‡å­˜å‚¨
        for node in memory.nodes:
            if node.embedding is not None:
                await self.vector_store.add_node(node)

    async def _find_memory_by_description(self, description: str) -> Optional[Memory]:
        """
        é€šè¿‡æè¿°æŸ¥æ‰¾è®°å¿†
        
        Args:
            description: è®°å¿†æè¿°
            
        Returns:
            æ‰¾åˆ°çš„è®°å¿†ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
        """
        # ä½¿ç”¨è¯­ä¹‰æœç´¢æŸ¥æ‰¾æœ€ç›¸å…³çš„è®°å¿†
        if self.builder.embedding_generator:
            query_embedding = await self.builder.embedding_generator.generate(description)
        else:
            import numpy as np
            query_embedding = np.random.rand(384).astype(np.float32)

        # æœç´¢ç›¸ä¼¼èŠ‚ç‚¹
        similar_nodes = await self.vector_store.search_similar_nodes(
            query_embedding=query_embedding,
            limit=5,
        )

        if not similar_nodes:
            return None

        # è·å–æœ€ç›¸ä¼¼èŠ‚ç‚¹å…³è”çš„è®°å¿†
        node_id, similarity, metadata = similar_nodes[0]
        
        if "memory_ids" not in metadata or not metadata["memory_ids"]:
            return None
        
        ids = metadata["memory_ids"]
        
        # ç¡®ä¿æ˜¯åˆ—è¡¨
        if isinstance(ids, str):
            import json
            try:
                ids = json.loads(ids)
            except Exception as e:
                logger.warning(f"JSON è§£æå¤±è´¥: {e}")
                ids = [ids]
        
        if isinstance(ids, list) and ids:
            memory_id = ids[0]
            return self.graph_store.get_memory_by_id(memory_id)
        
        return None

    def _summarize_memory(self, memory: Memory) -> str:
        """ç”Ÿæˆè®°å¿†æ‘˜è¦"""
        if not memory.metadata:
            return "æœªçŸ¥è®°å¿†"

        subject = memory.metadata.get("subject", "")
        topic = memory.metadata.get("topic", "")
        memory_type = memory.metadata.get("memory_type", "")

        return f"{subject} - {memory_type}: {topic}"

    @staticmethod
    def get_all_tool_schemas() -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰å·¥å…·çš„ schema
        
        Returns:
            å·¥å…· schema åˆ—è¡¨
        """
        return [
            MemoryTools.get_create_memory_schema(),
            MemoryTools.get_link_memories_schema(),
            MemoryTools.get_search_memories_schema(),
        ]
