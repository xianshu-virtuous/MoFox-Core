"""
Kokoro Flow Chatter - Replyer

çº¯ç²¹çš„å›å¤ç”Ÿæˆå™¨ï¼š
- æ¥æ”¶ planner çš„å†³ç­–ï¼ˆthought ç­‰ï¼‰
- ä¸“é—¨è´Ÿè´£å°†å›å¤æ„å›¾è½¬åŒ–ä¸ºè‡ªç„¶çš„å¯¹è¯æ–‡æœ¬
- ä¸è¾“å‡º JSONï¼Œç›´æ¥ç”Ÿæˆå¯å‘é€çš„æ¶ˆæ¯æ–‡æœ¬
"""

from typing import TYPE_CHECKING, Optional

from src.common.logger import get_logger
from src.plugin_system.apis import llm_api

from .prompt.builder import get_prompt_builder
from .session import KokoroSession

if TYPE_CHECKING:
    from src.chat.message_receive.chat_stream import ChatStream

logger = get_logger("kfc_replyer")


async def generate_reply_text(
    session: KokoroSession,
    user_name: str,
    thought: str,
    situation_type: str = "new_message",
    chat_stream: Optional["ChatStream"] = None,
    extra_context: Optional[dict] = None,
) -> tuple[bool, str]:
    """
    ç”Ÿæˆå›å¤æ–‡æœ¬
    
    Args:
        session: ä¼šè¯å¯¹è±¡
        user_name: ç”¨æˆ·åç§°
        thought: è§„åˆ’å™¨ç”Ÿæˆçš„æƒ³æ³•ï¼ˆå†…å¿ƒç‹¬ç™½ï¼‰
        situation_type: æƒ…å†µç±»å‹
        chat_stream: èŠå¤©æµå¯¹è±¡
        extra_context: é¢å¤–ä¸Šä¸‹æ–‡
        
    Returns:
        (success, reply_text) å…ƒç»„
        - success: æ˜¯å¦æˆåŠŸç”Ÿæˆ
        - reply_text: ç”Ÿæˆçš„å›å¤æ–‡æœ¬
    """
    try:
        # 1. æ„å»ºå›å¤å™¨æç¤ºè¯
        prompt_builder = get_prompt_builder()
        prompt = await prompt_builder.build_replyer_prompt(
            session=session,
            user_name=user_name,
            thought=thought,
            situation_type=situation_type,
            chat_stream=chat_stream,
            extra_context=extra_context,
        )
        
        from src.config.config import global_config
        if global_config and global_config.debug.show_prompt:
            logger.info(f"[KFC Replyer] ç”Ÿæˆçš„å›å¤æç¤ºè¯:\n{prompt}")
        
        # 2. è·å– replyer æ¨¡å‹é…ç½®å¹¶è°ƒç”¨ LLM
        models = llm_api.get_available_models()
        replyer_config = models.get("replyer")
        
        if not replyer_config:
            logger.error("[KFC Replyer] æœªæ‰¾åˆ° replyer æ¨¡å‹é…ç½®")
            return False, "ï¼ˆå›å¤ç”Ÿæˆå¤±è´¥ï¼šæœªæ‰¾åˆ°æ¨¡å‹é…ç½®ï¼‰"
        
        success, raw_response, reasoning, model_name = await llm_api.generate_with_model(
            prompt=prompt,
            model_config=replyer_config,
            request_type="kokoro_flow_chatter.reply",
        )
        
        if not success:
            logger.error(f"[KFC Replyer] LLM è°ƒç”¨å¤±è´¥: {raw_response}")
            return False, "ï¼ˆå›å¤ç”Ÿæˆå¤±è´¥ï¼‰"
        
        # 3. æ¸…ç†å¹¶è¿”å›å›å¤æ–‡æœ¬
        reply_text = _clean_reply_text(raw_response)
        
        # ä½¿ç”¨ logger è¾“å‡ºç¾åŒ–æ—¥å¿—ï¼ˆé¢œè‰²é€šè¿‡ logger ç³»ç»Ÿé…ç½®ï¼‰
        logger.info(f"ğŸ’¬ {reply_text}")
        
        return True, reply_text
        
    except Exception as e:
        logger.error(f"[KFC Replyer] ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, "ï¼ˆå›å¤ç”Ÿæˆå¤±è´¥ï¼‰"


def _clean_reply_text(raw_text: str) -> str:
    """
    æ¸…ç†å›å¤æ–‡æœ¬
    
    ç§»é™¤å¯èƒ½çš„å‰åç¼€ã€å¼•å·ã€markdown æ ‡è®°ç­‰
    """
    text = raw_text.strip()
    
    # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
    if text.startswith("```") and text.endswith("```"):
        lines = text.split("\n")
        if len(lines) >= 3:
            # ç§»é™¤é¦–å°¾çš„ ``` è¡Œ
            text = "\n".join(lines[1:-1]).strip()
    
    # ç§»é™¤é¦–å°¾çš„å¼•å·ï¼ˆå¦‚æœæ•´ä¸ªæ–‡æœ¬è¢«å¼•å·åŒ…è£¹ï¼‰
    if (text.startswith('"') and text.endswith('"')) or \
       (text.startswith("'") and text.endswith("'")):
        text = text[1:-1].strip()
    
    # ç§»é™¤å¯èƒ½çš„"ä½ è¯´ï¼š"ã€"å›å¤ï¼š"ç­‰å‰ç¼€
    prefixes_to_remove = ["ä½ è¯´ï¼š", "ä½ è¯´:", "å›å¤ï¼š", "å›å¤:", "æˆ‘è¯´ï¼š", "æˆ‘è¯´:"]
    for prefix in prefixes_to_remove:
        if text.startswith(prefix):
            text = text[len(prefix):].strip()
            break
    
    return text
